{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(array([ 1,  2,  3,  4,  6,  8,  9, 10, 11]), array([0, 5, 7])), (array([0, 2, 3, 4, 5, 6, 7, 8, 9]), array([ 1, 10, 11])), (array([ 0,  1,  4,  5,  6,  7,  9, 10, 11]), array([2, 3, 8])), (array([ 0,  1,  2,  3,  5,  7,  8, 10, 11]), array([4, 6, 9]))]\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=4, shuffle=True)\n",
    "data_org = [i for i in range(12)]\n",
    "\n",
    "# print([[list(a1), list(a2)]  for a in kf.split(data_org) for a1,a2 in a\n",
    "print([a  for a in kf.split(data_org)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numpy test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([-1,3,6,4])\n",
    "a - a.min()\n",
    "l = [1,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input as Array: [[-1  2  7]]\n",
      "Input minus min: [[0 3 8]]\n",
      "Input  Array: [[0.    0.375 1.   ]]\n",
      "Multiply 1:\n",
      "False\n",
      "Multiply 2:\n",
      "[[14]\n",
      " [32]]\n",
      "Multiply 3:\n",
      "[[ 9 12 15]]\n",
      "Mean == 2.6666666666666665\n"
     ]
    }
   ],
   "source": [
    "# Use the numpy library\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def prepare_inputs(inputs):\n",
    "    # TODO: create a 2-dimensional ndarray from the given 1-dimensional list;\n",
    "    #       assign it to input_array\n",
    "    input_array = np.array(inputs)[None, :]\n",
    "    \n",
    "    # TODO: find the minimum value in input_array and subtract that\n",
    "    #       value from all the elements of input_array. Store the\n",
    "    #       result in inputs_minus_min\n",
    "    inputs_minus_min = input_array - input_array.min()\n",
    "\n",
    "    # TODO: find the maximum value in inputs_minus_min and divide\n",
    "    #       all of the values in inputs_minus_min by the maximum value.\n",
    "    #       Store the results in inputs_div_max.\n",
    "    inputs_div_max = inputs_minus_min / inputs_minus_min.max()\n",
    "\n",
    "    # return the three arrays we've created\n",
    "    return input_array, inputs_minus_min, inputs_div_max\n",
    "    \n",
    "\n",
    "def multiply_inputs(m1, m2):\n",
    "    # TODO: Check the shapes of the matrices m1 and m2. \n",
    "    #       m1 and m2 will be ndarray objects.\n",
    "    #\n",
    "    #       Return False if the shapes cannot be used for matrix\n",
    "    #       multiplication. You may not use a transpose\n",
    "    if m1.shape[1]!=m2.shape[0] and m1.shape[0]!=m2.shape[1]:\n",
    "        return False\n",
    "\n",
    "\n",
    "    # TODO: If you have not returned False, then calculate the matrix product\n",
    "    #       of m1 and m2 and return it. Do not use a transpose,\n",
    "    #       but you swap their order if necessary\n",
    "    return np.matmul(m1, m2) if m1.shape[1]==m2.shape[0] else np.matmul(m2, m1)\n",
    "    \n",
    "\n",
    "def find_mean(values):\n",
    "    # TODO: Return the average of the values in the given Python list\n",
    "    return np.mean(values)\n",
    "\n",
    "\n",
    "input_array, inputs_minus_min, inputs_div_max = prepare_inputs([-1,2,7])\n",
    "print(\"Input as Array: {}\".format(input_array))\n",
    "print(\"Input minus min: {}\".format(inputs_minus_min))\n",
    "print(\"Input  Array: {}\".format(inputs_div_max))\n",
    "\n",
    "print(\"Multiply 1:\\n{}\".format(multiply_inputs(np.array([[1,2,3],[4,5,6]]), np.array([[1],[2],[3],[4]]))))\n",
    "print(\"Multiply 2:\\n{}\".format(multiply_inputs(np.array([[1,2,3],[4,5,6]]), np.array([[1],[2],[3]]))))\n",
    "print(\"Multiply 3:\\n{}\".format(multiply_inputs(np.array([[1,2,3],[4,5,6]]), np.array([[1,2]]))))\n",
    "\n",
    "print(\"Mean == {}\".format(find_mean([1,3,4])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Input as Array: [[-1  2  7]]\n",
    "Input minus min: [[0 3 8]]\n",
    "Input  Array: [[0.    0.375 1.   ]]\n",
    "Multiply 1:\n",
    "False\n",
    "Multiply 2:\n",
    "[[14]\n",
    " [32]]\n",
    "Multiply 3:\n",
    "[[ 9 12 15]]\n",
    "Mean == 2.6666666666666665\n",
    "\n",
    "Nice job!  That's right!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## jupyter notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# High resolution image\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2cc72376d88a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'hello'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-3-2cc72376d88a>\u001b[0m(4)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      1 \u001b[0;31m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pdb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      2 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      3 \u001b[0;31m\u001b[0mnums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'hello'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 4 \u001b[0;31m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> nums\n",
      "'hello'\n",
      "ipdb> type(nums)\n",
      "<class 'str'>\n",
      "ipdb> \n",
      "<class 'str'>\n",
      "ipdb> quit()\n"
     ]
    }
   ],
   "source": [
    "%pdb\n",
    "\n",
    "# check variable when error occur\n",
    "nums = 'hello'\n",
    "sum(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# convert to html\n",
    "# !jupyter nbconvert --to html notebook.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook some_small_model.ipynb to slides\n",
      "[NbConvertApp] Writing 295821 bytes to some_small_model.slides.html\n"
     ]
    }
   ],
   "source": [
    "# convert to slideshow\n",
    "# !jupyter nbconvert some_small_model.ipynb --to slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert and show slideshow\n",
    "!jupyter nbconvert some_small_model.ipynb --to slides --post serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = set([i for i in range(12)])\n",
    "print(l)\n",
    "dict(enumerate(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{12: 0, 13: 1, 14: 2, 15: 3, 16: 4, 17: 5, 18: 6, 19: 7, 20: 8, 21: 9, 22: 10, 23: 11}\n",
      "{12: 0, 13: 1, 14: 2, 15: 3, 16: 4, 17: 5, 18: 6, 19: 7, 20: 8, 21: 9, 22: 10, 23: 11}\n"
     ]
    }
   ],
   "source": [
    "l = [i for i in range(12,24)]\n",
    "\n",
    "# print(dict(enumerate(l)))\n",
    "print(dict([(n, i) for i,n in enumerate(l)]))\n",
    "\n",
    "d = {}\n",
    "for i, n in enumerate(l):\n",
    "    d[n] = i\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.735"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.abs(0.735)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch,rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, dropout=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the PyTorch RNN Module\n",
    "        :param vocab_size: The number of input dimensions of the neural network (the size of the vocabulary)\n",
    "        :param output_size: The number of output dimensions of the neural network\n",
    "        :param embedding_dim: The size of embeddings, should you choose to use them        \n",
    "        :param hidden_dim: The size of the hidden layer outputs\n",
    "        :param dropout: dropout to add in between LSTM/GRU layers\n",
    "        \"\"\"\n",
    "        super(RNN, self).__init__()\n",
    "        # TODO: Implement function\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # embedding and LSTM layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                            dropout=dropout, batch_first=True)\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # linear and sigmoid layers\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "    \n",
    "    \n",
    "    def forward(self, nn_input, hidden):\n",
    "        \"\"\"\n",
    "        Forward propagation of the neural network\n",
    "        :param nn_input: The input to the neural network\n",
    "        :param hidden: The hidden state        \n",
    "        :return: Two Tensors, the output of the neural network and the latest hidden state\n",
    "        \"\"\"\n",
    "        # TODO: Implement function   \n",
    "        batch_size = nn_input.size(0)\n",
    "\n",
    "        # embeddings and lstm_out\n",
    "        embeds = self.embedding(nn_input)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "    \n",
    "        # stack up lstm outputs\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        # dropout and fully-connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        # sigmoid function\n",
    "        sig_out = self.sig(out)\n",
    "        \n",
    "        # reshape to be batch_size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1] # get last batch of labels\n",
    "        \n",
    "        # return one batch of output word scores and the hidden state\n",
    "        return sig_out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        '''\n",
    "        Initialize the hidden state of an LSTM/GRU\n",
    "        :param batch_size: The batch_size of the hidden state\n",
    "        :return: hidden state of dims (n_layers, batch_size, hidden_dim)\n",
    "        '''\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 50\n",
    "# sequence_length = 3\n",
    "# vocab_size = 20\n",
    "# output_size=20\n",
    "# embedding_dim=15\n",
    "# hidden_dim = 10\n",
    "# n_layers = 2\n",
    "\n",
    "# # create test RNN\n",
    "# # params: (vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "# # rnn = RNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "# rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=.5, batch_first=True)\n",
    "# print(rnn)\n",
    "\n",
    "# # create test input\n",
    "# a = np.random.randint(vocab_size, size=(batch_size, sequence_length))\n",
    "# #b = torch.LongTensor(a)\n",
    "# b = torch.from_numpy(a)\n",
    "# print('b:\\t', b.shape)\n",
    "# hidden = rnn.init_hidden(batch_size)\n",
    "# print('hidden:\\t', hidden[0].shape, hidden[1].shape)\n",
    "# output, hidden_out = rnn(b, hidden)\n",
    "# print('opt:\\t', output.shape)        # (batch_size, output_size)          # (50, 20)\n",
    "# print('hid_o:\\t', hidden_out[0].shape, hidden_out[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (TF1.x)BN and toy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5\n",
      "[2. 3.]\n",
      "[1.5 3.5]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1., 2.], [3., 4.]])\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(tf.reduce_mean(x)))  # 2.5, mean value of both axis after reduce dimension,equal sum()/num_elements\n",
    "    print(sess.run(tf.reduce_mean(x, 0)) ) # [2. 3.]\n",
    "    print(sess.run(tf.reduce_mean(x, 1)))  # [1.5 3.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_28:0\", shape=(5, 6), dtype=int32)\n",
      "[[30 29 28 27 26 25]\n",
      " [24 23 22 21 20 19]\n",
      " [18 17 16 15 14 13]\n",
      " [12 11 10  9  8  7]\n",
      " [ 6  5  4  3  2  1]]\n",
      "Tensor(\"ArgMax_10:0\", shape=(6,), dtype=int64)\n",
      "[0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "ten_lst, ten_int = tf.constant(np.array([i for i in range(30,0,-1)]).reshape([5,6])), tf.constant(1)\n",
    "with tf.Session() as sess:\n",
    "    print(ten_lst)\n",
    "    print(sess.run(ten_lst))\n",
    "    \n",
    "    ten_am = tf.argmax(ten_lst, axis=ten_int)   # Returns the index with the largest value across axes of a tensor\n",
    "    print(ten_am)\n",
    "    print(sess.run(ten_am))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "(7-5+ 2*4)/2+1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import ceil\n",
    "\n",
    "def get_size(inputs, f, s, state='valid'):\n",
    "    p = 0\n",
    "    if state=='valid':\n",
    "        p = 2*((f-1)/2)\n",
    "        print(p)\n",
    "    print(\"(%d-%d+ 2*%d)/%d+1)\"%(inputs, f, p, s))\n",
    "    return int((inputs\n",
    "            -f\n",
    "            + p\n",
    "           )/s+1)\n",
    "\n",
    "get_size(7, 5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "((7-1)*2 - 4 + 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_size(inputs, f, s, state='valid'): \n",
    "    p = 0\n",
    "    if state=='valid':\n",
    "        p = 2*((f-1)/2)\n",
    "        print(p)\n",
    "    print(\"((%d-1)*%d - 2*%d + %d)\"%(inputs, s, p, f))\n",
    "    return int(((inputs-1)*s - 2*p + f))\n",
    "                               \n",
    "get_size(7, 5, 2)  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((4-1)*2 - 0 + 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_size(4, 5, 2, 'same')  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 9)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.uniform(-0.5, 0.5, (64, 9)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
