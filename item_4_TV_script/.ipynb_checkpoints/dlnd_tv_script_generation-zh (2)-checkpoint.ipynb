{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成电视剧剧本\n",
    "\n",
    "在这个项目中，你将使用 RNN 创作你自己的[《辛普森一家》](https://zh.wikipedia.org/wiki/%E8%BE%9B%E6%99%AE%E6%A3%AE%E4%B8%80%E5%AE%B6)电视剧剧本。你将会用到《辛普森一家》第 27 季中部分剧本的[数据集](https://www.kaggle.com/wcukierski/the-simpsons-by-the-data)。你创建的神经网络将为一个在 [Moe 酒馆](https://simpsonswiki.com/wiki/Moe's_Tavern)中的场景生成一集新的剧本。\n",
    "\n",
    "## 获取数据\n",
    "我们早已为你提供了数据`./data/Seinfeld_Scripts.txt`。我们建议你打开文档来看看这个文档内容。\n",
    "\n",
    ">* 第一步，我们来读入文档，并看几段例子。\n",
    "* 然后，你需要定义并训练一个 RNN 网络来生成新的剧本！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# load in data\n",
    "import helper\n",
    "data_dir = './data/Seinfeld_Scripts.txt'\n",
    "text = helper.load_data(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索数据\n",
    "使用 `view_line_range` 来查阅数据的不同部分，这个部分会让你对整体数据有个基础的了解。你会发现，文档中全是小写字母，并且所有的对话都是使用 `\\n` 来分割的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Stats\n",
      "Roughly the number of unique words: 46367\n",
      "Number of lines: 109233\n",
      "Average number of words in each line: 5.544240293684143\n",
      "\n",
      "The lines 0 to 10:\n",
      "jerry: do you know what this is all about? do you know, why were here? to be out, this is out...and out is one of the single most enjoyable experiences of life. people...did you ever hear people talking about we should go out? this is what theyre talking about...this whole thing, were all out now, no one is home. not one person here is home, were all out! there are people trying to find us, they dont know where we are. (on an imaginary phone) did you ring?, i cant find him. where did he go? he didnt tell me where he was going. he must have gone out. you wanna go out you get ready, you pick out the clothes, right? you take the shower, you get all ready, get the cash, get your friends, the car, the spot, the reservation...then youre standing around, what do you do? you go we gotta be getting back. once youre out, you wanna get back! you wanna go to sleep, you wanna get up, you wanna go out again tomorrow, right? where ever you are in life, its my feeling, youve gotta go. \n",
      "\n",
      "jerry: (pointing at georges shirt) see, to me, that button is in the worst possible spot. the second button literally makes or breaks the shirt, look at it. its too high! its in no-mans-land. you look like you live with your mother. \n",
      "\n",
      "george: are you through? \n",
      "\n",
      "jerry: you do of course try on, when you buy? \n",
      "\n",
      "george: yes, it was purple, i liked it, i dont actually recall considering the buttons. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "view_line_range = (0, 10)\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "print('Dataset Stats')\n",
    "print('Roughly the number of unique words: {}'.format(len({word: None for word in text.split()})))\n",
    "\n",
    "lines = text.split('\\n')\n",
    "print('Number of lines: {}'.format(len(lines)))\n",
    "word_count_line = [len(line.split()) for line in lines]\n",
    "print('Average number of words in each line: {}'.format(np.average(word_count_line)))\n",
    "\n",
    "print()\n",
    "print('The lines {} to {}:'.format(*view_line_range))\n",
    "print('\\n'.join(text.split('\\n')[view_line_range[0]:view_line_range[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 实现预处理函数\n",
    "对数据集进行的第一个操作是预处理。请实现下面两个预处理函数：\n",
    "\n",
    "- 查询表\n",
    "- 标记符号\n",
    "\n",
    "### 查询表\n",
    "要创建词嵌入，你首先要将词语转换为 id。请在这个函数中创建两个字典：\n",
    "\n",
    "- 将词语转换为 id 的字典，我们称它为 `vocab_to_int`\n",
    "- 将 id 转换为词语的字典，我们称它为 `int_to_vocab`\n",
    "\n",
    "请在下面的元组中返回这些字典\n",
    " `(vocab_to_int, int_to_vocab)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "import problem_unittests as tests\n",
    "\n",
    "def create_lookup_tables(text):\n",
    "    \"\"\"\n",
    "    Create lookup tables for vocabulary\n",
    "    :param text: The text of tv scripts split into words\n",
    "    :return: A tuple of dicts (vocab_to_int, int_to_vocab)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    from collections import Counter\n",
    "\n",
    "    ## Build a dictionary that maps words to integers\n",
    "    counts = Counter(text)\n",
    "    vocab = sorted(counts, key=counts.get, reverse=True)            # sorted method param\"key\"\n",
    "    vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n",
    "    int_to_vocab = {v:k for k,v in vocab_to_int.items()}\n",
    "    # return tuple\n",
    "    return (vocab_to_int, int_to_vocab)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_create_lookup_tables(create_lookup_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 标记符号的字符串\n",
    "我们会使用空格当作分隔符，来将剧本分割为词语数组。然而，句号和感叹号等符号使得神经网络难以分辨“再见”和“再见！”之间的区别。\n",
    "\n",
    "实现函数 `token_lookup` 来返回一个字典，这个字典用于将 “!” 等符号标记为 “||Exclamation_Mark||” 形式。为下列符号创建一个字典，其中符号为标志，值为标记。\n",
    "\n",
    "- period ( . )\n",
    "- comma ( , )\n",
    "- quotation mark ( \" )\n",
    "- semicolon ( ; )\n",
    "- exclamation mark ( ! )\n",
    "- question mark ( ? )\n",
    "- left parenthesis ( ( )\n",
    "- right parenthesis ( ) )\n",
    "- dash ( -- )\n",
    "- return ( \\n )\n",
    "\n",
    "这个字典将用于标记符号并在其周围添加分隔符（空格）。这能将符号视作单独词汇分割开来，并使神经网络更轻松地预测下一个词汇。请确保你并没有使用容易与词汇混淆的标记。与其使用 “dash” 这样的标记，试试使用“||dash||”。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def token_lookup():\n",
    "    \"\"\"\n",
    "    Generate a dict to turn punctuation into a token.\n",
    "    :return: Tokenized dictionary where the key is the punctuation and the value is the token\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    token_dict = {'.': '||period||',\n",
    "                 ',': '||comma||',\n",
    "                 '\"': '||quotation_mark||',\n",
    "                 ';': '||semicolon||',\n",
    "                 '!': '||exclamation_mark||',\n",
    "                 '?': '||question_mark||',\n",
    "                 '(': '||left_parenthesis||',\n",
    "                 ')': '||right_parenthesis||',\n",
    "                 '-': '||dash||',\n",
    "                 '\\n': '||return||'}\n",
    "    return token_dict\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_tokenize(token_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理并保存所有数据\n",
    "运行以下代码将预处理所有数据，并将它们保存至文件。建议你查看`helpers.py` 文件中的 `preprocess_and_save_data` 代码来看这一步在做什么，但是你不需要修改`helpers.py`中的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# pre-process training data\n",
    "helper.preprocess_and_save_data(data_dir, token_lookup, create_lookup_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "这是你遇到的第一个检点。如果你想要回到这个 notebook，或需要重新打开 notebook，你都可以从这里开始。预处理的数据都已经保存完毕。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import helper\n",
    "import problem_unittests as tests\n",
    "\n",
    "int_text, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建神经网络\n",
    "在本节中，你会构建 RNN 中的必要 Module，以及 前向、后向函数。\n",
    "\n",
    "### 检查 GPU 访问权限"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found. Please use a GPU to train your neural network.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import torch\n",
    "\n",
    "# Check for a GPU\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if not train_on_gpu:\n",
    "    print('No GPU found. Please use a GPU to train your neural network.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输入\n",
    "让我们开始预处理输入数据。我们会使用 [TensorDataset](http://pytorch.org/docs/master/data.html#torch.utils.data.TensorDataset) 来为数据库提供一个数据格式；以及一个 [DataLoader](http://pytorch.org/docs/master/data.html#torch.utils.data.DataLoader), 该对象会实现 batching，shuffling 以及其他数据迭代功能。\n",
    "\n",
    "你可以通过传入 特征 和目标 tensors 来创建 TensorDataset，随后创建一个 DataLoader 。\n",
    "```\n",
    "data = TensorDataset(feature_tensors, target_tensors)\n",
    "data_loader = torch.utils.data.DataLoader(data, \n",
    "                                          batch_size=batch_size)\n",
    "```\n",
    "\n",
    "### Batching\n",
    " 通过 `TensorDataset` 和 `DataLoader` 类来实现  `batch_data` 函数来将 `words` 数据分成 `batch_size` 批次。\n",
    "\n",
    ">你可以使用 DataLoader 来分批 单词, 但是你可以自由设置 `feature_tensors` 和 `target_tensors` 的大小以及 `sequence_length`。\n",
    "\n",
    "比如，我们有如下输入:\n",
    "```\n",
    "words = [1, 2, 3, 4, 5, 6, 7]\n",
    "sequence_length = 4\n",
    "```\n",
    "\n",
    "你的第一个 `feature_tensor` 会包含:\n",
    "```\n",
    "[1, 2, 3, 4]\n",
    "```\n",
    "随后的 `target_tensor` 会是接下去的一个字符值:\n",
    "```\n",
    "5\n",
    "```\n",
    "那么，第二组的`feature_tensor`, `target_tensor` 则如下所示:\n",
    "```\n",
    "[2, 3, 4, 5]  # features\n",
    "6             # target\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 4], [2, 3, 4, 5], [3, 4, 5, 6]]\n",
      "[5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "words = [1, 2, 3, 4, 5, 6, 7]\n",
    "sequ_len = 4\n",
    "\n",
    "fea_list = [words[n:n+sequ_len] for n in range(0, len(words)-sequ_len)]\n",
    "tar_list = [words[n] for n in range(sequ_len, len(words))]\n",
    "\n",
    "print(fea_list)\n",
    "print(tar_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[3., 4., 5., 6.]]), tensor([7.])] \t torch.Size([1, 4]) torch.Size([1])\n",
      "[tensor([[1., 2., 3., 4.]]), tensor([5.])] \t torch.Size([1, 4]) torch.Size([1])\n",
      "[tensor([[2., 3., 4., 5.]]), tensor([6.])] \t torch.Size([1, 4]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "def batch_data(words, sequence_length, batch_size):\n",
    "    \"\"\"\n",
    "    Batch the neural network data using DataLoader\n",
    "    :param words: The word ids of the TV scripts\n",
    "    :param sequence_length: The sequence length of each batch\n",
    "    :param batch_size: The size of each batch; the number of sequences in a batch\n",
    "    :return: DataLoader with batched data\n",
    "    \"\"\"\n",
    "    # TODO: Implement function\n",
    "    feature_tensor = torch.Tensor([words[n:n+sequence_length] for n in range(0, len(words)-sequence_length)])\n",
    "    target_tensor = torch.Tensor([words[n] for n in range(sequence_length, len(words))])\n",
    "    \n",
    "    dataset = TensorDataset(feature_tensor, target_tensor)\n",
    "    \n",
    "    data_loader = DataLoader(dataset, shuffle=True, batch_size=batch_size)\n",
    "    # return a dataloader\n",
    "    return data_loader\n",
    "\n",
    "# there is no test for this function, but you are encouraged to create\n",
    "# print statements and tests of your own\n",
    "ws_lst = [1, 2, 3, 4, 5, 6, 7]\n",
    "seq_len = 4\n",
    "\n",
    "for data in batch_data(ws_lst, seq_len, 1):\n",
    "    print(data, '\\t', data[0].shape, data[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试你的 dataloader \n",
    "\n",
    "你需要改写下述代码来测试 batching 函数，改写后的代码会现在的比较类似。\n",
    "\n",
    "下面，我们生成了一些测试文本数据，并使用了一个你上面写 dataloader 。然后，我们会得到一些使用`sample_x`输入以及`sample_y`目标生成的文本。\n",
    "\n",
    "你的代码会返回如下结果(通常是不同的顺序，如果你 shuffle 了你的数据):\n",
    "\n",
    "```\n",
    "torch.Size([10, 5])\n",
    "tensor([[ 28,  29,  30,  31,  32],\n",
    "        [ 21,  22,  23,  24,  25],\n",
    "        [ 17,  18,  19,  20,  21],\n",
    "        [ 34,  35,  36,  37,  38],\n",
    "        [ 11,  12,  13,  14,  15],\n",
    "        [ 23,  24,  25,  26,  27],\n",
    "        [  6,   7,   8,   9,  10],\n",
    "        [ 38,  39,  40,  41,  42],\n",
    "        [ 25,  26,  27,  28,  29],\n",
    "        [  7,   8,   9,  10,  11]])\n",
    "\n",
    "torch.Size([10])\n",
    "tensor([ 33,  26,  22,  39,  16,  28,  11,  43,  30,  12])\n",
    "```\n",
    "\n",
    "### 大小\n",
    "你的 sample_x 应该是 `(batch_size, sequence_length)`的 大小 或者是(10, 5)， sample_y 应该是 一维的: batch_size (10)。\n",
    "\n",
    "### 值\n",
    "\n",
    "你应该也会发现 sample_y, 是 test_text 数据中的*下一个*值。因此，对于一个输入的序列 `[ 28,  29,  30,  31,  32]` ，它的结尾是 `32`, 那么其相应的输出应该是 `33`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 5])\n",
      "tensor([[ 2.,  3.,  4.,  5.,  6.],\n",
      "        [ 5.,  6.,  7.,  8.,  9.],\n",
      "        [ 4.,  5.,  6.,  7.,  8.],\n",
      "        [13., 14., 15., 16., 17.],\n",
      "        [ 1.,  2.,  3.,  4.,  5.],\n",
      "        [41., 42., 43., 44., 45.],\n",
      "        [27., 28., 29., 30., 31.],\n",
      "        [15., 16., 17., 18., 19.],\n",
      "        [ 8.,  9., 10., 11., 12.],\n",
      "        [11., 12., 13., 14., 15.]])\n",
      "\n",
      "torch.Size([10])\n",
      "tensor([ 7., 10.,  9., 18.,  6., 46., 32., 20., 13., 16.])\n"
     ]
    }
   ],
   "source": [
    "# test dataloader\n",
    "\n",
    "test_text = range(50)\n",
    "t_loader = batch_data(test_text, sequence_length=5, batch_size=10)\n",
    "\n",
    "data_iter = iter(t_loader)\n",
    "sample_x, sample_y = data_iter.next()\n",
    "\n",
    "print(sample_x.shape)\n",
    "print(sample_x)\n",
    "print()\n",
    "print(sample_y.shape)\n",
    "print(sample_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 构建神经网络\n",
    "使用 PyTorch [Module class](http://pytorch.org/docs/master/nn.html#torch.nn.Module) 来实现一个 循环神经网络 RNN。你需要选择一个 GRU 或者 一个 LSTM。为了完成循环神经网络。为了实现 RNN，你需要实现以下类:\n",
    " - `__init__` - 初始化函数\n",
    " - `init_hidden` - LSTM/GRU 隐藏组昂泰的初始化函数\n",
    " - `forward` - 前向传播函数\n",
    " \n",
    "初始化函数需要创建神经网络的层数，并保存到类。前向传播函数会使用这些网络来进行前向传播，并生成输出和隐藏状态。\n",
    "\n",
    "在该流程完成后，**该模型的输出是 *最后的* 文字分数结果** 对于每段输入的文字序列，我们只需要输出一个单词，也就是，下一个单词。 \n",
    "\n",
    "### 提示\n",
    "\n",
    "1. 确保 lstm 的输出会链接一个 全链接层，你可以参考如下代码 `lstm_output = lstm_output.contiguous().view(-1, self.hidden_dim)`\n",
    "2. 你可以通过 reshape 模型最后输出的全链接层，来得到最终的文字分数:\n",
    "\n",
    "```\n",
    "# reshape into (batch_size, seq_length, output_size)\n",
    "output = output.view(batch_size, -1, self.output_size)\n",
    "# get last batch\n",
    "out = output[:, -1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, dropout=0.5):\n",
    "        super(RNN, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.output_size = output_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.embedding = nn.Embedding(num_embeddings=self.vocab_size, \n",
    "                                      embedding_dim=self.embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size=self.embedding_dim, \n",
    "                            hidden_size=self.hidden_dim, \n",
    "                            dropout=self.dropout,\n",
    "                            num_layers=self.n_layers,\n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(self.hidden_dim, self.output_size)\n",
    "    \n",
    "    \n",
    "    def forward(self, nn_input, hidden):\n",
    "        nn_input = nn_input.long()\n",
    "        batch_size, _ = nn_input.size() # batch first\n",
    "        embedding_input = self.embedding(nn_input)\n",
    "        nn_output, hidden = self.lstm(embedding_input, hidden)\n",
    "        nn_output = nn_output.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        output = self.fc(nn_output)\n",
    "        output = output.view(batch_size, -1, self.output_size)\n",
    "        output = output[:, -1]\n",
    "\n",
    "        # return one batch of output word scores and the hidden state\n",
    "        return output, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        # initialize hidden state with zero weights, and move to GPU if available\n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        return hidden\n",
    "    \n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_rnn(RNN, train_on_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义前向及后向传播\n",
    "\n",
    "通过你实现的 RNN 类来进行前向及后项传播。你可以在训练循环中，不断地调用如下代码来实现：\n",
    "```\n",
    "loss = forward_back_prop(decoder, decoder_optimizer, criterion, inp, target)\n",
    "```\n",
    "\n",
    "函数中需要返回一个批次以及其隐藏状态的loss均值，你可以调用一个函数`RNN(inp, hidden)`来实现。记得，你可以通过调用`loss.item()` 来计算得到该loss。\n",
    "\n",
    "**如果使用 GPU，你需要将你的数据存到 GPU 的设备上。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def forward_back_prop(rnn, optimizer, criterion, inp, target, hidden):\n",
    "    \n",
    "    # move data to GPU, if available\n",
    "    if train_on_gpu:\n",
    "        inp, target = inp.cuda(), target.cuda()\n",
    "    \n",
    "    hidden = tuple([each.data for each in hidden])\n",
    "    \n",
    "    # perform backpropagation and optimization\n",
    "    rnn.zero_grad()\n",
    "    \n",
    "    output, hidden = rnn(inp, hidden)\n",
    "    loss = criterion(output.squeeze(), target.long())\n",
    "    loss.backward()\n",
    "    \n",
    "    clip = 5.0 # gradient clipping\n",
    "    nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n",
    "    optimizer.step()\n",
    "    \n",
    "    # return the loss over a batch and the hidden state produced by our model\n",
    "    return loss.item(), hidden\n",
    "\n",
    "\n",
    "\n",
    "# Note that these tests aren't completely extensive.\n",
    "# they are here to act as general checks on the expected outputs of your functions\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_forward_back_prop(RNN, forward_back_prop, train_on_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络训练\n",
    "\n",
    "神经网络结构完成以及数据准备完后，我们可以开始训练网络了。\n",
    "\n",
    "### 训练循环\n",
    "\n",
    "训练循环是通过 `train_decoder` 函数实现的。该函数将进行 epochs 次数的训练。模型的训练成果会在一定批次的训练后，被打印出来。这个“一定批次”可以通过`show_every_n_batches` 来设置。你会在下一节设置这个参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "from workspace_utils import keep_awake\n",
    "\n",
    "def train_rnn(rnn, batch_size, optimizer, criterion, n_epochs, show_every_n_batches=100):\n",
    "    batch_losses = []\n",
    "    \n",
    "    rnn.train()\n",
    "\n",
    "    print(\"Training for %d epoch(s)...\" % n_epochs)\n",
    "#     for epoch_i in range(1, n_epochs + 1):\n",
    "    for epoch_i in keep_awake(range(1, n_epochs + 1)):\n",
    "        \n",
    "        # initialize hidden state\n",
    "        hidden = rnn.init_hidden(batch_size)\n",
    "        \n",
    "        for batch_i, (inputs, labels) in enumerate(train_loader, 1):\n",
    "            \n",
    "            # make sure you iterate over completely full batches, only\n",
    "            n_batches = len(train_loader.dataset)//batch_size\n",
    "            if(batch_i > n_batches):\n",
    "                break\n",
    "            \n",
    "            # forward, back prop\n",
    "            loss, hidden = forward_back_prop(rnn, optimizer, criterion, inputs, labels, hidden)          \n",
    "            # record loss\n",
    "            batch_losses.append(loss)\n",
    "\n",
    "            # printing loss stats\n",
    "            if batch_i % show_every_n_batches == 0:\n",
    "                print('Epoch: {:>4}/{:<4}  Batch:{:>4}/{:<4}  Loss: {}'.format(\n",
    "                    epoch_i, n_epochs, batch_i, n_batches, np.average(batch_losses)))\n",
    "                batch_losses = []\n",
    "\n",
    "    # returns a trained rnn\n",
    "    return rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 超参数\n",
    "\n",
    "设置并训练以下超参数:\n",
    "-  `sequence_length`，序列长度 \n",
    "-  `batch_size`，分批大小\n",
    "-  `num_epochs`，循环次数\n",
    "-  `learning_rate`，Adam优化器的学习率\n",
    "-  `vocab_size`，唯一标示词汇的数量\n",
    "-  `output_size`，模型输出的大小 \n",
    "-  `embedding_dim`，词嵌入的维度，小于 vocab_size\n",
    "-  `hidden_dim`， 隐藏层维度\n",
    "-  `n_layers`， RNN的层数\n",
    "-  `show_every_n_batches`，打印结果的频次\n",
    "\n",
    "如果模型没有获得你预期的结果，调整 `RNN`类中的上述参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Data params\n",
    "# Sequence Length\n",
    "# set the hyperparamaters\n",
    "sequence_length = 131        # number of words in a sequence; total words: 892,110: factors are 30, 131, 227\n",
    "batch_size = 128\n",
    "train_loader = batch_data(int_text, sequence_length, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "# set the training parameters\n",
    "num_epochs = 3\n",
    "learning_rate = 0.001       # 0.01 is worse\n",
    "\n",
    "# set the model parameters\n",
    "vocab_size = len(vocab_to_int)\n",
    "output_size = vocab_size\n",
    "embedding_dim = 300        # 128 is worse\n",
    "hidden_dim = 512\n",
    "n_layers = 2\n",
    "\n",
    "# show stats for every n number of batches\n",
    "show_every_n_batches = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练\n",
    "下一节，通过预处理数据来训练神经网络。如果你的loss结果不好，可以通过调整超参数来修正。通常情况下，大的隐藏层及层数会带来比较好的效果，但同时也会消耗较长的时间来训练。\n",
    "> **你应该努力得到一个低于3.5的loss** \n",
    "\n",
    "你也可以试试不同的序列长度，该参数表明模型学习的范围大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 3 epoch(s)...\n",
      "Epoch:    1/3     Batch:   5/6968  Loss: 9.750128173828125\n",
      "\n",
      "Epoch:    1/3     Batch:  10/6968  Loss: 7.587319278717041\n",
      "\n",
      "Epoch:    1/3     Batch:  15/6968  Loss: 6.27403039932251\n",
      "\n",
      "Epoch:    1/3     Batch:  20/6968  Loss: 6.382200813293457\n",
      "\n",
      "Epoch:    1/3     Batch:  25/6968  Loss: 6.394595146179199\n",
      "\n",
      "Epoch:    1/3     Batch:  30/6968  Loss: 6.236073398590088\n",
      "\n",
      "Epoch:    1/3     Batch:  35/6968  Loss: 6.104263877868652\n",
      "\n",
      "Epoch:    1/3     Batch:  40/6968  Loss: 6.022180652618408\n",
      "\n",
      "Epoch:    1/3     Batch:  45/6968  Loss: 6.098670864105225\n",
      "\n",
      "Epoch:    1/3     Batch:  50/6968  Loss: 6.010707092285156\n",
      "\n",
      "Epoch:    1/3     Batch:  55/6968  Loss: 5.996320343017578\n",
      "\n",
      "Epoch:    1/3     Batch:  60/6968  Loss: 5.838743114471436\n",
      "\n",
      "Epoch:    1/3     Batch:  65/6968  Loss: 5.976468849182129\n",
      "\n",
      "Epoch:    1/3     Batch:  70/6968  Loss: 5.696450710296631\n",
      "\n",
      "Epoch:    1/3     Batch:  75/6968  Loss: 5.736187076568603\n",
      "\n",
      "Epoch:    1/3     Batch:  80/6968  Loss: 5.275537395477295\n",
      "\n",
      "Epoch:    1/3     Batch:  85/6968  Loss: 5.680975818634034\n",
      "\n",
      "Epoch:    1/3     Batch:  90/6968  Loss: 5.540169048309326\n",
      "\n",
      "Epoch:    1/3     Batch:  95/6968  Loss: 5.718049335479736\n",
      "\n",
      "Epoch:    1/3     Batch: 100/6968  Loss: 5.778532981872559\n",
      "\n",
      "Epoch:    1/3     Batch: 105/6968  Loss: 5.644120979309082\n",
      "\n",
      "Epoch:    1/3     Batch: 110/6968  Loss: 5.422787284851074\n",
      "\n",
      "Epoch:    1/3     Batch: 115/6968  Loss: 5.440309238433838\n",
      "\n",
      "Epoch:    1/3     Batch: 120/6968  Loss: 5.401534557342529\n",
      "\n",
      "Epoch:    1/3     Batch: 125/6968  Loss: 5.379133701324463\n",
      "\n",
      "Epoch:    1/3     Batch: 130/6968  Loss: 5.421982097625732\n",
      "\n",
      "Epoch:    1/3     Batch: 135/6968  Loss: 5.2608263969421385\n",
      "\n",
      "Epoch:    1/3     Batch: 140/6968  Loss: 5.309752082824707\n",
      "\n",
      "Epoch:    1/3     Batch: 145/6968  Loss: 5.362815570831299\n",
      "\n",
      "Epoch:    1/3     Batch: 150/6968  Loss: 5.6154707908630375\n",
      "\n",
      "Epoch:    1/3     Batch: 155/6968  Loss: 5.152061939239502\n",
      "\n",
      "Epoch:    1/3     Batch: 160/6968  Loss: 5.155161380767822\n",
      "\n",
      "Epoch:    1/3     Batch: 165/6968  Loss: 5.35765495300293\n",
      "\n",
      "Epoch:    1/3     Batch: 170/6968  Loss: 5.440842247009277\n",
      "\n",
      "Epoch:    1/3     Batch: 175/6968  Loss: 5.345183372497559\n",
      "\n",
      "Epoch:    1/3     Batch: 180/6968  Loss: 5.292539024353028\n",
      "\n",
      "Epoch:    1/3     Batch: 185/6968  Loss: 5.279997634887695\n",
      "\n",
      "Epoch:    1/3     Batch: 190/6968  Loss: 5.233267879486084\n",
      "\n",
      "Epoch:    1/3     Batch: 195/6968  Loss: 5.121058464050293\n",
      "\n",
      "Epoch:    1/3     Batch: 200/6968  Loss: 5.237169551849365\n",
      "\n",
      "Epoch:    1/3     Batch: 205/6968  Loss: 4.940316772460937\n",
      "\n",
      "Epoch:    1/3     Batch: 210/6968  Loss: 5.124304008483887\n",
      "\n",
      "Epoch:    1/3     Batch: 215/6968  Loss: 5.177223873138428\n",
      "\n",
      "Epoch:    1/3     Batch: 220/6968  Loss: 5.397690391540527\n",
      "\n",
      "Epoch:    1/3     Batch: 225/6968  Loss: 5.211797523498535\n",
      "\n",
      "Epoch:    1/3     Batch: 230/6968  Loss: 5.2788127899169925\n",
      "\n",
      "Epoch:    1/3     Batch: 235/6968  Loss: 5.315092658996582\n",
      "\n",
      "Epoch:    1/3     Batch: 240/6968  Loss: 5.320226955413818\n",
      "\n",
      "Epoch:    1/3     Batch: 245/6968  Loss: 5.382871150970459\n",
      "\n",
      "Epoch:    1/3     Batch: 250/6968  Loss: 5.149456310272217\n",
      "\n",
      "Epoch:    1/3     Batch: 255/6968  Loss: 5.056778240203857\n",
      "\n",
      "Epoch:    1/3     Batch: 260/6968  Loss: 5.173492336273194\n",
      "\n",
      "Epoch:    1/3     Batch: 265/6968  Loss: 5.156652641296387\n",
      "\n",
      "Epoch:    1/3     Batch: 270/6968  Loss: 5.298219108581543\n",
      "\n",
      "Epoch:    1/3     Batch: 275/6968  Loss: 5.2249000549316404\n",
      "\n",
      "Epoch:    1/3     Batch: 280/6968  Loss: 5.086783695220947\n",
      "\n",
      "Epoch:    1/3     Batch: 285/6968  Loss: 5.2540678024292\n",
      "\n",
      "Epoch:    1/3     Batch: 290/6968  Loss: 5.203664684295655\n",
      "\n",
      "Epoch:    1/3     Batch: 295/6968  Loss: 5.099918174743652\n",
      "\n",
      "Epoch:    1/3     Batch: 300/6968  Loss: 4.817231464385986\n",
      "\n",
      "Epoch:    1/3     Batch: 305/6968  Loss: 4.99855260848999\n",
      "\n",
      "Epoch:    1/3     Batch: 310/6968  Loss: 5.227304363250733\n",
      "\n",
      "Epoch:    1/3     Batch: 315/6968  Loss: 5.175643825531006\n",
      "\n",
      "Epoch:    1/3     Batch: 320/6968  Loss: 5.236608791351318\n",
      "\n",
      "Epoch:    1/3     Batch: 325/6968  Loss: 5.202243137359619\n",
      "\n",
      "Epoch:    1/3     Batch: 330/6968  Loss: 5.059982395172119\n",
      "\n",
      "Epoch:    1/3     Batch: 335/6968  Loss: 5.109754276275635\n",
      "\n",
      "Epoch:    1/3     Batch: 340/6968  Loss: 5.0011794090271\n",
      "\n",
      "Epoch:    1/3     Batch: 345/6968  Loss: 5.030645751953125\n",
      "\n",
      "Epoch:    1/3     Batch: 350/6968  Loss: 5.201321029663086\n",
      "\n",
      "Epoch:    1/3     Batch: 355/6968  Loss: 4.77671480178833\n",
      "\n",
      "Epoch:    1/3     Batch: 360/6968  Loss: 5.152935409545899\n",
      "\n",
      "Epoch:    1/3     Batch: 365/6968  Loss: 5.065126132965088\n",
      "\n",
      "Epoch:    1/3     Batch: 370/6968  Loss: 4.957786941528321\n",
      "\n",
      "Epoch:    1/3     Batch: 375/6968  Loss: 5.111560726165772\n",
      "\n",
      "Epoch:    1/3     Batch: 380/6968  Loss: 4.886110782623291\n",
      "\n",
      "Epoch:    1/3     Batch: 385/6968  Loss: 5.031745529174804\n",
      "\n",
      "Epoch:    1/3     Batch: 390/6968  Loss: 4.756417942047119\n",
      "\n",
      "Epoch:    1/3     Batch: 395/6968  Loss: 5.156128597259522\n",
      "\n",
      "Epoch:    1/3     Batch: 400/6968  Loss: 4.823983955383301\n",
      "\n",
      "Epoch:    1/3     Batch: 405/6968  Loss: 5.059776496887207\n",
      "\n",
      "Epoch:    1/3     Batch: 410/6968  Loss: 5.249338626861572\n",
      "\n",
      "Epoch:    1/3     Batch: 415/6968  Loss: 5.158122730255127\n",
      "\n",
      "Epoch:    1/3     Batch: 420/6968  Loss: 4.980728244781494\n",
      "\n",
      "Epoch:    1/3     Batch: 425/6968  Loss: 4.9503655433654785\n",
      "\n",
      "Epoch:    1/3     Batch: 430/6968  Loss: 4.79356279373169\n",
      "\n",
      "Epoch:    1/3     Batch: 435/6968  Loss: 4.917339229583741\n",
      "\n",
      "Epoch:    1/3     Batch: 440/6968  Loss: 4.963007164001465\n",
      "\n",
      "Epoch:    1/3     Batch: 445/6968  Loss: 4.849606323242187\n",
      "\n",
      "Epoch:    1/3     Batch: 450/6968  Loss: 5.143941211700439\n",
      "\n",
      "Epoch:    1/3     Batch: 455/6968  Loss: 4.962843227386474\n",
      "\n",
      "Epoch:    1/3     Batch: 460/6968  Loss: 4.806574821472168\n",
      "\n",
      "Epoch:    1/3     Batch: 465/6968  Loss: 4.809088706970215\n",
      "\n",
      "Epoch:    1/3     Batch: 470/6968  Loss: 4.91211576461792\n",
      "\n",
      "Epoch:    1/3     Batch: 475/6968  Loss: 5.0900373458862305\n",
      "\n",
      "Epoch:    1/3     Batch: 480/6968  Loss: 4.773991394042969\n",
      "\n",
      "Epoch:    1/3     Batch: 485/6968  Loss: 4.863422870635986\n",
      "\n",
      "Epoch:    1/3     Batch: 490/6968  Loss: 5.020481300354004\n",
      "\n",
      "Epoch:    1/3     Batch: 495/6968  Loss: 4.952882480621338\n",
      "\n",
      "Epoch:    1/3     Batch: 500/6968  Loss: 4.863512706756592\n",
      "\n",
      "Epoch:    1/3     Batch: 505/6968  Loss: 5.132748413085937\n",
      "\n",
      "Epoch:    1/3     Batch: 510/6968  Loss: 4.933696460723877\n",
      "\n",
      "Epoch:    1/3     Batch: 515/6968  Loss: 5.120452880859375\n",
      "\n",
      "Epoch:    1/3     Batch: 520/6968  Loss: 4.926198291778564\n",
      "\n",
      "Epoch:    1/3     Batch: 525/6968  Loss: 4.774826431274414\n",
      "\n",
      "Epoch:    1/3     Batch: 530/6968  Loss: 4.899876499176026\n",
      "\n",
      "Epoch:    1/3     Batch: 535/6968  Loss: 4.797694110870362\n",
      "\n",
      "Epoch:    1/3     Batch: 540/6968  Loss: 4.926697731018066\n",
      "\n",
      "Epoch:    1/3     Batch: 545/6968  Loss: 4.83276596069336\n",
      "\n",
      "Epoch:    1/3     Batch: 550/6968  Loss: 4.609684658050537\n",
      "\n",
      "Epoch:    1/3     Batch: 555/6968  Loss: 4.964363098144531\n",
      "\n",
      "Epoch:    1/3     Batch: 560/6968  Loss: 5.022169589996338\n",
      "\n",
      "Epoch:    1/3     Batch: 565/6968  Loss: 4.732285785675049\n",
      "\n",
      "Epoch:    1/3     Batch: 570/6968  Loss: 4.756827354431152\n",
      "\n",
      "Epoch:    1/3     Batch: 575/6968  Loss: 4.727940368652344\n",
      "\n",
      "Epoch:    1/3     Batch: 580/6968  Loss: 4.948253440856933\n",
      "\n",
      "Epoch:    1/3     Batch: 585/6968  Loss: 4.7780835151672365\n",
      "\n",
      "Epoch:    1/3     Batch: 590/6968  Loss: 4.675056743621826\n",
      "\n",
      "Epoch:    1/3     Batch: 595/6968  Loss: 4.699673461914062\n",
      "\n",
      "Epoch:    1/3     Batch: 600/6968  Loss: 4.919089031219483\n",
      "\n",
      "Epoch:    1/3     Batch: 605/6968  Loss: 4.890504646301269\n",
      "\n",
      "Epoch:    1/3     Batch: 610/6968  Loss: 4.840717124938965\n",
      "\n",
      "Epoch:    1/3     Batch: 615/6968  Loss: 4.785198593139649\n",
      "\n",
      "Epoch:    1/3     Batch: 620/6968  Loss: 4.7878459930419925\n",
      "\n",
      "Epoch:    1/3     Batch: 625/6968  Loss: 4.982426452636719\n",
      "\n",
      "Epoch:    1/3     Batch: 630/6968  Loss: 4.864188289642334\n",
      "\n",
      "Epoch:    1/3     Batch: 635/6968  Loss: 4.634480953216553\n",
      "\n",
      "Epoch:    1/3     Batch: 640/6968  Loss: 4.903260612487793\n",
      "\n",
      "Epoch:    1/3     Batch: 645/6968  Loss: 4.8414027214050295\n",
      "\n",
      "Epoch:    1/3     Batch: 650/6968  Loss: 4.8798730850219725\n",
      "\n",
      "Epoch:    1/3     Batch: 655/6968  Loss: 4.851053142547608\n",
      "\n",
      "Epoch:    1/3     Batch: 660/6968  Loss: 4.79002571105957\n",
      "\n",
      "Epoch:    1/3     Batch: 665/6968  Loss: 4.641717147827149\n",
      "\n",
      "Epoch:    1/3     Batch: 670/6968  Loss: 4.750352573394776\n",
      "\n",
      "Epoch:    1/3     Batch: 675/6968  Loss: 4.850431156158447\n",
      "\n",
      "Epoch:    1/3     Batch: 680/6968  Loss: 4.699352169036866\n",
      "\n",
      "Epoch:    1/3     Batch: 685/6968  Loss: 4.526249790191651\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    1/3     Batch: 690/6968  Loss: 4.848678016662598\n",
      "\n",
      "Epoch:    1/3     Batch: 695/6968  Loss: 4.9819238662719725\n",
      "\n",
      "Epoch:    1/3     Batch: 700/6968  Loss: 4.903989315032959\n",
      "\n",
      "Epoch:    1/3     Batch: 705/6968  Loss: 4.534520816802979\n",
      "\n",
      "Epoch:    1/3     Batch: 710/6968  Loss: 4.759167289733886\n",
      "\n",
      "Epoch:    1/3     Batch: 715/6968  Loss: 4.97975492477417\n",
      "\n",
      "Epoch:    1/3     Batch: 720/6968  Loss: 4.754351711273193\n",
      "\n",
      "Epoch:    1/3     Batch: 725/6968  Loss: 4.706702136993409\n",
      "\n",
      "Epoch:    1/3     Batch: 730/6968  Loss: 4.698509693145752\n",
      "\n",
      "Epoch:    1/3     Batch: 735/6968  Loss: 4.676018619537354\n",
      "\n",
      "Epoch:    1/3     Batch: 740/6968  Loss: 4.763796997070313\n",
      "\n",
      "Epoch:    1/3     Batch: 745/6968  Loss: 4.647189903259277\n",
      "\n",
      "Epoch:    1/3     Batch: 750/6968  Loss: 4.9056438446044925\n",
      "\n",
      "Epoch:    1/3     Batch: 755/6968  Loss: 4.8195648193359375\n",
      "\n",
      "Epoch:    1/3     Batch: 760/6968  Loss: 4.612755298614502\n",
      "\n",
      "Epoch:    1/3     Batch: 765/6968  Loss: 4.685379600524902\n",
      "\n",
      "Epoch:    1/3     Batch: 770/6968  Loss: 4.889772701263428\n",
      "\n",
      "Epoch:    1/3     Batch: 775/6968  Loss: 4.744906902313232\n",
      "\n",
      "Epoch:    1/3     Batch: 780/6968  Loss: 4.750149440765381\n",
      "\n",
      "Epoch:    1/3     Batch: 785/6968  Loss: 4.837139701843261\n",
      "\n",
      "Epoch:    1/3     Batch: 790/6968  Loss: 4.613916873931885\n",
      "\n",
      "Epoch:    1/3     Batch: 795/6968  Loss: 4.655515861511231\n",
      "\n",
      "Epoch:    1/3     Batch: 800/6968  Loss: 4.791832542419433\n",
      "\n",
      "Epoch:    1/3     Batch: 805/6968  Loss: 4.463043594360352\n",
      "\n",
      "Epoch:    1/3     Batch: 810/6968  Loss: 4.747757339477539\n",
      "\n",
      "Epoch:    1/3     Batch: 815/6968  Loss: 4.65513162612915\n",
      "\n",
      "Epoch:    1/3     Batch: 820/6968  Loss: 4.722323226928711\n",
      "\n",
      "Epoch:    1/3     Batch: 825/6968  Loss: 4.690341472625732\n",
      "\n",
      "Epoch:    1/3     Batch: 830/6968  Loss: 4.506390523910523\n",
      "\n",
      "Epoch:    1/3     Batch: 835/6968  Loss: 4.668068885803223\n",
      "\n",
      "Epoch:    1/3     Batch: 840/6968  Loss: 4.721821594238281\n",
      "\n",
      "Epoch:    1/3     Batch: 845/6968  Loss: 4.828873157501221\n",
      "\n",
      "Epoch:    1/3     Batch: 850/6968  Loss: 4.992566967010498\n",
      "\n",
      "Epoch:    1/3     Batch: 855/6968  Loss: 4.903077411651611\n",
      "\n",
      "Epoch:    1/3     Batch: 860/6968  Loss: 4.562736320495605\n",
      "\n",
      "Epoch:    1/3     Batch: 865/6968  Loss: 4.792805957794189\n",
      "\n",
      "Epoch:    1/3     Batch: 870/6968  Loss: 4.708815574645996\n",
      "\n",
      "Epoch:    1/3     Batch: 875/6968  Loss: 4.593480777740479\n",
      "\n",
      "Epoch:    1/3     Batch: 880/6968  Loss: 4.688701343536377\n",
      "\n",
      "Epoch:    1/3     Batch: 885/6968  Loss: 4.699550819396973\n",
      "\n",
      "Epoch:    1/3     Batch: 890/6968  Loss: 4.637645626068116\n",
      "\n",
      "Epoch:    1/3     Batch: 895/6968  Loss: 4.369801998138428\n",
      "\n",
      "Epoch:    1/3     Batch: 900/6968  Loss: 4.682023906707764\n",
      "\n",
      "Epoch:    1/3     Batch: 905/6968  Loss: 4.732181549072266\n",
      "\n",
      "Epoch:    1/3     Batch: 910/6968  Loss: 4.6033354759216305\n",
      "\n",
      "Epoch:    1/3     Batch: 915/6968  Loss: 4.633442306518555\n",
      "\n",
      "Epoch:    1/3     Batch: 920/6968  Loss: 4.553624248504638\n",
      "\n",
      "Epoch:    1/3     Batch: 925/6968  Loss: 4.622634506225586\n",
      "\n",
      "Epoch:    1/3     Batch: 930/6968  Loss: 4.628456783294678\n",
      "\n",
      "Epoch:    1/3     Batch: 935/6968  Loss: 4.5454669952392575\n",
      "\n",
      "Epoch:    1/3     Batch: 940/6968  Loss: 4.636597061157227\n",
      "\n",
      "Epoch:    1/3     Batch: 945/6968  Loss: 4.502985286712646\n",
      "\n",
      "Epoch:    1/3     Batch: 950/6968  Loss: 4.691935443878174\n",
      "\n",
      "Epoch:    1/3     Batch: 955/6968  Loss: 4.610521507263184\n",
      "\n",
      "Epoch:    1/3     Batch: 960/6968  Loss: 4.410991907119751\n",
      "\n",
      "Epoch:    1/3     Batch: 965/6968  Loss: 4.661038780212403\n",
      "\n",
      "Epoch:    1/3     Batch: 970/6968  Loss: 4.3019743919372555\n",
      "\n",
      "Epoch:    1/3     Batch: 975/6968  Loss: 4.758837127685547\n",
      "\n",
      "Epoch:    1/3     Batch: 980/6968  Loss: 4.6327136039733885\n",
      "\n",
      "Epoch:    1/3     Batch: 985/6968  Loss: 4.74949426651001\n",
      "\n",
      "Epoch:    1/3     Batch: 990/6968  Loss: 4.426281547546386\n",
      "\n",
      "Epoch:    1/3     Batch: 995/6968  Loss: 4.86012487411499\n",
      "\n",
      "Epoch:    1/3     Batch:1000/6968  Loss: 4.661612129211425\n",
      "\n",
      "Epoch:    1/3     Batch:1005/6968  Loss: 4.628987789154053\n",
      "\n",
      "Epoch:    1/3     Batch:1010/6968  Loss: 4.3001429557800295\n",
      "\n",
      "Epoch:    1/3     Batch:1015/6968  Loss: 4.837167263031006\n",
      "\n",
      "Epoch:    1/3     Batch:1020/6968  Loss: 4.632686519622803\n",
      "\n",
      "Epoch:    1/3     Batch:1025/6968  Loss: 4.579188251495362\n",
      "\n",
      "Epoch:    1/3     Batch:1030/6968  Loss: 4.563564968109131\n",
      "\n",
      "Epoch:    1/3     Batch:1035/6968  Loss: 4.6300126075744625\n",
      "\n",
      "Epoch:    1/3     Batch:1040/6968  Loss: 4.6512809753417965\n",
      "\n",
      "Epoch:    1/3     Batch:1045/6968  Loss: 4.671288394927979\n",
      "\n",
      "Epoch:    1/3     Batch:1050/6968  Loss: 4.460823917388916\n",
      "\n",
      "Epoch:    1/3     Batch:1055/6968  Loss: 4.747821235656739\n",
      "\n",
      "Epoch:    1/3     Batch:1060/6968  Loss: 4.300530099868775\n",
      "\n",
      "Epoch:    1/3     Batch:1065/6968  Loss: 4.49251708984375\n",
      "\n",
      "Epoch:    1/3     Batch:1070/6968  Loss: 4.3675398349761965\n",
      "\n",
      "Epoch:    1/3     Batch:1075/6968  Loss: 4.637915706634521\n",
      "\n",
      "Epoch:    1/3     Batch:1080/6968  Loss: 4.463059616088867\n",
      "\n",
      "Epoch:    1/3     Batch:1085/6968  Loss: 4.526980400085449\n",
      "\n",
      "Epoch:    1/3     Batch:1090/6968  Loss: 4.488797283172607\n",
      "\n",
      "Epoch:    1/3     Batch:1095/6968  Loss: 4.606516933441162\n",
      "\n",
      "Epoch:    1/3     Batch:1100/6968  Loss: 4.564334583282471\n",
      "\n",
      "Epoch:    1/3     Batch:1105/6968  Loss: 4.688960170745849\n",
      "\n",
      "Epoch:    1/3     Batch:1110/6968  Loss: 4.377244377136231\n",
      "\n",
      "Epoch:    1/3     Batch:1115/6968  Loss: 4.4506940841674805\n",
      "\n",
      "Epoch:    1/3     Batch:1120/6968  Loss: 4.338824367523193\n",
      "\n",
      "Epoch:    1/3     Batch:1125/6968  Loss: 4.929047393798828\n",
      "\n",
      "Epoch:    1/3     Batch:1130/6968  Loss: 4.668771457672119\n",
      "\n",
      "Epoch:    1/3     Batch:1135/6968  Loss: 4.522837734222412\n",
      "\n",
      "Epoch:    1/3     Batch:1140/6968  Loss: 4.509209156036377\n",
      "\n",
      "Epoch:    1/3     Batch:1145/6968  Loss: 4.482801818847657\n",
      "\n",
      "Epoch:    1/3     Batch:1150/6968  Loss: 4.622485733032226\n",
      "\n",
      "Epoch:    1/3     Batch:1155/6968  Loss: 4.8201264381408695\n",
      "\n",
      "Epoch:    1/3     Batch:1160/6968  Loss: 4.327554321289062\n",
      "\n",
      "Epoch:    1/3     Batch:1165/6968  Loss: 4.64321813583374\n",
      "\n",
      "Epoch:    1/3     Batch:1170/6968  Loss: 4.579875659942627\n",
      "\n",
      "Epoch:    1/3     Batch:1175/6968  Loss: 4.738707160949707\n",
      "\n",
      "Epoch:    1/3     Batch:1180/6968  Loss: 4.502294921875\n",
      "\n",
      "Epoch:    1/3     Batch:1185/6968  Loss: 4.67742691040039\n",
      "\n",
      "Epoch:    1/3     Batch:1190/6968  Loss: 4.451070880889892\n",
      "\n",
      "Epoch:    1/3     Batch:1195/6968  Loss: 4.323656272888184\n",
      "\n",
      "Epoch:    1/3     Batch:1200/6968  Loss: 4.526631641387939\n",
      "\n",
      "Epoch:    1/3     Batch:1205/6968  Loss: 4.5407287120819095\n",
      "\n",
      "Epoch:    1/3     Batch:1210/6968  Loss: 4.343169212341309\n",
      "\n",
      "Epoch:    1/3     Batch:1215/6968  Loss: 4.820063972473145\n",
      "\n",
      "Epoch:    1/3     Batch:1220/6968  Loss: 4.301026248931885\n",
      "\n",
      "Epoch:    1/3     Batch:1225/6968  Loss: 4.656641674041748\n",
      "\n",
      "Epoch:    1/3     Batch:1230/6968  Loss: 4.372783470153808\n",
      "\n",
      "Epoch:    1/3     Batch:1235/6968  Loss: 4.696846961975098\n",
      "\n",
      "Epoch:    1/3     Batch:1240/6968  Loss: 4.569698715209961\n",
      "\n",
      "Epoch:    1/3     Batch:1245/6968  Loss: 4.47497787475586\n",
      "\n",
      "Epoch:    1/3     Batch:1250/6968  Loss: 4.375362396240234\n",
      "\n",
      "Epoch:    1/3     Batch:1255/6968  Loss: 4.5629274368286135\n",
      "\n",
      "Epoch:    1/3     Batch:1260/6968  Loss: 4.365400886535644\n",
      "\n",
      "Epoch:    1/3     Batch:1265/6968  Loss: 4.597637176513672\n",
      "\n",
      "Epoch:    1/3     Batch:1270/6968  Loss: 4.53065824508667\n",
      "\n",
      "Epoch:    1/3     Batch:1275/6968  Loss: 4.5371994972229\n",
      "\n",
      "Epoch:    1/3     Batch:1280/6968  Loss: 4.287905502319336\n",
      "\n",
      "Epoch:    1/3     Batch:1285/6968  Loss: 4.676590919494629\n",
      "\n",
      "Epoch:    1/3     Batch:1290/6968  Loss: 4.498696804046631\n",
      "\n",
      "Epoch:    1/3     Batch:1295/6968  Loss: 4.7191996574401855\n",
      "\n",
      "Epoch:    1/3     Batch:1300/6968  Loss: 4.525846195220947\n",
      "\n",
      "Epoch:    1/3     Batch:1305/6968  Loss: 4.672219562530517\n",
      "\n",
      "Epoch:    1/3     Batch:1310/6968  Loss: 4.6380946159362795\n",
      "\n",
      "Epoch:    1/3     Batch:1315/6968  Loss: 4.699905300140381\n",
      "\n",
      "Epoch:    1/3     Batch:1320/6968  Loss: 4.4470624923706055\n",
      "\n",
      "Epoch:    1/3     Batch:1325/6968  Loss: 4.083415555953979\n",
      "\n",
      "Epoch:    1/3     Batch:1330/6968  Loss: 4.523955059051514\n",
      "\n",
      "Epoch:    1/3     Batch:1335/6968  Loss: 4.5501128196716305\n",
      "\n",
      "Epoch:    1/3     Batch:1340/6968  Loss: 4.342148494720459\n",
      "\n",
      "Epoch:    1/3     Batch:1345/6968  Loss: 4.347846841812133\n",
      "\n",
      "Epoch:    1/3     Batch:1350/6968  Loss: 4.438533782958984\n",
      "\n",
      "Epoch:    1/3     Batch:1355/6968  Loss: 4.444538116455078\n",
      "\n",
      "Epoch:    1/3     Batch:1360/6968  Loss: 4.378529167175293\n",
      "\n",
      "Epoch:    1/3     Batch:1365/6968  Loss: 4.482834529876709\n",
      "\n",
      "Epoch:    1/3     Batch:1370/6968  Loss: 4.382142829895019\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    1/3     Batch:1375/6968  Loss: 4.656357669830323\n",
      "\n",
      "Epoch:    1/3     Batch:1380/6968  Loss: 4.468048572540283\n",
      "\n",
      "Epoch:    1/3     Batch:1385/6968  Loss: 4.568103218078614\n",
      "\n",
      "Epoch:    1/3     Batch:1390/6968  Loss: 4.502295732498169\n",
      "\n",
      "Epoch:    1/3     Batch:1395/6968  Loss: 4.517316055297852\n",
      "\n",
      "Epoch:    1/3     Batch:1400/6968  Loss: 4.522204971313476\n",
      "\n",
      "Epoch:    1/3     Batch:1405/6968  Loss: 4.371023273468017\n",
      "\n",
      "Epoch:    1/3     Batch:1410/6968  Loss: 4.545676898956299\n",
      "\n",
      "Epoch:    1/3     Batch:1415/6968  Loss: 4.3565483570098875\n",
      "\n",
      "Epoch:    1/3     Batch:1420/6968  Loss: 4.362685012817383\n",
      "\n",
      "Epoch:    1/3     Batch:1425/6968  Loss: 4.382701587677002\n",
      "\n",
      "Epoch:    1/3     Batch:1430/6968  Loss: 4.424052143096924\n",
      "\n",
      "Epoch:    1/3     Batch:1435/6968  Loss: 4.461735534667969\n",
      "\n",
      "Epoch:    1/3     Batch:1440/6968  Loss: 4.547649955749511\n",
      "\n",
      "Epoch:    1/3     Batch:1445/6968  Loss: 4.605693054199219\n",
      "\n",
      "Epoch:    1/3     Batch:1450/6968  Loss: 4.445745944976807\n",
      "\n",
      "Epoch:    1/3     Batch:1455/6968  Loss: 4.388899087905884\n",
      "\n",
      "Epoch:    1/3     Batch:1460/6968  Loss: 4.524132966995239\n",
      "\n",
      "Epoch:    1/3     Batch:1465/6968  Loss: 4.519767618179321\n",
      "\n",
      "Epoch:    1/3     Batch:1470/6968  Loss: 4.634839916229248\n",
      "\n",
      "Epoch:    1/3     Batch:1475/6968  Loss: 4.741477298736572\n",
      "\n",
      "Epoch:    1/3     Batch:1480/6968  Loss: 4.548974990844727\n",
      "\n",
      "Epoch:    1/3     Batch:1485/6968  Loss: 4.330973386764526\n",
      "\n",
      "Epoch:    1/3     Batch:1490/6968  Loss: 4.426516914367676\n",
      "\n",
      "Epoch:    1/3     Batch:1495/6968  Loss: 4.317061185836792\n",
      "\n",
      "Epoch:    1/3     Batch:1500/6968  Loss: 4.496721363067627\n",
      "\n",
      "Epoch:    1/3     Batch:1505/6968  Loss: 4.510729598999023\n",
      "\n",
      "Epoch:    1/3     Batch:1510/6968  Loss: 4.560235977172852\n",
      "\n",
      "Epoch:    1/3     Batch:1515/6968  Loss: 4.263696384429932\n",
      "\n",
      "Epoch:    1/3     Batch:1520/6968  Loss: 4.572563934326172\n",
      "\n",
      "Epoch:    1/3     Batch:1525/6968  Loss: 4.4585339546203615\n",
      "\n",
      "Epoch:    1/3     Batch:1530/6968  Loss: 4.539857864379883\n",
      "\n",
      "Epoch:    1/3     Batch:1535/6968  Loss: 4.438768100738526\n",
      "\n",
      "Epoch:    1/3     Batch:1540/6968  Loss: 4.426087474822998\n",
      "\n",
      "Epoch:    1/3     Batch:1545/6968  Loss: 4.743013668060303\n",
      "\n",
      "Epoch:    1/3     Batch:1550/6968  Loss: 4.5118988990783695\n",
      "\n",
      "Epoch:    1/3     Batch:1555/6968  Loss: 3.9982912063598635\n",
      "\n",
      "Epoch:    1/3     Batch:1560/6968  Loss: 4.5250725746154785\n",
      "\n",
      "Epoch:    1/3     Batch:1565/6968  Loss: 4.228685712814331\n",
      "\n",
      "Epoch:    1/3     Batch:1570/6968  Loss: 4.643907356262207\n",
      "\n",
      "Epoch:    1/3     Batch:1575/6968  Loss: 4.342564582824707\n",
      "\n",
      "Epoch:    1/3     Batch:1580/6968  Loss: 4.4436136245727536\n",
      "\n",
      "Epoch:    1/3     Batch:1585/6968  Loss: 4.492047500610352\n",
      "\n",
      "Epoch:    1/3     Batch:1590/6968  Loss: 4.389322090148926\n",
      "\n",
      "Epoch:    1/3     Batch:1595/6968  Loss: 4.461169147491455\n",
      "\n",
      "Epoch:    1/3     Batch:1600/6968  Loss: 4.23521580696106\n",
      "\n",
      "Epoch:    1/3     Batch:1605/6968  Loss: 4.703604030609131\n",
      "\n",
      "Epoch:    1/3     Batch:1610/6968  Loss: 4.654234981536865\n",
      "\n",
      "Epoch:    1/3     Batch:1615/6968  Loss: 4.402396965026855\n",
      "\n",
      "Epoch:    1/3     Batch:1620/6968  Loss: 4.695653915405273\n",
      "\n",
      "Epoch:    1/3     Batch:1625/6968  Loss: 4.64728479385376\n",
      "\n",
      "Epoch:    1/3     Batch:1630/6968  Loss: 4.37327995300293\n",
      "\n",
      "Epoch:    1/3     Batch:1635/6968  Loss: 4.478740406036377\n",
      "\n",
      "Epoch:    1/3     Batch:1640/6968  Loss: 4.444884300231934\n",
      "\n",
      "Epoch:    1/3     Batch:1645/6968  Loss: 4.5668891906738285\n",
      "\n",
      "Epoch:    1/3     Batch:1650/6968  Loss: 4.667622089385986\n",
      "\n",
      "Epoch:    1/3     Batch:1655/6968  Loss: 4.565388965606689\n",
      "\n",
      "Epoch:    1/3     Batch:1660/6968  Loss: 4.177248573303222\n",
      "\n",
      "Epoch:    1/3     Batch:1665/6968  Loss: 4.200215625762939\n",
      "\n",
      "Epoch:    1/3     Batch:1670/6968  Loss: 4.2097584247589115\n",
      "\n",
      "Epoch:    1/3     Batch:1675/6968  Loss: 4.5046079635620115\n",
      "\n",
      "Epoch:    1/3     Batch:1680/6968  Loss: 4.609858989715576\n",
      "\n",
      "Epoch:    1/3     Batch:1685/6968  Loss: 4.418320417404175\n",
      "\n",
      "Epoch:    1/3     Batch:1690/6968  Loss: 4.587518692016602\n",
      "\n",
      "Epoch:    1/3     Batch:1695/6968  Loss: 4.365388202667236\n",
      "\n",
      "Epoch:    1/3     Batch:1700/6968  Loss: 4.624236106872559\n",
      "\n",
      "Epoch:    1/3     Batch:1705/6968  Loss: 4.442840194702148\n",
      "\n",
      "Epoch:    1/3     Batch:1710/6968  Loss: 4.359500980377197\n",
      "\n",
      "Epoch:    1/3     Batch:1715/6968  Loss: 4.444331932067871\n",
      "\n",
      "Epoch:    1/3     Batch:1720/6968  Loss: 4.55339822769165\n",
      "\n",
      "Epoch:    1/3     Batch:1725/6968  Loss: 4.5355535507202145\n",
      "\n",
      "Epoch:    1/3     Batch:1730/6968  Loss: 4.422043704986573\n",
      "\n",
      "Epoch:    1/3     Batch:1735/6968  Loss: 4.377195739746094\n",
      "\n",
      "Epoch:    1/3     Batch:1740/6968  Loss: 4.413198852539063\n",
      "\n",
      "Epoch:    1/3     Batch:1745/6968  Loss: 4.746611309051514\n",
      "\n",
      "Epoch:    1/3     Batch:1750/6968  Loss: 4.5363493919372555\n",
      "\n",
      "Epoch:    1/3     Batch:1755/6968  Loss: 4.3163783073425295\n",
      "\n",
      "Epoch:    1/3     Batch:1760/6968  Loss: 4.304538440704346\n",
      "\n",
      "Epoch:    1/3     Batch:1765/6968  Loss: 4.2559606552124025\n",
      "\n",
      "Epoch:    1/3     Batch:1770/6968  Loss: 4.2962260246276855\n",
      "\n",
      "Epoch:    1/3     Batch:1775/6968  Loss: 4.393638658523559\n",
      "\n",
      "Epoch:    1/3     Batch:1780/6968  Loss: 4.38446683883667\n",
      "\n",
      "Epoch:    1/3     Batch:1785/6968  Loss: 4.357852602005005\n",
      "\n",
      "Epoch:    1/3     Batch:1790/6968  Loss: 4.269560050964356\n",
      "\n",
      "Epoch:    1/3     Batch:1795/6968  Loss: 4.291233873367309\n",
      "\n",
      "Epoch:    1/3     Batch:1800/6968  Loss: 4.284886741638184\n",
      "\n",
      "Epoch:    1/3     Batch:1805/6968  Loss: 4.355469417572022\n",
      "\n",
      "Epoch:    1/3     Batch:1810/6968  Loss: 4.270726108551026\n",
      "\n",
      "Epoch:    1/3     Batch:1815/6968  Loss: 4.306589984893799\n",
      "\n",
      "Epoch:    1/3     Batch:1820/6968  Loss: 4.400968742370606\n",
      "\n",
      "Epoch:    1/3     Batch:1825/6968  Loss: 4.280548095703125\n",
      "\n",
      "Epoch:    1/3     Batch:1830/6968  Loss: 4.374991416931152\n",
      "\n",
      "Epoch:    1/3     Batch:1835/6968  Loss: 4.579241752624512\n",
      "\n",
      "Epoch:    1/3     Batch:1840/6968  Loss: 4.289284372329712\n",
      "\n",
      "Epoch:    1/3     Batch:1845/6968  Loss: 4.318180942535401\n",
      "\n",
      "Epoch:    1/3     Batch:1850/6968  Loss: 4.40517110824585\n",
      "\n",
      "Epoch:    1/3     Batch:1855/6968  Loss: 4.23740177154541\n",
      "\n",
      "Epoch:    1/3     Batch:1860/6968  Loss: 4.578986644744873\n",
      "\n",
      "Epoch:    1/3     Batch:1865/6968  Loss: 4.365732288360595\n",
      "\n",
      "Epoch:    1/3     Batch:1870/6968  Loss: 4.120385456085205\n",
      "\n",
      "Epoch:    1/3     Batch:1875/6968  Loss: 4.234841012954712\n",
      "\n",
      "Epoch:    1/3     Batch:1880/6968  Loss: 4.494702529907227\n",
      "\n",
      "Epoch:    1/3     Batch:1885/6968  Loss: 4.32631483078003\n",
      "\n",
      "Epoch:    1/3     Batch:1890/6968  Loss: 4.162127685546875\n",
      "\n",
      "Epoch:    1/3     Batch:1895/6968  Loss: 4.578019714355468\n",
      "\n",
      "Epoch:    1/3     Batch:1900/6968  Loss: 4.4861083984375\n",
      "\n",
      "Epoch:    1/3     Batch:1905/6968  Loss: 4.375905990600586\n",
      "\n",
      "Epoch:    1/3     Batch:1910/6968  Loss: 4.212785863876343\n",
      "\n",
      "Epoch:    1/3     Batch:1915/6968  Loss: 4.321417427062988\n",
      "\n",
      "Epoch:    1/3     Batch:1920/6968  Loss: 4.313104438781738\n",
      "\n",
      "Epoch:    1/3     Batch:1925/6968  Loss: 4.439853382110596\n",
      "\n",
      "Epoch:    1/3     Batch:1930/6968  Loss: 4.493614959716797\n",
      "\n",
      "Epoch:    1/3     Batch:1935/6968  Loss: 4.460653686523438\n",
      "\n",
      "Epoch:    1/3     Batch:1940/6968  Loss: 4.299294662475586\n",
      "\n",
      "Epoch:    1/3     Batch:1945/6968  Loss: 4.3292844772338865\n",
      "\n",
      "Epoch:    1/3     Batch:1950/6968  Loss: 4.11942229270935\n",
      "\n",
      "Epoch:    1/3     Batch:1955/6968  Loss: 4.426570892333984\n",
      "\n",
      "Epoch:    1/3     Batch:1960/6968  Loss: 4.390542221069336\n",
      "\n",
      "Epoch:    1/3     Batch:1965/6968  Loss: 4.458846855163574\n",
      "\n",
      "Epoch:    1/3     Batch:1970/6968  Loss: 4.311839962005616\n",
      "\n",
      "Epoch:    1/3     Batch:1975/6968  Loss: 4.344687747955322\n",
      "\n",
      "Epoch:    1/3     Batch:1980/6968  Loss: 4.320083332061768\n",
      "\n",
      "Epoch:    1/3     Batch:1985/6968  Loss: 4.453358745574951\n",
      "\n",
      "Epoch:    1/3     Batch:1990/6968  Loss: 4.467040252685547\n",
      "\n",
      "Epoch:    1/3     Batch:1995/6968  Loss: 4.105141925811767\n",
      "\n",
      "Epoch:    1/3     Batch:2000/6968  Loss: 4.4827922821044925\n",
      "\n",
      "Epoch:    1/3     Batch:2005/6968  Loss: 4.358054733276367\n",
      "\n",
      "Epoch:    1/3     Batch:2010/6968  Loss: 4.336585330963135\n",
      "\n",
      "Epoch:    1/3     Batch:2015/6968  Loss: 4.683542919158936\n",
      "\n",
      "Epoch:    1/3     Batch:2020/6968  Loss: 4.530293560028076\n",
      "\n",
      "Epoch:    1/3     Batch:2025/6968  Loss: 4.423167324066162\n",
      "\n",
      "Epoch:    1/3     Batch:2030/6968  Loss: 4.476753044128418\n",
      "\n",
      "Epoch:    1/3     Batch:2035/6968  Loss: 4.319592094421386\n",
      "\n",
      "Epoch:    1/3     Batch:2040/6968  Loss: 4.361172389984131\n",
      "\n",
      "Epoch:    1/3     Batch:2045/6968  Loss: 4.55549430847168\n",
      "\n",
      "Epoch:    1/3     Batch:2050/6968  Loss: 4.16685266494751\n",
      "\n",
      "Epoch:    1/3     Batch:2055/6968  Loss: 4.239091396331787\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    1/3     Batch:2060/6968  Loss: 4.518200826644898\n",
      "\n",
      "Epoch:    1/3     Batch:2065/6968  Loss: 4.3675000190734865\n",
      "\n",
      "Epoch:    1/3     Batch:2070/6968  Loss: 4.322602844238281\n",
      "\n",
      "Epoch:    1/3     Batch:2075/6968  Loss: 4.642829036712646\n",
      "\n",
      "Epoch:    1/3     Batch:2080/6968  Loss: 4.1229664325714115\n",
      "\n",
      "Epoch:    1/3     Batch:2085/6968  Loss: 4.629550170898438\n",
      "\n",
      "Epoch:    1/3     Batch:2090/6968  Loss: 4.189075994491577\n",
      "\n",
      "Epoch:    1/3     Batch:2095/6968  Loss: 4.273756980895996\n",
      "\n",
      "Epoch:    1/3     Batch:2100/6968  Loss: 4.443008804321289\n",
      "\n",
      "Epoch:    1/3     Batch:2105/6968  Loss: 4.259553337097168\n",
      "\n",
      "Epoch:    1/3     Batch:2110/6968  Loss: 4.57703971862793\n",
      "\n",
      "Epoch:    1/3     Batch:2115/6968  Loss: 4.32003002166748\n",
      "\n",
      "Epoch:    1/3     Batch:2120/6968  Loss: 4.128205251693726\n",
      "\n",
      "Epoch:    1/3     Batch:2125/6968  Loss: 4.290370178222656\n",
      "\n",
      "Epoch:    1/3     Batch:2130/6968  Loss: 4.253934049606324\n",
      "\n",
      "Epoch:    1/3     Batch:2135/6968  Loss: 4.3208146572113035\n",
      "\n",
      "Epoch:    1/3     Batch:2140/6968  Loss: 4.241131973266602\n",
      "\n",
      "Epoch:    1/3     Batch:2145/6968  Loss: 4.300946140289307\n",
      "\n",
      "Epoch:    1/3     Batch:2150/6968  Loss: 4.5566551208496096\n",
      "\n",
      "Epoch:    1/3     Batch:2155/6968  Loss: 4.158632707595825\n",
      "\n",
      "Epoch:    1/3     Batch:2160/6968  Loss: 4.465410232543945\n",
      "\n",
      "Epoch:    1/3     Batch:2165/6968  Loss: 4.398065757751465\n",
      "\n",
      "Epoch:    1/3     Batch:2170/6968  Loss: 4.276286792755127\n",
      "\n",
      "Epoch:    1/3     Batch:2175/6968  Loss: 4.43150839805603\n",
      "\n",
      "Epoch:    1/3     Batch:2180/6968  Loss: 4.418843746185303\n",
      "\n",
      "Epoch:    1/3     Batch:2185/6968  Loss: 4.360586071014405\n",
      "\n",
      "Epoch:    1/3     Batch:2190/6968  Loss: 4.2495392799377445\n",
      "\n",
      "Epoch:    1/3     Batch:2195/6968  Loss: 4.166989946365357\n",
      "\n",
      "Epoch:    1/3     Batch:2200/6968  Loss: 4.122019815444946\n",
      "\n",
      "Epoch:    1/3     Batch:2205/6968  Loss: 4.3802824974060055\n",
      "\n",
      "Epoch:    1/3     Batch:2210/6968  Loss: 4.424734306335449\n",
      "\n",
      "Epoch:    1/3     Batch:2215/6968  Loss: 4.408103656768799\n",
      "\n",
      "Epoch:    1/3     Batch:2220/6968  Loss: 4.330238962173462\n",
      "\n",
      "Epoch:    1/3     Batch:2225/6968  Loss: 4.239652347564697\n",
      "\n",
      "Epoch:    1/3     Batch:2230/6968  Loss: 4.081533908843994\n",
      "\n",
      "Epoch:    1/3     Batch:2235/6968  Loss: 4.492919826507569\n",
      "\n",
      "Epoch:    1/3     Batch:2240/6968  Loss: 4.186448764801026\n",
      "\n",
      "Epoch:    1/3     Batch:2245/6968  Loss: 4.429296684265137\n",
      "\n",
      "Epoch:    1/3     Batch:2250/6968  Loss: 4.317654848098755\n",
      "\n",
      "Epoch:    1/3     Batch:2255/6968  Loss: 4.329652118682861\n",
      "\n",
      "Epoch:    1/3     Batch:2260/6968  Loss: 4.142975902557373\n",
      "\n",
      "Epoch:    1/3     Batch:2265/6968  Loss: 4.280419635772705\n",
      "\n",
      "Epoch:    1/3     Batch:2270/6968  Loss: 4.226040077209473\n",
      "\n",
      "Epoch:    1/3     Batch:2275/6968  Loss: 4.50552396774292\n",
      "\n",
      "Epoch:    1/3     Batch:2280/6968  Loss: 4.432708263397217\n",
      "\n",
      "Epoch:    1/3     Batch:2285/6968  Loss: 4.511583757400513\n",
      "\n",
      "Epoch:    1/3     Batch:2290/6968  Loss: 4.146542501449585\n",
      "\n",
      "Epoch:    1/3     Batch:2295/6968  Loss: 4.506737518310547\n",
      "\n",
      "Epoch:    1/3     Batch:2300/6968  Loss: 4.1694639205932615\n",
      "\n",
      "Epoch:    1/3     Batch:2305/6968  Loss: 4.271384429931641\n",
      "\n",
      "Epoch:    1/3     Batch:2310/6968  Loss: 4.427478694915772\n",
      "\n",
      "Epoch:    1/3     Batch:2315/6968  Loss: 4.507037162780762\n",
      "\n",
      "Epoch:    1/3     Batch:2320/6968  Loss: 4.164080333709717\n",
      "\n",
      "Epoch:    1/3     Batch:2325/6968  Loss: 4.240768718719482\n",
      "\n",
      "Epoch:    1/3     Batch:2330/6968  Loss: 4.13468222618103\n",
      "\n",
      "Epoch:    1/3     Batch:2335/6968  Loss: 4.468679809570313\n",
      "\n",
      "Epoch:    1/3     Batch:2340/6968  Loss: 4.095935535430908\n",
      "\n",
      "Epoch:    1/3     Batch:2345/6968  Loss: 4.218086528778076\n",
      "\n",
      "Epoch:    1/3     Batch:2350/6968  Loss: 4.352392148971558\n",
      "\n",
      "Epoch:    1/3     Batch:2355/6968  Loss: 4.301599025726318\n",
      "\n",
      "Epoch:    1/3     Batch:2360/6968  Loss: 4.300566101074219\n",
      "\n",
      "Epoch:    1/3     Batch:2365/6968  Loss: 4.5131322860717775\n",
      "\n",
      "Epoch:    1/3     Batch:2370/6968  Loss: 4.08389720916748\n",
      "\n",
      "Epoch:    1/3     Batch:2375/6968  Loss: 4.271858596801758\n",
      "\n",
      "Epoch:    1/3     Batch:2380/6968  Loss: 4.355653905868531\n",
      "\n",
      "Epoch:    1/3     Batch:2385/6968  Loss: 4.245172309875488\n",
      "\n",
      "Epoch:    1/3     Batch:2390/6968  Loss: 4.358313941955567\n",
      "\n",
      "Epoch:    1/3     Batch:2395/6968  Loss: 4.304792976379394\n",
      "\n",
      "Epoch:    1/3     Batch:2400/6968  Loss: 4.423413228988648\n",
      "\n",
      "Epoch:    1/3     Batch:2405/6968  Loss: 4.323713970184326\n",
      "\n",
      "Epoch:    1/3     Batch:2410/6968  Loss: 4.3511699676513675\n",
      "\n",
      "Epoch:    1/3     Batch:2415/6968  Loss: 4.122750949859619\n",
      "\n",
      "Epoch:    1/3     Batch:2420/6968  Loss: 4.391840553283691\n",
      "\n",
      "Epoch:    1/3     Batch:2425/6968  Loss: 4.200619220733643\n",
      "\n",
      "Epoch:    1/3     Batch:2430/6968  Loss: 4.378038597106934\n",
      "\n",
      "Epoch:    1/3     Batch:2435/6968  Loss: 4.172945737838745\n",
      "\n",
      "Epoch:    1/3     Batch:2440/6968  Loss: 4.241245698928833\n",
      "\n",
      "Epoch:    1/3     Batch:2445/6968  Loss: 4.092933940887451\n",
      "\n",
      "Epoch:    1/3     Batch:2450/6968  Loss: 4.127607011795044\n",
      "\n",
      "Epoch:    1/3     Batch:2455/6968  Loss: 4.2550914764404295\n",
      "\n",
      "Epoch:    1/3     Batch:2460/6968  Loss: 4.3278196334838865\n",
      "\n",
      "Epoch:    1/3     Batch:2465/6968  Loss: 4.370132637023926\n",
      "\n",
      "Epoch:    1/3     Batch:2470/6968  Loss: 4.1575977325439455\n",
      "\n",
      "Epoch:    1/3     Batch:2475/6968  Loss: 4.360936689376831\n",
      "\n",
      "Epoch:    1/3     Batch:2480/6968  Loss: 4.437492179870605\n",
      "\n",
      "Epoch:    1/3     Batch:2485/6968  Loss: 4.499176836013794\n",
      "\n",
      "Epoch:    1/3     Batch:2490/6968  Loss: 4.264478063583374\n",
      "\n",
      "Epoch:    1/3     Batch:2495/6968  Loss: 4.318380832672119\n",
      "\n",
      "Epoch:    1/3     Batch:2500/6968  Loss: 4.078609037399292\n",
      "\n",
      "Epoch:    1/3     Batch:2505/6968  Loss: 4.334802532196045\n",
      "\n",
      "Epoch:    1/3     Batch:2510/6968  Loss: 4.129227924346924\n",
      "\n",
      "Epoch:    1/3     Batch:2515/6968  Loss: 4.18556056022644\n",
      "\n",
      "Epoch:    1/3     Batch:2520/6968  Loss: 4.184506607055664\n",
      "\n",
      "Epoch:    1/3     Batch:2525/6968  Loss: 4.0946417331695555\n",
      "\n",
      "Epoch:    1/3     Batch:2530/6968  Loss: 3.992779350280762\n",
      "\n",
      "Epoch:    1/3     Batch:2535/6968  Loss: 4.323543691635132\n",
      "\n",
      "Epoch:    1/3     Batch:2540/6968  Loss: 4.049076652526855\n",
      "\n",
      "Epoch:    1/3     Batch:2545/6968  Loss: 4.278021907806396\n",
      "\n",
      "Epoch:    1/3     Batch:2550/6968  Loss: 4.300134181976318\n",
      "\n",
      "Epoch:    1/3     Batch:2555/6968  Loss: 4.229043674468994\n",
      "\n",
      "Epoch:    1/3     Batch:2560/6968  Loss: 4.316046142578125\n",
      "\n",
      "Epoch:    1/3     Batch:2565/6968  Loss: 4.138598680496216\n",
      "\n",
      "Epoch:    1/3     Batch:2570/6968  Loss: 4.075445556640625\n",
      "\n",
      "Epoch:    1/3     Batch:2575/6968  Loss: 4.319869709014893\n",
      "\n",
      "Epoch:    1/3     Batch:2580/6968  Loss: 4.379693984985352\n",
      "\n",
      "Epoch:    1/3     Batch:2585/6968  Loss: 4.189770078659057\n",
      "\n",
      "Epoch:    1/3     Batch:2590/6968  Loss: 4.426199340820313\n",
      "\n",
      "Epoch:    1/3     Batch:2595/6968  Loss: 4.598422813415527\n",
      "\n",
      "Epoch:    1/3     Batch:2600/6968  Loss: 4.278790664672852\n",
      "\n",
      "Epoch:    1/3     Batch:2605/6968  Loss: 4.361922359466552\n",
      "\n",
      "Epoch:    1/3     Batch:2610/6968  Loss: 4.544913864135742\n",
      "\n",
      "Epoch:    1/3     Batch:2615/6968  Loss: 4.0766558170318605\n",
      "\n",
      "Epoch:    1/3     Batch:2620/6968  Loss: 4.43024845123291\n",
      "\n",
      "Epoch:    1/3     Batch:2625/6968  Loss: 4.183941221237182\n",
      "\n",
      "Epoch:    1/3     Batch:2630/6968  Loss: 4.352594566345215\n",
      "\n",
      "Epoch:    1/3     Batch:2635/6968  Loss: 4.433832740783691\n",
      "\n",
      "Epoch:    1/3     Batch:2640/6968  Loss: 4.121306943893432\n",
      "\n",
      "Epoch:    1/3     Batch:2645/6968  Loss: 4.194446849822998\n",
      "\n",
      "Epoch:    1/3     Batch:2650/6968  Loss: 4.144779205322266\n",
      "\n",
      "Epoch:    1/3     Batch:2655/6968  Loss: 4.081550884246826\n",
      "\n",
      "Epoch:    1/3     Batch:2660/6968  Loss: 4.4060639381408695\n",
      "\n",
      "Epoch:    1/3     Batch:2665/6968  Loss: 4.075683307647705\n",
      "\n",
      "Epoch:    1/3     Batch:2670/6968  Loss: 4.350575160980225\n",
      "\n",
      "Epoch:    1/3     Batch:2675/6968  Loss: 4.180459833145141\n",
      "\n",
      "Epoch:    1/3     Batch:2680/6968  Loss: 4.473345184326172\n",
      "\n",
      "Epoch:    1/3     Batch:2685/6968  Loss: 4.652651691436768\n",
      "\n",
      "Epoch:    1/3     Batch:2690/6968  Loss: 4.080317258834839\n",
      "\n",
      "Epoch:    1/3     Batch:2695/6968  Loss: 4.517640590667725\n",
      "\n",
      "Epoch:    1/3     Batch:2700/6968  Loss: 3.996096706390381\n",
      "\n",
      "Epoch:    1/3     Batch:2705/6968  Loss: 4.208441686630249\n",
      "\n",
      "Epoch:    1/3     Batch:2710/6968  Loss: 4.195828294754028\n",
      "\n",
      "Epoch:    1/3     Batch:2715/6968  Loss: 4.403075885772705\n",
      "\n",
      "Epoch:    1/3     Batch:2720/6968  Loss: 4.102787971496582\n",
      "\n",
      "Epoch:    1/3     Batch:2725/6968  Loss: 4.4451416015625\n",
      "\n",
      "Epoch:    1/3     Batch:2730/6968  Loss: 4.380489921569824\n",
      "\n",
      "Epoch:    1/3     Batch:2735/6968  Loss: 4.379327726364136\n",
      "\n",
      "Epoch:    1/3     Batch:2740/6968  Loss: 4.153593444824219\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    1/3     Batch:2745/6968  Loss: 4.207505798339843\n",
      "\n",
      "Epoch:    1/3     Batch:2750/6968  Loss: 4.254744529724121\n",
      "\n",
      "Epoch:    1/3     Batch:2755/6968  Loss: 4.256886005401611\n",
      "\n",
      "Epoch:    1/3     Batch:2760/6968  Loss: 4.4325484275817875\n",
      "\n",
      "Epoch:    1/3     Batch:2765/6968  Loss: 4.177724075317383\n",
      "\n",
      "Epoch:    1/3     Batch:2770/6968  Loss: 4.165682554244995\n",
      "\n",
      "Epoch:    1/3     Batch:2775/6968  Loss: 4.292422533035278\n",
      "\n",
      "Epoch:    1/3     Batch:2780/6968  Loss: 4.369127368927002\n",
      "\n",
      "Epoch:    1/3     Batch:2785/6968  Loss: 4.333321571350098\n",
      "\n",
      "Epoch:    1/3     Batch:2790/6968  Loss: 4.223998069763184\n",
      "\n",
      "Epoch:    1/3     Batch:2795/6968  Loss: 4.498069953918457\n",
      "\n",
      "Epoch:    1/3     Batch:2800/6968  Loss: 4.294446325302124\n",
      "\n",
      "Epoch:    1/3     Batch:2805/6968  Loss: 4.407936668395996\n",
      "\n",
      "Epoch:    1/3     Batch:2810/6968  Loss: 4.378002643585205\n",
      "\n",
      "Epoch:    1/3     Batch:2815/6968  Loss: 4.4598517417907715\n",
      "\n",
      "Epoch:    1/3     Batch:2820/6968  Loss: 4.437887382507324\n",
      "\n",
      "Epoch:    1/3     Batch:2825/6968  Loss: 4.277080631256103\n",
      "\n",
      "Epoch:    1/3     Batch:2830/6968  Loss: 4.019677448272705\n",
      "\n",
      "Epoch:    1/3     Batch:2835/6968  Loss: 3.91805739402771\n",
      "\n",
      "Epoch:    1/3     Batch:2840/6968  Loss: 4.340036678314209\n",
      "\n",
      "Epoch:    1/3     Batch:2845/6968  Loss: 4.479201984405518\n",
      "\n",
      "Epoch:    1/3     Batch:2850/6968  Loss: 4.229074621200562\n",
      "\n",
      "Epoch:    1/3     Batch:2855/6968  Loss: 3.9863659858703615\n",
      "\n",
      "Epoch:    1/3     Batch:2860/6968  Loss: 4.407267475128174\n",
      "\n",
      "Epoch:    1/3     Batch:2865/6968  Loss: 4.227694416046143\n",
      "\n",
      "Epoch:    1/3     Batch:2870/6968  Loss: 4.069023275375367\n",
      "\n",
      "Epoch:    1/3     Batch:2875/6968  Loss: 4.132333421707154\n",
      "\n",
      "Epoch:    1/3     Batch:2880/6968  Loss: 4.139461421966553\n",
      "\n",
      "Epoch:    1/3     Batch:2885/6968  Loss: 4.133414173126221\n",
      "\n",
      "Epoch:    1/3     Batch:2890/6968  Loss: 4.29255313873291\n",
      "\n",
      "Epoch:    1/3     Batch:2895/6968  Loss: 4.4081549644470215\n",
      "\n",
      "Epoch:    1/3     Batch:2900/6968  Loss: 4.130246591567993\n",
      "\n",
      "Epoch:    1/3     Batch:2905/6968  Loss: 4.2177817821502686\n",
      "\n",
      "Epoch:    1/3     Batch:2910/6968  Loss: 4.070316982269287\n",
      "\n",
      "Epoch:    1/3     Batch:2915/6968  Loss: 4.313876342773438\n",
      "\n",
      "Epoch:    1/3     Batch:2920/6968  Loss: 4.289034032821656\n",
      "\n",
      "Epoch:    1/3     Batch:2925/6968  Loss: 4.454299354553223\n",
      "\n",
      "Epoch:    1/3     Batch:2930/6968  Loss: 4.388951539993286\n",
      "\n",
      "Epoch:    1/3     Batch:2935/6968  Loss: 4.185903739929199\n",
      "\n",
      "Epoch:    1/3     Batch:2940/6968  Loss: 4.115180253982544\n",
      "\n",
      "Epoch:    1/3     Batch:2945/6968  Loss: 4.472963523864746\n",
      "\n",
      "Epoch:    1/3     Batch:2950/6968  Loss: 3.9822718620300295\n",
      "\n",
      "Epoch:    1/3     Batch:2955/6968  Loss: 4.363727807998657\n",
      "\n",
      "Epoch:    1/3     Batch:2960/6968  Loss: 4.339293384552002\n",
      "\n",
      "Epoch:    1/3     Batch:2965/6968  Loss: 4.182570505142212\n",
      "\n",
      "Epoch:    1/3     Batch:2970/6968  Loss: 4.267073011398315\n",
      "\n",
      "Epoch:    1/3     Batch:2975/6968  Loss: 4.404855537414551\n",
      "\n",
      "Epoch:    1/3     Batch:2980/6968  Loss: 4.317816972732544\n",
      "\n",
      "Epoch:    1/3     Batch:2985/6968  Loss: 4.426172256469727\n",
      "\n",
      "Epoch:    1/3     Batch:2990/6968  Loss: 4.169717407226562\n",
      "\n",
      "Epoch:    1/3     Batch:2995/6968  Loss: 4.208128786087036\n",
      "\n",
      "Epoch:    1/3     Batch:3000/6968  Loss: 4.178811645507812\n",
      "\n",
      "Epoch:    1/3     Batch:3005/6968  Loss: 4.171015739440918\n",
      "\n",
      "Epoch:    1/3     Batch:3010/6968  Loss: 4.238909149169922\n",
      "\n",
      "Epoch:    1/3     Batch:3015/6968  Loss: 4.360973596572876\n",
      "\n",
      "Epoch:    1/3     Batch:3020/6968  Loss: 4.313055372238159\n",
      "\n",
      "Epoch:    1/3     Batch:3025/6968  Loss: 4.151100206375122\n",
      "\n",
      "Epoch:    1/3     Batch:3030/6968  Loss: 4.311474132537842\n",
      "\n",
      "Epoch:    1/3     Batch:3035/6968  Loss: 4.318841457366943\n",
      "\n",
      "Epoch:    1/3     Batch:3040/6968  Loss: 4.415357208251953\n",
      "\n",
      "Epoch:    1/3     Batch:3045/6968  Loss: 4.060753583908081\n",
      "\n",
      "Epoch:    1/3     Batch:3050/6968  Loss: 4.253317356109619\n",
      "\n",
      "Epoch:    1/3     Batch:3055/6968  Loss: 4.264328479766846\n",
      "\n",
      "Epoch:    1/3     Batch:3060/6968  Loss: 4.042530250549317\n",
      "\n",
      "Epoch:    1/3     Batch:3065/6968  Loss: 4.176823139190674\n",
      "\n",
      "Epoch:    1/3     Batch:3070/6968  Loss: 4.103734159469605\n",
      "\n",
      "Epoch:    1/3     Batch:3075/6968  Loss: 4.2565700054168705\n",
      "\n",
      "Epoch:    1/3     Batch:3080/6968  Loss: 4.250556612014771\n",
      "\n",
      "Epoch:    1/3     Batch:3085/6968  Loss: 4.205898332595825\n",
      "\n",
      "Epoch:    1/3     Batch:3090/6968  Loss: 4.262176513671875\n",
      "\n",
      "Epoch:    1/3     Batch:3095/6968  Loss: 4.013646125793457\n",
      "\n",
      "Epoch:    1/3     Batch:3100/6968  Loss: 4.04188756942749\n",
      "\n",
      "Epoch:    1/3     Batch:3105/6968  Loss: 4.415220928192139\n",
      "\n",
      "Epoch:    1/3     Batch:3110/6968  Loss: 4.017007350921631\n",
      "\n",
      "Epoch:    1/3     Batch:3115/6968  Loss: 4.232228088378906\n",
      "\n",
      "Epoch:    1/3     Batch:3120/6968  Loss: 4.454471588134766\n",
      "\n",
      "Epoch:    1/3     Batch:3125/6968  Loss: 4.218003034591675\n",
      "\n",
      "Epoch:    1/3     Batch:3130/6968  Loss: 4.137934684753418\n",
      "\n",
      "Epoch:    1/3     Batch:3135/6968  Loss: 4.138142919540405\n",
      "\n",
      "Epoch:    1/3     Batch:3140/6968  Loss: 4.2317932605743405\n",
      "\n",
      "Epoch:    1/3     Batch:3145/6968  Loss: 4.076478719711304\n",
      "\n",
      "Epoch:    1/3     Batch:3150/6968  Loss: 4.022616577148438\n",
      "\n",
      "Epoch:    1/3     Batch:3155/6968  Loss: 4.042517471313476\n",
      "\n",
      "Epoch:    1/3     Batch:3160/6968  Loss: 3.947270917892456\n",
      "\n",
      "Epoch:    1/3     Batch:3165/6968  Loss: 4.032961654663086\n",
      "\n",
      "Epoch:    1/3     Batch:3170/6968  Loss: 4.238651609420776\n",
      "\n",
      "Epoch:    1/3     Batch:3175/6968  Loss: 4.234079504013062\n",
      "\n",
      "Epoch:    1/3     Batch:3180/6968  Loss: 4.119684839248658\n",
      "\n",
      "Epoch:    1/3     Batch:3185/6968  Loss: 4.126413631439209\n",
      "\n",
      "Epoch:    1/3     Batch:3190/6968  Loss: 4.09603590965271\n",
      "\n",
      "Epoch:    1/3     Batch:3195/6968  Loss: 4.099840831756592\n",
      "\n",
      "Epoch:    1/3     Batch:3200/6968  Loss: 4.229012298583984\n",
      "\n",
      "Epoch:    1/3     Batch:3205/6968  Loss: 4.113519668579102\n",
      "\n",
      "Epoch:    1/3     Batch:3210/6968  Loss: 4.208339834213257\n",
      "\n",
      "Epoch:    1/3     Batch:3215/6968  Loss: 4.367858028411865\n",
      "\n",
      "Epoch:    1/3     Batch:3220/6968  Loss: 4.270273923873901\n",
      "\n",
      "Epoch:    1/3     Batch:3225/6968  Loss: 4.045563220977783\n",
      "\n",
      "Epoch:    1/3     Batch:3230/6968  Loss: 4.224947929382324\n",
      "\n",
      "Epoch:    1/3     Batch:3235/6968  Loss: 4.304475116729736\n",
      "\n",
      "Epoch:    1/3     Batch:3240/6968  Loss: 4.204940462112427\n",
      "\n",
      "Epoch:    1/3     Batch:3245/6968  Loss: 4.225405597686768\n",
      "\n",
      "Epoch:    1/3     Batch:3250/6968  Loss: 4.222927284240723\n",
      "\n",
      "Epoch:    1/3     Batch:3255/6968  Loss: 4.1671287536621096\n",
      "\n",
      "Epoch:    1/3     Batch:3260/6968  Loss: 4.1246572971344\n",
      "\n",
      "Epoch:    1/3     Batch:3265/6968  Loss: 4.445484828948975\n",
      "\n",
      "Epoch:    1/3     Batch:3270/6968  Loss: 4.114928436279297\n",
      "\n",
      "Epoch:    1/3     Batch:3275/6968  Loss: 4.375523948669434\n",
      "\n",
      "Epoch:    1/3     Batch:3280/6968  Loss: 4.215462112426758\n",
      "\n",
      "Epoch:    1/3     Batch:3285/6968  Loss: 4.199926519393921\n",
      "\n",
      "Epoch:    1/3     Batch:3290/6968  Loss: 4.314584875106812\n",
      "\n",
      "Epoch:    1/3     Batch:3295/6968  Loss: 4.266681861877442\n",
      "\n",
      "Epoch:    1/3     Batch:3300/6968  Loss: 4.115563535690308\n",
      "\n",
      "Epoch:    1/3     Batch:3305/6968  Loss: 4.2285919189453125\n",
      "\n",
      "Epoch:    1/3     Batch:3310/6968  Loss: 4.226917362213134\n",
      "\n",
      "Epoch:    1/3     Batch:3315/6968  Loss: 4.474964141845703\n",
      "\n",
      "Epoch:    1/3     Batch:3320/6968  Loss: 4.348340797424316\n",
      "\n",
      "Epoch:    1/3     Batch:3325/6968  Loss: 4.146579027175903\n",
      "\n",
      "Epoch:    1/3     Batch:3330/6968  Loss: 4.166243267059326\n",
      "\n",
      "Epoch:    1/3     Batch:3335/6968  Loss: 4.139848518371582\n",
      "\n",
      "Epoch:    1/3     Batch:3340/6968  Loss: 3.9966583251953125\n",
      "\n",
      "Epoch:    1/3     Batch:3345/6968  Loss: 4.1509418964385985\n",
      "\n",
      "Epoch:    1/3     Batch:3350/6968  Loss: 3.9927789211273192\n",
      "\n",
      "Epoch:    1/3     Batch:3355/6968  Loss: 4.335475587844849\n",
      "\n",
      "Epoch:    1/3     Batch:3360/6968  Loss: 4.179642963409424\n",
      "\n",
      "Epoch:    1/3     Batch:3365/6968  Loss: 4.396824836730957\n",
      "\n",
      "Epoch:    1/3     Batch:3370/6968  Loss: 4.1757642269134525\n",
      "\n",
      "Epoch:    1/3     Batch:3375/6968  Loss: 4.021476078033447\n",
      "\n",
      "Epoch:    1/3     Batch:3380/6968  Loss: 4.173483371734619\n",
      "\n",
      "Epoch:    1/3     Batch:3385/6968  Loss: 4.099246978759766\n",
      "\n",
      "Epoch:    1/3     Batch:3390/6968  Loss: 4.38266658782959\n",
      "\n",
      "Epoch:    1/3     Batch:3395/6968  Loss: 4.1842447280883786\n",
      "\n",
      "Epoch:    1/3     Batch:3400/6968  Loss: 4.380465412139893\n",
      "\n",
      "Epoch:    1/3     Batch:3405/6968  Loss: 4.125360584259033\n",
      "\n",
      "Epoch:    1/3     Batch:3410/6968  Loss: 4.497723913192749\n",
      "\n",
      "Epoch:    1/3     Batch:3415/6968  Loss: 4.186980152130127\n",
      "\n",
      "Epoch:    1/3     Batch:3420/6968  Loss: 4.351336193084717\n",
      "\n",
      "Epoch:    1/3     Batch:3425/6968  Loss: 4.3759033203125\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    1/3     Batch:3430/6968  Loss: 4.187979030609131\n",
      "\n",
      "Epoch:    1/3     Batch:3435/6968  Loss: 4.203513669967651\n",
      "\n",
      "Epoch:    1/3     Batch:3440/6968  Loss: 4.205085706710816\n",
      "\n",
      "Epoch:    1/3     Batch:3445/6968  Loss: 4.2782470226287845\n",
      "\n",
      "Epoch:    1/3     Batch:3450/6968  Loss: 4.019217443466187\n",
      "\n",
      "Epoch:    1/3     Batch:3455/6968  Loss: 4.20587854385376\n",
      "\n",
      "Epoch:    1/3     Batch:3460/6968  Loss: 4.210698223114013\n",
      "\n",
      "Epoch:    1/3     Batch:3465/6968  Loss: 4.2645604610443115\n",
      "\n",
      "Epoch:    1/3     Batch:3470/6968  Loss: 4.126839971542358\n",
      "\n",
      "Epoch:    1/3     Batch:3475/6968  Loss: 4.352223968505859\n",
      "\n",
      "Epoch:    1/3     Batch:3480/6968  Loss: 4.360379695892334\n",
      "\n",
      "Epoch:    1/3     Batch:3485/6968  Loss: 4.197786664962768\n",
      "\n",
      "Epoch:    1/3     Batch:3490/6968  Loss: 4.182921075820923\n",
      "\n",
      "Epoch:    1/3     Batch:3495/6968  Loss: 3.9223687648773193\n",
      "\n",
      "Epoch:    1/3     Batch:3500/6968  Loss: 4.217592430114746\n",
      "\n",
      "Epoch:    1/3     Batch:3505/6968  Loss: 4.239665746688843\n",
      "\n",
      "Epoch:    1/3     Batch:3510/6968  Loss: 4.201743650436401\n",
      "\n",
      "Epoch:    1/3     Batch:3515/6968  Loss: 4.388459777832031\n",
      "\n",
      "Epoch:    1/3     Batch:3520/6968  Loss: 4.300442218780518\n",
      "\n",
      "Epoch:    1/3     Batch:3525/6968  Loss: 4.082541418075562\n",
      "\n",
      "Epoch:    1/3     Batch:3530/6968  Loss: 4.241441249847412\n",
      "\n",
      "Epoch:    1/3     Batch:3535/6968  Loss: 4.090154695510864\n",
      "\n",
      "Epoch:    1/3     Batch:3540/6968  Loss: 4.393299007415772\n",
      "\n",
      "Epoch:    1/3     Batch:3545/6968  Loss: 4.094659662246704\n",
      "\n",
      "Epoch:    1/3     Batch:3550/6968  Loss: 4.066186761856079\n",
      "\n",
      "Epoch:    1/3     Batch:3555/6968  Loss: 4.062949180603027\n",
      "\n",
      "Epoch:    1/3     Batch:3560/6968  Loss: 4.201538467407227\n",
      "\n",
      "Epoch:    1/3     Batch:3565/6968  Loss: 4.154174900054931\n",
      "\n",
      "Epoch:    1/3     Batch:3570/6968  Loss: 3.9751883029937742\n",
      "\n",
      "Epoch:    1/3     Batch:3575/6968  Loss: 4.190408706665039\n",
      "\n",
      "Epoch:    1/3     Batch:3580/6968  Loss: 4.348273038864136\n",
      "\n",
      "Epoch:    1/3     Batch:3585/6968  Loss: 3.9741536140441895\n",
      "\n",
      "Epoch:    1/3     Batch:3590/6968  Loss: 4.589783096313477\n",
      "\n",
      "Epoch:    1/3     Batch:3595/6968  Loss: 4.007544612884521\n",
      "\n",
      "Epoch:    1/3     Batch:3600/6968  Loss: 4.360007572174072\n",
      "\n",
      "Epoch:    1/3     Batch:3605/6968  Loss: 3.988849973678589\n",
      "\n",
      "Epoch:    1/3     Batch:3610/6968  Loss: 4.459249877929688\n",
      "\n",
      "Epoch:    1/3     Batch:3615/6968  Loss: 4.270147657394409\n",
      "\n",
      "Epoch:    1/3     Batch:3620/6968  Loss: 3.9642993927001955\n",
      "\n",
      "Epoch:    1/3     Batch:3625/6968  Loss: 4.1277172565460205\n",
      "\n",
      "Epoch:    1/3     Batch:3630/6968  Loss: 4.247060298919678\n",
      "\n",
      "Epoch:    1/3     Batch:3635/6968  Loss: 4.211916255950928\n",
      "\n",
      "Epoch:    1/3     Batch:3640/6968  Loss: 4.178881454467773\n",
      "\n",
      "Epoch:    1/3     Batch:3645/6968  Loss: 4.18050856590271\n",
      "\n",
      "Epoch:    1/3     Batch:3650/6968  Loss: 3.9642450332641603\n",
      "\n",
      "Epoch:    1/3     Batch:3655/6968  Loss: 4.133161497116089\n",
      "\n",
      "Epoch:    1/3     Batch:3660/6968  Loss: 4.273523759841919\n",
      "\n",
      "Epoch:    1/3     Batch:3665/6968  Loss: 4.184047412872315\n",
      "\n",
      "Epoch:    1/3     Batch:3670/6968  Loss: 4.273389863967895\n",
      "\n",
      "Epoch:    1/3     Batch:3675/6968  Loss: 4.347976779937744\n",
      "\n",
      "Epoch:    1/3     Batch:3680/6968  Loss: 4.21310601234436\n",
      "\n",
      "Epoch:    1/3     Batch:3685/6968  Loss: 4.025074052810669\n",
      "\n",
      "Epoch:    1/3     Batch:3690/6968  Loss: 4.057224273681641\n",
      "\n",
      "Epoch:    1/3     Batch:3695/6968  Loss: 4.285232925415039\n",
      "\n",
      "Epoch:    1/3     Batch:3700/6968  Loss: 4.297186326980591\n",
      "\n",
      "Epoch:    1/3     Batch:3705/6968  Loss: 4.165372323989868\n",
      "\n",
      "Epoch:    1/3     Batch:3710/6968  Loss: 4.2162422180175785\n",
      "\n",
      "Epoch:    1/3     Batch:3715/6968  Loss: 4.265992259979248\n",
      "\n",
      "Epoch:    1/3     Batch:3720/6968  Loss: 4.630753898620606\n",
      "\n",
      "Epoch:    1/3     Batch:3725/6968  Loss: 4.118927764892578\n",
      "\n",
      "Epoch:    1/3     Batch:3730/6968  Loss: 4.336017847061157\n",
      "\n",
      "Epoch:    1/3     Batch:3735/6968  Loss: 4.255375099182129\n",
      "\n",
      "Epoch:    1/3     Batch:3740/6968  Loss: 4.36046724319458\n",
      "\n",
      "Epoch:    1/3     Batch:3745/6968  Loss: 4.179823493957519\n",
      "\n",
      "Epoch:    1/3     Batch:3750/6968  Loss: 4.1526123046875\n",
      "\n",
      "Epoch:    1/3     Batch:3755/6968  Loss: 3.8882352828979494\n",
      "\n",
      "Epoch:    1/3     Batch:3760/6968  Loss: 4.19254846572876\n",
      "\n",
      "Epoch:    1/3     Batch:3765/6968  Loss: 3.9957876682281492\n",
      "\n",
      "Epoch:    1/3     Batch:3770/6968  Loss: 4.119297695159912\n",
      "\n",
      "Epoch:    1/3     Batch:3775/6968  Loss: 4.276698255538941\n",
      "\n",
      "Epoch:    1/3     Batch:3780/6968  Loss: 4.4278241157531735\n",
      "\n",
      "Epoch:    1/3     Batch:3785/6968  Loss: 4.413191032409668\n",
      "\n",
      "Epoch:    1/3     Batch:3790/6968  Loss: 4.317440032958984\n",
      "\n",
      "Epoch:    1/3     Batch:3795/6968  Loss: 4.184520101547241\n",
      "\n",
      "Epoch:    1/3     Batch:3800/6968  Loss: 4.053957843780518\n",
      "\n",
      "Epoch:    1/3     Batch:3805/6968  Loss: 4.215684223175049\n",
      "\n",
      "Epoch:    1/3     Batch:3810/6968  Loss: 4.113372182846069\n",
      "\n",
      "Epoch:    1/3     Batch:3815/6968  Loss: 4.137315368652343\n",
      "\n",
      "Epoch:    1/3     Batch:3820/6968  Loss: 4.271681499481201\n",
      "\n",
      "Epoch:    1/3     Batch:3825/6968  Loss: 4.173885917663574\n",
      "\n",
      "Epoch:    1/3     Batch:3830/6968  Loss: 4.4256268501281735\n",
      "\n",
      "Epoch:    1/3     Batch:3835/6968  Loss: 4.179532146453857\n",
      "\n",
      "Epoch:    1/3     Batch:3840/6968  Loss: 4.289939975738525\n",
      "\n",
      "Epoch:    1/3     Batch:3845/6968  Loss: 4.122229433059692\n",
      "\n",
      "Epoch:    1/3     Batch:3850/6968  Loss: 4.264679431915283\n",
      "\n",
      "Epoch:    1/3     Batch:3855/6968  Loss: 4.269182872772217\n",
      "\n",
      "Epoch:    1/3     Batch:3860/6968  Loss: 4.344109725952149\n",
      "\n",
      "Epoch:    1/3     Batch:3865/6968  Loss: 4.056116962432862\n",
      "\n",
      "Epoch:    1/3     Batch:3870/6968  Loss: 4.03650598526001\n",
      "\n",
      "Epoch:    1/3     Batch:3875/6968  Loss: 4.227248239517212\n",
      "\n",
      "Epoch:    1/3     Batch:3880/6968  Loss: 4.205630493164063\n",
      "\n",
      "Epoch:    1/3     Batch:3885/6968  Loss: 4.223969316482544\n",
      "\n",
      "Epoch:    1/3     Batch:3890/6968  Loss: 4.050241994857788\n",
      "\n",
      "Epoch:    1/3     Batch:3895/6968  Loss: 4.210376262664795\n",
      "\n",
      "Epoch:    1/3     Batch:3900/6968  Loss: 4.3979668617248535\n",
      "\n",
      "Epoch:    1/3     Batch:3905/6968  Loss: 4.342047119140625\n",
      "\n",
      "Epoch:    1/3     Batch:3910/6968  Loss: 4.204680967330932\n",
      "\n",
      "Epoch:    1/3     Batch:3915/6968  Loss: 4.153046989440918\n",
      "\n",
      "Epoch:    1/3     Batch:3920/6968  Loss: 4.042909765243531\n",
      "\n",
      "Epoch:    1/3     Batch:3925/6968  Loss: 4.133627700805664\n",
      "\n",
      "Epoch:    1/3     Batch:3930/6968  Loss: 4.052732372283936\n",
      "\n",
      "Epoch:    1/3     Batch:3935/6968  Loss: 4.234605598449707\n",
      "\n",
      "Epoch:    1/3     Batch:3940/6968  Loss: 3.8738609790802\n",
      "\n",
      "Epoch:    1/3     Batch:3945/6968  Loss: 4.268706035614014\n",
      "\n",
      "Epoch:    1/3     Batch:3950/6968  Loss: 4.350695371627808\n",
      "\n",
      "Epoch:    1/3     Batch:3955/6968  Loss: 4.258748960494995\n",
      "\n",
      "Epoch:    1/3     Batch:3960/6968  Loss: 4.150429105758667\n",
      "\n",
      "Epoch:    1/3     Batch:3965/6968  Loss: 4.054628896713257\n",
      "\n",
      "Epoch:    1/3     Batch:3970/6968  Loss: 4.008844470977783\n",
      "\n",
      "Epoch:    1/3     Batch:3975/6968  Loss: 4.275981760025024\n",
      "\n",
      "Epoch:    1/3     Batch:3980/6968  Loss: 4.062666177749634\n",
      "\n",
      "Epoch:    1/3     Batch:3985/6968  Loss: 4.086192464828491\n",
      "\n",
      "Epoch:    1/3     Batch:3990/6968  Loss: 4.007298421859741\n",
      "\n",
      "Epoch:    1/3     Batch:3995/6968  Loss: 4.100915956497192\n",
      "\n",
      "Epoch:    1/3     Batch:4000/6968  Loss: 4.18939847946167\n",
      "\n",
      "Epoch:    1/3     Batch:4005/6968  Loss: 4.041358470916748\n",
      "\n",
      "Epoch:    1/3     Batch:4010/6968  Loss: 4.172744560241699\n",
      "\n",
      "Epoch:    1/3     Batch:4015/6968  Loss: 4.233117246627808\n",
      "\n",
      "Epoch:    1/3     Batch:4020/6968  Loss: 4.254790115356445\n",
      "\n",
      "Epoch:    1/3     Batch:4025/6968  Loss: 4.345253276824951\n",
      "\n",
      "Epoch:    1/3     Batch:4030/6968  Loss: 4.205162429809571\n",
      "\n",
      "Epoch:    1/3     Batch:4035/6968  Loss: 4.081226205825805\n",
      "\n",
      "Epoch:    1/3     Batch:4040/6968  Loss: 4.192438411712646\n",
      "\n",
      "Epoch:    1/3     Batch:4045/6968  Loss: 4.231508064270019\n",
      "\n",
      "Epoch:    1/3     Batch:4050/6968  Loss: 4.013659572601318\n",
      "\n",
      "Epoch:    1/3     Batch:4055/6968  Loss: 3.8475455760955812\n",
      "\n",
      "Epoch:    1/3     Batch:4060/6968  Loss: 4.225575065612793\n",
      "\n",
      "Epoch:    1/3     Batch:4065/6968  Loss: 4.215657091140747\n",
      "\n",
      "Epoch:    1/3     Batch:4070/6968  Loss: 4.124020910263061\n",
      "\n",
      "Epoch:    1/3     Batch:4075/6968  Loss: 4.216460227966309\n",
      "\n",
      "Epoch:    1/3     Batch:4080/6968  Loss: 4.174820756912231\n",
      "\n",
      "Epoch:    1/3     Batch:4085/6968  Loss: 4.182872533798218\n",
      "\n",
      "Epoch:    1/3     Batch:4090/6968  Loss: 4.33069543838501\n",
      "\n",
      "Epoch:    1/3     Batch:4095/6968  Loss: 4.348844718933106\n",
      "\n",
      "Epoch:    1/3     Batch:4100/6968  Loss: 4.160871696472168\n",
      "\n",
      "Epoch:    1/3     Batch:4105/6968  Loss: 4.3926536560058596\n",
      "\n",
      "Epoch:    1/3     Batch:4110/6968  Loss: 4.168072605133057\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    1/3     Batch:4115/6968  Loss: 4.070484161376953\n",
      "\n",
      "Epoch:    1/3     Batch:4120/6968  Loss: 4.088151502609253\n",
      "\n",
      "Epoch:    1/3     Batch:4125/6968  Loss: 4.015921211242675\n",
      "\n",
      "Epoch:    1/3     Batch:4130/6968  Loss: 4.0457014560699465\n",
      "\n",
      "Epoch:    1/3     Batch:4135/6968  Loss: 4.1323949813842775\n",
      "\n",
      "Epoch:    1/3     Batch:4140/6968  Loss: 4.153937578201294\n",
      "\n",
      "Epoch:    1/3     Batch:4145/6968  Loss: 4.1213866710662845\n",
      "\n",
      "Epoch:    1/3     Batch:4150/6968  Loss: 4.004870891571045\n",
      "\n",
      "Epoch:    1/3     Batch:4155/6968  Loss: 4.028061056137085\n",
      "\n",
      "Epoch:    1/3     Batch:4160/6968  Loss: 4.36729998588562\n",
      "\n",
      "Epoch:    1/3     Batch:4165/6968  Loss: 4.008653783798218\n",
      "\n",
      "Epoch:    1/3     Batch:4170/6968  Loss: 4.302184200286865\n",
      "\n",
      "Epoch:    1/3     Batch:4175/6968  Loss: 4.08613429069519\n",
      "\n",
      "Epoch:    1/3     Batch:4180/6968  Loss: 4.163252830505371\n",
      "\n",
      "Epoch:    1/3     Batch:4185/6968  Loss: 4.025714540481568\n",
      "\n",
      "Epoch:    1/3     Batch:4190/6968  Loss: 4.413759708404541\n",
      "\n",
      "Epoch:    1/3     Batch:4195/6968  Loss: 3.9505523204803468\n",
      "\n",
      "Epoch:    1/3     Batch:4200/6968  Loss: 4.099016523361206\n",
      "\n",
      "Epoch:    1/3     Batch:4205/6968  Loss: 4.198480892181396\n",
      "\n",
      "Epoch:    1/3     Batch:4210/6968  Loss: 3.9752489566802978\n",
      "\n",
      "Epoch:    1/3     Batch:4215/6968  Loss: 3.957082653045654\n",
      "\n",
      "Epoch:    1/3     Batch:4220/6968  Loss: 4.031323528289795\n",
      "\n",
      "Epoch:    1/3     Batch:4225/6968  Loss: 4.220332050323487\n",
      "\n",
      "Epoch:    1/3     Batch:4230/6968  Loss: 4.100966215133667\n",
      "\n",
      "Epoch:    1/3     Batch:4235/6968  Loss: 4.099571466445923\n",
      "\n",
      "Epoch:    1/3     Batch:4240/6968  Loss: 4.163495492935181\n",
      "\n",
      "Epoch:    1/3     Batch:4245/6968  Loss: 4.002713584899903\n",
      "\n",
      "Epoch:    1/3     Batch:4250/6968  Loss: 3.7401029586791994\n",
      "\n",
      "Epoch:    1/3     Batch:4255/6968  Loss: 4.002683496475219\n",
      "\n",
      "Epoch:    1/3     Batch:4260/6968  Loss: 4.171934318542481\n",
      "\n",
      "Epoch:    1/3     Batch:4265/6968  Loss: 4.173420333862305\n",
      "\n",
      "Epoch:    1/3     Batch:4270/6968  Loss: 4.108736801147461\n",
      "\n",
      "Epoch:    1/3     Batch:4275/6968  Loss: 4.188172960281372\n",
      "\n",
      "Epoch:    1/3     Batch:4280/6968  Loss: 4.194408416748047\n",
      "\n",
      "Epoch:    1/3     Batch:4285/6968  Loss: 3.809315729141235\n",
      "\n",
      "Epoch:    1/3     Batch:4290/6968  Loss: 4.325854921340943\n",
      "\n",
      "Epoch:    1/3     Batch:4295/6968  Loss: 4.06101245880127\n",
      "\n",
      "Epoch:    1/3     Batch:4300/6968  Loss: 4.023004531860352\n",
      "\n",
      "Epoch:    1/3     Batch:4305/6968  Loss: 4.502779769897461\n",
      "\n",
      "Epoch:    1/3     Batch:4310/6968  Loss: 4.206565809249878\n",
      "\n",
      "Epoch:    1/3     Batch:4315/6968  Loss: 4.159735107421875\n",
      "\n",
      "Epoch:    1/3     Batch:4320/6968  Loss: 4.318202638626099\n",
      "\n",
      "Epoch:    1/3     Batch:4325/6968  Loss: 3.995937871932983\n",
      "\n",
      "Epoch:    1/3     Batch:4330/6968  Loss: 4.161729240417481\n",
      "\n",
      "Epoch:    1/3     Batch:4335/6968  Loss: 4.278644323348999\n",
      "\n",
      "Epoch:    1/3     Batch:4340/6968  Loss: 4.158756828308105\n",
      "\n",
      "Epoch:    1/3     Batch:4345/6968  Loss: 4.008175182342529\n",
      "\n",
      "Epoch:    1/3     Batch:4350/6968  Loss: 4.207886791229248\n",
      "\n",
      "Epoch:    1/3     Batch:4355/6968  Loss: 4.21010103225708\n",
      "\n",
      "Epoch:    1/3     Batch:4360/6968  Loss: 4.2101703643798825\n",
      "\n",
      "Epoch:    1/3     Batch:4365/6968  Loss: 4.232834243774414\n",
      "\n",
      "Epoch:    1/3     Batch:4370/6968  Loss: 4.185391616821289\n",
      "\n",
      "Epoch:    1/3     Batch:4375/6968  Loss: 4.222398090362549\n",
      "\n",
      "Epoch:    1/3     Batch:4380/6968  Loss: 4.235319137573242\n",
      "\n",
      "Epoch:    1/3     Batch:4385/6968  Loss: 4.297035884857178\n",
      "\n",
      "Epoch:    1/3     Batch:4390/6968  Loss: 4.261688327789306\n",
      "\n",
      "Epoch:    1/3     Batch:4395/6968  Loss: 4.1309739112854\n",
      "\n",
      "Epoch:    1/3     Batch:4400/6968  Loss: 4.0210789203643795\n",
      "\n",
      "Epoch:    1/3     Batch:4405/6968  Loss: 3.918936538696289\n",
      "\n",
      "Epoch:    1/3     Batch:4410/6968  Loss: 4.192880153656006\n",
      "\n",
      "Epoch:    1/3     Batch:4415/6968  Loss: 4.080351209640503\n",
      "\n",
      "Epoch:    1/3     Batch:4420/6968  Loss: 3.990218734741211\n",
      "\n",
      "Epoch:    1/3     Batch:4425/6968  Loss: 4.117635822296142\n",
      "\n",
      "Epoch:    1/3     Batch:4430/6968  Loss: 4.053015804290771\n",
      "\n",
      "Epoch:    1/3     Batch:4435/6968  Loss: 4.039447212219239\n",
      "\n",
      "Epoch:    1/3     Batch:4440/6968  Loss: 4.344717407226563\n",
      "\n",
      "Epoch:    1/3     Batch:4445/6968  Loss: 4.243463563919067\n",
      "\n",
      "Epoch:    1/3     Batch:4450/6968  Loss: 4.298170948028565\n",
      "\n",
      "Epoch:    1/3     Batch:4455/6968  Loss: 4.170134544372559\n",
      "\n",
      "Epoch:    1/3     Batch:4460/6968  Loss: 4.3670378684997555\n",
      "\n",
      "Epoch:    1/3     Batch:4465/6968  Loss: 3.9134077548980715\n",
      "\n",
      "Epoch:    1/3     Batch:4470/6968  Loss: 4.035157251358032\n",
      "\n",
      "Epoch:    1/3     Batch:4475/6968  Loss: 4.0769397735595705\n",
      "\n",
      "Epoch:    1/3     Batch:4480/6968  Loss: 4.152324438095093\n",
      "\n",
      "Epoch:    1/3     Batch:4485/6968  Loss: 4.312933349609375\n",
      "\n",
      "Epoch:    1/3     Batch:4490/6968  Loss: 4.10333399772644\n",
      "\n",
      "Epoch:    1/3     Batch:4495/6968  Loss: 4.153323125839234\n",
      "\n",
      "Epoch:    1/3     Batch:4500/6968  Loss: 4.263215208053589\n",
      "\n",
      "Epoch:    1/3     Batch:4505/6968  Loss: 3.922418403625488\n",
      "\n",
      "Epoch:    1/3     Batch:4510/6968  Loss: 4.073553133010864\n",
      "\n",
      "Epoch:    1/3     Batch:4515/6968  Loss: 3.916481304168701\n",
      "\n",
      "Epoch:    1/3     Batch:4520/6968  Loss: 4.224157857894897\n",
      "\n",
      "Epoch:    1/3     Batch:4525/6968  Loss: 4.300906085968018\n",
      "\n",
      "Epoch:    1/3     Batch:4530/6968  Loss: 4.359914302825928\n",
      "\n",
      "Epoch:    1/3     Batch:4535/6968  Loss: 3.950681686401367\n",
      "\n",
      "Epoch:    1/3     Batch:4540/6968  Loss: 4.293680000305176\n",
      "\n",
      "Epoch:    1/3     Batch:4545/6968  Loss: 4.17624568939209\n",
      "\n",
      "Epoch:    1/3     Batch:4550/6968  Loss: 3.995894718170166\n",
      "\n",
      "Epoch:    1/3     Batch:4555/6968  Loss: 4.2675799369812015\n",
      "\n",
      "Epoch:    1/3     Batch:4560/6968  Loss: 4.355057430267334\n",
      "\n",
      "Epoch:    1/3     Batch:4565/6968  Loss: 4.206433725357056\n",
      "\n",
      "Epoch:    1/3     Batch:4570/6968  Loss: 4.020949745178223\n",
      "\n",
      "Epoch:    1/3     Batch:4575/6968  Loss: 4.040496349334717\n",
      "\n",
      "Epoch:    1/3     Batch:4580/6968  Loss: 4.102259826660156\n",
      "\n",
      "Epoch:    1/3     Batch:4585/6968  Loss: 4.259299278259277\n",
      "\n",
      "Epoch:    1/3     Batch:4590/6968  Loss: 4.134342384338379\n",
      "\n",
      "Epoch:    1/3     Batch:4595/6968  Loss: 4.063509702682495\n",
      "\n",
      "Epoch:    1/3     Batch:4600/6968  Loss: 3.878804922103882\n",
      "\n",
      "Epoch:    1/3     Batch:4605/6968  Loss: 4.040742063522339\n",
      "\n",
      "Epoch:    1/3     Batch:4610/6968  Loss: 4.030856657028198\n",
      "\n",
      "Epoch:    1/3     Batch:4615/6968  Loss: 4.0539556503295895\n",
      "\n",
      "Epoch:    1/3     Batch:4620/6968  Loss: 4.125331068038941\n",
      "\n",
      "Epoch:    1/3     Batch:4625/6968  Loss: 4.079235935211182\n",
      "\n",
      "Epoch:    1/3     Batch:4630/6968  Loss: 3.9892857551574705\n",
      "\n",
      "Epoch:    1/3     Batch:4635/6968  Loss: 4.101451873779297\n",
      "\n",
      "Epoch:    1/3     Batch:4640/6968  Loss: 3.9767778873443604\n",
      "\n",
      "Epoch:    1/3     Batch:4645/6968  Loss: 4.249313449859619\n",
      "\n",
      "Epoch:    1/3     Batch:4650/6968  Loss: 3.9653876781463624\n",
      "\n",
      "Epoch:    1/3     Batch:4655/6968  Loss: 4.106549692153931\n",
      "\n",
      "Epoch:    1/3     Batch:4660/6968  Loss: 4.440305709838867\n",
      "\n",
      "Epoch:    1/3     Batch:4665/6968  Loss: 4.1401043891906735\n",
      "\n",
      "Epoch:    1/3     Batch:4670/6968  Loss: 3.996077060699463\n",
      "\n",
      "Epoch:    1/3     Batch:4675/6968  Loss: 4.14042329788208\n",
      "\n",
      "Epoch:    1/3     Batch:4680/6968  Loss: 4.02727780342102\n",
      "\n",
      "Epoch:    1/3     Batch:4685/6968  Loss: 4.218103885650635\n",
      "\n",
      "Epoch:    1/3     Batch:4690/6968  Loss: 4.143760824203492\n",
      "\n",
      "Epoch:    1/3     Batch:4695/6968  Loss: 4.09026780128479\n",
      "\n",
      "Epoch:    1/3     Batch:4700/6968  Loss: 4.0981817722320555\n",
      "\n",
      "Epoch:    1/3     Batch:4705/6968  Loss: 4.303330039978027\n",
      "\n",
      "Epoch:    1/3     Batch:4710/6968  Loss: 4.187305212020874\n",
      "\n",
      "Epoch:    1/3     Batch:4715/6968  Loss: 4.0431664943695065\n",
      "\n",
      "Epoch:    1/3     Batch:4720/6968  Loss: 3.974171781539917\n",
      "\n",
      "Epoch:    1/3     Batch:4725/6968  Loss: 4.089354610443115\n",
      "\n",
      "Epoch:    1/3     Batch:4730/6968  Loss: 4.043311071395874\n",
      "\n",
      "Epoch:    1/3     Batch:4735/6968  Loss: 4.21101450920105\n",
      "\n",
      "Epoch:    1/3     Batch:4740/6968  Loss: 4.412787246704101\n",
      "\n",
      "Epoch:    1/3     Batch:4745/6968  Loss: 4.1160999774932865\n",
      "\n",
      "Epoch:    1/3     Batch:4750/6968  Loss: 4.060732078552246\n",
      "\n",
      "Epoch:    1/3     Batch:4755/6968  Loss: 3.9587279319763184\n",
      "\n",
      "Epoch:    1/3     Batch:4760/6968  Loss: 4.20183916091919\n",
      "\n",
      "Epoch:    1/3     Batch:4765/6968  Loss: 4.0998206615448\n",
      "\n",
      "Epoch:    1/3     Batch:4770/6968  Loss: 4.113442659378052\n",
      "\n",
      "Epoch:    1/3     Batch:4775/6968  Loss: 4.046040821075439\n",
      "\n",
      "Epoch:    1/3     Batch:4780/6968  Loss: 4.377703285217285\n",
      "\n",
      "Epoch:    1/3     Batch:4785/6968  Loss: 4.119327640533447\n",
      "\n",
      "Epoch:    1/3     Batch:4790/6968  Loss: 4.237945413589477\n",
      "\n",
      "Epoch:    1/3     Batch:4795/6968  Loss: 4.230613899230957\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    1/3     Batch:4800/6968  Loss: 3.911201810836792\n",
      "\n",
      "Epoch:    1/3     Batch:4805/6968  Loss: 3.9903016090393066\n",
      "\n",
      "Epoch:    1/3     Batch:4810/6968  Loss: 4.167161226272583\n",
      "\n",
      "Epoch:    1/3     Batch:4815/6968  Loss: 4.1560595512390135\n",
      "\n",
      "Epoch:    1/3     Batch:4820/6968  Loss: 4.303090190887451\n",
      "\n",
      "Epoch:    1/3     Batch:4825/6968  Loss: 3.889985466003418\n",
      "\n",
      "Epoch:    1/3     Batch:4830/6968  Loss: 3.831309604644775\n",
      "\n",
      "Epoch:    1/3     Batch:4835/6968  Loss: 4.134624195098877\n",
      "\n",
      "Epoch:    1/3     Batch:4840/6968  Loss: 3.9535356044769285\n",
      "\n",
      "Epoch:    1/3     Batch:4845/6968  Loss: 4.162876176834106\n",
      "\n",
      "Epoch:    1/3     Batch:4850/6968  Loss: 4.373470163345337\n",
      "\n",
      "Epoch:    1/3     Batch:4855/6968  Loss: 4.261623954772949\n",
      "\n",
      "Epoch:    1/3     Batch:4860/6968  Loss: 4.271462154388428\n",
      "\n",
      "Epoch:    1/3     Batch:4865/6968  Loss: 4.088104677200318\n",
      "\n",
      "Epoch:    1/3     Batch:4870/6968  Loss: 3.9106927871704102\n",
      "\n",
      "Epoch:    1/3     Batch:4875/6968  Loss: 4.260928440093994\n",
      "\n",
      "Epoch:    1/3     Batch:4880/6968  Loss: 3.9547736644744873\n",
      "\n",
      "Epoch:    1/3     Batch:4885/6968  Loss: 4.145688915252686\n",
      "\n",
      "Epoch:    1/3     Batch:4890/6968  Loss: 4.15558090209961\n",
      "\n",
      "Epoch:    1/3     Batch:4895/6968  Loss: 3.9617806911468505\n",
      "\n",
      "Epoch:    1/3     Batch:4900/6968  Loss: 3.9123933792114256\n",
      "\n",
      "Epoch:    1/3     Batch:4905/6968  Loss: 4.238373231887818\n",
      "\n",
      "Epoch:    1/3     Batch:4910/6968  Loss: 4.2405139923095705\n",
      "\n",
      "Epoch:    1/3     Batch:4915/6968  Loss: 4.261136054992676\n",
      "\n",
      "Epoch:    1/3     Batch:4920/6968  Loss: 4.0472736835479735\n",
      "\n",
      "Epoch:    1/3     Batch:4925/6968  Loss: 4.186649894714355\n",
      "\n",
      "Epoch:    1/3     Batch:4930/6968  Loss: 4.160499811172485\n",
      "\n",
      "Epoch:    1/3     Batch:4935/6968  Loss: 4.318628644943237\n",
      "\n",
      "Epoch:    1/3     Batch:4940/6968  Loss: 4.106869077682495\n",
      "\n",
      "Epoch:    1/3     Batch:4945/6968  Loss: 4.006341791152954\n",
      "\n",
      "Epoch:    1/3     Batch:4950/6968  Loss: 4.147909832000733\n",
      "\n",
      "Epoch:    1/3     Batch:4955/6968  Loss: 3.9154963970184324\n",
      "\n",
      "Epoch:    1/3     Batch:4960/6968  Loss: 4.1243593215942385\n",
      "\n",
      "Epoch:    1/3     Batch:4965/6968  Loss: 4.005873441696167\n",
      "\n",
      "Epoch:    1/3     Batch:4970/6968  Loss: 3.986935615539551\n",
      "\n",
      "Epoch:    1/3     Batch:4975/6968  Loss: 4.200815868377686\n",
      "\n",
      "Epoch:    1/3     Batch:4980/6968  Loss: 4.309074544906617\n",
      "\n",
      "Epoch:    1/3     Batch:4985/6968  Loss: 3.9432679176330567\n",
      "\n",
      "Epoch:    1/3     Batch:4990/6968  Loss: 4.1265312194824215\n",
      "\n",
      "Epoch:    1/3     Batch:4995/6968  Loss: 3.9146302223205565\n",
      "\n",
      "Epoch:    1/3     Batch:5000/6968  Loss: 3.9060158252716066\n",
      "\n",
      "Epoch:    1/3     Batch:5005/6968  Loss: 4.097655391693115\n",
      "\n",
      "Epoch:    1/3     Batch:5010/6968  Loss: 4.2776477336883545\n",
      "\n",
      "Epoch:    1/3     Batch:5015/6968  Loss: 4.250856685638428\n",
      "\n",
      "Epoch:    1/3     Batch:5020/6968  Loss: 3.970270347595215\n",
      "\n",
      "Epoch:    1/3     Batch:5025/6968  Loss: 4.052954244613647\n",
      "\n",
      "Epoch:    1/3     Batch:5030/6968  Loss: 4.001302433013916\n",
      "\n",
      "Epoch:    1/3     Batch:5035/6968  Loss: 3.933366060256958\n",
      "\n",
      "Epoch:    1/3     Batch:5040/6968  Loss: 4.064375543594361\n",
      "\n",
      "Epoch:    1/3     Batch:5045/6968  Loss: 4.245770359039307\n",
      "\n",
      "Epoch:    1/3     Batch:5050/6968  Loss: 4.273397159576416\n",
      "\n",
      "Epoch:    1/3     Batch:5055/6968  Loss: 4.068597936630249\n",
      "\n",
      "Epoch:    1/3     Batch:5060/6968  Loss: 4.142822313308716\n",
      "\n",
      "Epoch:    1/3     Batch:5065/6968  Loss: 4.006548643112183\n",
      "\n",
      "Epoch:    1/3     Batch:5070/6968  Loss: 4.022743844985962\n",
      "\n",
      "Epoch:    1/3     Batch:5075/6968  Loss: 4.344172430038452\n",
      "\n",
      "Epoch:    1/3     Batch:5080/6968  Loss: 4.088079833984375\n",
      "\n",
      "Epoch:    1/3     Batch:5085/6968  Loss: 4.151054430007934\n",
      "\n",
      "Epoch:    1/3     Batch:5090/6968  Loss: 4.133035182952881\n",
      "\n",
      "Epoch:    1/3     Batch:5095/6968  Loss: 4.113891077041626\n",
      "\n",
      "Epoch:    1/3     Batch:5100/6968  Loss: 4.284044170379639\n",
      "\n",
      "Epoch:    1/3     Batch:5105/6968  Loss: 4.1558239459991455\n",
      "\n",
      "Epoch:    1/3     Batch:5110/6968  Loss: 3.91395845413208\n",
      "\n",
      "Epoch:    1/3     Batch:5115/6968  Loss: 4.3091468334198\n",
      "\n",
      "Epoch:    1/3     Batch:5120/6968  Loss: 4.04290132522583\n",
      "\n",
      "Epoch:    1/3     Batch:5125/6968  Loss: 4.016612768173218\n",
      "\n",
      "Epoch:    1/3     Batch:5130/6968  Loss: 3.9332026481628417\n",
      "\n",
      "Epoch:    1/3     Batch:5135/6968  Loss: 4.050581407546997\n",
      "\n",
      "Epoch:    1/3     Batch:5140/6968  Loss: 4.2810746192932125\n",
      "\n",
      "Epoch:    1/3     Batch:5145/6968  Loss: 3.955800771713257\n",
      "\n",
      "Epoch:    1/3     Batch:5150/6968  Loss: 4.204747200012207\n",
      "\n",
      "Epoch:    1/3     Batch:5155/6968  Loss: 3.869861030578613\n",
      "\n",
      "Epoch:    1/3     Batch:5160/6968  Loss: 4.001069498062134\n",
      "\n",
      "Epoch:    1/3     Batch:5165/6968  Loss: 4.105078411102295\n",
      "\n",
      "Epoch:    1/3     Batch:5170/6968  Loss: 4.398182201385498\n",
      "\n",
      "Epoch:    1/3     Batch:5175/6968  Loss: 4.171877765655518\n",
      "\n",
      "Epoch:    1/3     Batch:5180/6968  Loss: 4.15929913520813\n",
      "\n",
      "Epoch:    1/3     Batch:5185/6968  Loss: 4.4323217391967775\n",
      "\n",
      "Epoch:    1/3     Batch:5190/6968  Loss: 4.069424247741699\n",
      "\n",
      "Epoch:    1/3     Batch:5195/6968  Loss: 3.898099994659424\n",
      "\n",
      "Epoch:    1/3     Batch:5200/6968  Loss: 4.008939027786255\n",
      "\n",
      "Epoch:    1/3     Batch:5205/6968  Loss: 4.0851799011230465\n",
      "\n",
      "Epoch:    1/3     Batch:5210/6968  Loss: 3.80849142074585\n",
      "\n",
      "Epoch:    1/3     Batch:5215/6968  Loss: 4.054675436019897\n",
      "\n",
      "Epoch:    1/3     Batch:5220/6968  Loss: 4.3106982707977295\n",
      "\n",
      "Epoch:    1/3     Batch:5225/6968  Loss: 4.308338928222656\n",
      "\n",
      "Epoch:    1/3     Batch:5230/6968  Loss: 4.006886577606201\n",
      "\n",
      "Epoch:    1/3     Batch:5235/6968  Loss: 3.99873366355896\n",
      "\n",
      "Epoch:    1/3     Batch:5240/6968  Loss: 4.204101514816284\n",
      "\n",
      "Epoch:    1/3     Batch:5245/6968  Loss: 3.987597608566284\n",
      "\n",
      "Epoch:    1/3     Batch:5250/6968  Loss: 4.189966821670533\n",
      "\n",
      "Epoch:    1/3     Batch:5255/6968  Loss: 3.956830310821533\n",
      "\n",
      "Epoch:    1/3     Batch:5260/6968  Loss: 4.077332782745361\n",
      "\n",
      "Epoch:    1/3     Batch:5265/6968  Loss: 4.18367280960083\n",
      "\n",
      "Epoch:    1/3     Batch:5270/6968  Loss: 3.9112993717193603\n",
      "\n",
      "Epoch:    1/3     Batch:5275/6968  Loss: 3.799742078781128\n",
      "\n",
      "Epoch:    1/3     Batch:5280/6968  Loss: 4.274055624008179\n",
      "\n",
      "Epoch:    1/3     Batch:5285/6968  Loss: 4.223827600479126\n",
      "\n",
      "Epoch:    1/3     Batch:5290/6968  Loss: 4.10946102142334\n",
      "\n",
      "Epoch:    1/3     Batch:5295/6968  Loss: 3.991503429412842\n",
      "\n",
      "Epoch:    1/3     Batch:5300/6968  Loss: 4.333047676086426\n",
      "\n",
      "Epoch:    1/3     Batch:5305/6968  Loss: 3.8322847843170167\n",
      "\n",
      "Epoch:    1/3     Batch:5310/6968  Loss: 4.153788328170776\n",
      "\n",
      "Epoch:    1/3     Batch:5315/6968  Loss: 3.9550217151641847\n",
      "\n",
      "Epoch:    1/3     Batch:5320/6968  Loss: 4.1145414352417\n",
      "\n",
      "Epoch:    1/3     Batch:5325/6968  Loss: 3.9765506744384767\n",
      "\n",
      "Epoch:    1/3     Batch:5330/6968  Loss: 3.973901796340942\n",
      "\n",
      "Epoch:    1/3     Batch:5335/6968  Loss: 4.011135244369507\n",
      "\n",
      "Epoch:    1/3     Batch:5340/6968  Loss: 4.211542749404908\n",
      "\n",
      "Epoch:    1/3     Batch:5345/6968  Loss: 4.06382737159729\n",
      "\n",
      "Epoch:    1/3     Batch:5350/6968  Loss: 3.994811487197876\n",
      "\n",
      "Epoch:    1/3     Batch:5355/6968  Loss: 4.097737169265747\n",
      "\n",
      "Epoch:    1/3     Batch:5360/6968  Loss: 4.127856349945068\n",
      "\n",
      "Epoch:    1/3     Batch:5365/6968  Loss: 4.128725528717041\n",
      "\n",
      "Epoch:    1/3     Batch:5370/6968  Loss: 4.206983375549316\n",
      "\n",
      "Epoch:    1/3     Batch:5375/6968  Loss: 3.906199550628662\n",
      "\n",
      "Epoch:    1/3     Batch:5380/6968  Loss: 3.94739670753479\n",
      "\n",
      "Epoch:    1/3     Batch:5385/6968  Loss: 3.991261863708496\n",
      "\n",
      "Epoch:    1/3     Batch:5390/6968  Loss: 4.083249235153199\n",
      "\n",
      "Epoch:    1/3     Batch:5395/6968  Loss: 4.114268016815186\n",
      "\n",
      "Epoch:    1/3     Batch:5400/6968  Loss: 4.142147064208984\n",
      "\n",
      "Epoch:    1/3     Batch:5405/6968  Loss: 4.144999837875366\n",
      "\n",
      "Epoch:    1/3     Batch:5410/6968  Loss: 4.18858962059021\n",
      "\n",
      "Epoch:    1/3     Batch:5415/6968  Loss: 4.13797779083252\n",
      "\n",
      "Epoch:    1/3     Batch:5420/6968  Loss: 4.373667240142822\n",
      "\n",
      "Epoch:    1/3     Batch:5425/6968  Loss: 4.2577108383178714\n",
      "\n",
      "Epoch:    1/3     Batch:5430/6968  Loss: 3.9247053623199464\n",
      "\n",
      "Epoch:    1/3     Batch:5435/6968  Loss: 3.844914770126343\n",
      "\n",
      "Epoch:    1/3     Batch:5440/6968  Loss: 4.15985631942749\n",
      "\n",
      "Epoch:    1/3     Batch:5445/6968  Loss: 4.156185817718506\n",
      "\n",
      "Epoch:    1/3     Batch:5450/6968  Loss: 4.286250019073487\n",
      "\n",
      "Epoch:    1/3     Batch:5455/6968  Loss: 4.08667106628418\n",
      "\n",
      "Epoch:    1/3     Batch:5460/6968  Loss: 4.190841007232666\n",
      "\n",
      "Epoch:    1/3     Batch:5465/6968  Loss: 4.165944051742554\n",
      "\n",
      "Epoch:    1/3     Batch:5470/6968  Loss: 4.085962867736816\n",
      "\n",
      "Epoch:    1/3     Batch:5475/6968  Loss: 3.964214324951172\n",
      "\n",
      "Epoch:    1/3     Batch:5480/6968  Loss: 4.280564308166504\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    1/3     Batch:5485/6968  Loss: 4.192758655548095\n",
      "\n",
      "Epoch:    1/3     Batch:5490/6968  Loss: 4.1372185230255125\n",
      "\n",
      "Epoch:    1/3     Batch:5495/6968  Loss: 4.169901180267334\n",
      "\n",
      "Epoch:    1/3     Batch:5500/6968  Loss: 4.040326261520386\n",
      "\n",
      "Epoch:    1/3     Batch:5505/6968  Loss: 4.114344739913941\n",
      "\n",
      "Epoch:    1/3     Batch:5510/6968  Loss: 4.08459792137146\n",
      "\n",
      "Epoch:    1/3     Batch:5515/6968  Loss: 3.975052833557129\n",
      "\n",
      "Epoch:    1/3     Batch:5520/6968  Loss: 3.832414245605469\n",
      "\n",
      "Epoch:    1/3     Batch:5525/6968  Loss: 4.078027677536011\n",
      "\n",
      "Epoch:    1/3     Batch:5530/6968  Loss: 4.007351350784302\n",
      "\n",
      "Epoch:    1/3     Batch:5535/6968  Loss: 3.9215002059936523\n",
      "\n",
      "Epoch:    1/3     Batch:5540/6968  Loss: 4.392729473114014\n",
      "\n",
      "Epoch:    1/3     Batch:5545/6968  Loss: 4.059539747238159\n",
      "\n",
      "Epoch:    1/3     Batch:5550/6968  Loss: 3.8567872524261473\n",
      "\n",
      "Epoch:    1/3     Batch:5555/6968  Loss: 4.105297613143921\n",
      "\n",
      "Epoch:    1/3     Batch:5560/6968  Loss: 4.0794881820678714\n",
      "\n",
      "Epoch:    1/3     Batch:5565/6968  Loss: 4.258207845687866\n",
      "\n",
      "Epoch:    1/3     Batch:5570/6968  Loss: 4.23297266960144\n",
      "\n",
      "Epoch:    1/3     Batch:5575/6968  Loss: 3.9720114707946776\n",
      "\n",
      "Epoch:    1/3     Batch:5580/6968  Loss: 4.109186697006225\n",
      "\n",
      "Epoch:    1/3     Batch:5585/6968  Loss: 4.100671625137329\n",
      "\n",
      "Epoch:    1/3     Batch:5590/6968  Loss: 4.206593561172485\n",
      "\n",
      "Epoch:    1/3     Batch:5595/6968  Loss: 4.022022008895874\n",
      "\n",
      "Epoch:    1/3     Batch:5600/6968  Loss: 4.033266401290893\n",
      "\n",
      "Epoch:    1/3     Batch:5605/6968  Loss: 3.861275005340576\n",
      "\n",
      "Epoch:    1/3     Batch:5610/6968  Loss: 4.025204515457153\n",
      "\n",
      "Epoch:    1/3     Batch:5615/6968  Loss: 4.427403545379638\n",
      "\n",
      "Epoch:    1/3     Batch:5620/6968  Loss: 4.18614559173584\n",
      "\n",
      "Epoch:    1/3     Batch:5625/6968  Loss: 4.022891855239868\n",
      "\n",
      "Epoch:    1/3     Batch:5630/6968  Loss: 4.153292894363403\n",
      "\n",
      "Epoch:    1/3     Batch:5635/6968  Loss: 4.137969303131103\n",
      "\n",
      "Epoch:    1/3     Batch:5640/6968  Loss: 3.916415643692017\n",
      "\n",
      "Epoch:    1/3     Batch:5645/6968  Loss: 4.072527503967285\n",
      "\n",
      "Epoch:    1/3     Batch:5650/6968  Loss: 4.1685021877288815\n",
      "\n",
      "Epoch:    1/3     Batch:5655/6968  Loss: 4.171139764785766\n",
      "\n",
      "Epoch:    1/3     Batch:5660/6968  Loss: 4.208099365234375\n",
      "\n",
      "Epoch:    1/3     Batch:5665/6968  Loss: 4.017380952835083\n",
      "\n",
      "Epoch:    1/3     Batch:5670/6968  Loss: 3.9845202445983885\n",
      "\n",
      "Epoch:    1/3     Batch:5675/6968  Loss: 4.060373020172119\n",
      "\n",
      "Epoch:    1/3     Batch:5680/6968  Loss: 4.113573932647705\n",
      "\n",
      "Epoch:    1/3     Batch:5685/6968  Loss: 3.938830041885376\n",
      "\n",
      "Epoch:    1/3     Batch:5690/6968  Loss: 3.913267803192139\n",
      "\n",
      "Epoch:    1/3     Batch:5695/6968  Loss: 4.155334949493408\n",
      "\n",
      "Epoch:    1/3     Batch:5700/6968  Loss: 4.099452877044678\n",
      "\n",
      "Epoch:    1/3     Batch:5705/6968  Loss: 4.11458797454834\n",
      "\n",
      "Epoch:    1/3     Batch:5710/6968  Loss: 4.0772397994995115\n",
      "\n",
      "Epoch:    1/3     Batch:5715/6968  Loss: 3.974379301071167\n",
      "\n",
      "Epoch:    1/3     Batch:5720/6968  Loss: 4.2603809356689455\n",
      "\n",
      "Epoch:    1/3     Batch:5725/6968  Loss: 4.131353139877319\n",
      "\n",
      "Epoch:    1/3     Batch:5730/6968  Loss: 4.036737251281738\n",
      "\n",
      "Epoch:    1/3     Batch:5735/6968  Loss: 4.008012008666992\n",
      "\n",
      "Epoch:    1/3     Batch:5740/6968  Loss: 4.15396294593811\n",
      "\n",
      "Epoch:    1/3     Batch:5745/6968  Loss: 4.04055643081665\n",
      "\n",
      "Epoch:    1/3     Batch:5750/6968  Loss: 4.011256694793701\n",
      "\n",
      "Epoch:    1/3     Batch:5755/6968  Loss: 4.136015319824219\n",
      "\n",
      "Epoch:    1/3     Batch:5760/6968  Loss: 3.8204723834991454\n",
      "\n",
      "Epoch:    1/3     Batch:5765/6968  Loss: 4.026190280914307\n",
      "\n",
      "Epoch:    1/3     Batch:5770/6968  Loss: 4.001552534103394\n",
      "\n",
      "Epoch:    1/3     Batch:5775/6968  Loss: 4.0973046779632565\n",
      "\n",
      "Epoch:    1/3     Batch:5780/6968  Loss: 4.011101961135864\n",
      "\n",
      "Epoch:    1/3     Batch:5785/6968  Loss: 3.93514142036438\n",
      "\n",
      "Epoch:    1/3     Batch:5790/6968  Loss: 4.051027774810791\n",
      "\n",
      "Epoch:    1/3     Batch:5795/6968  Loss: 4.1883642196655275\n",
      "\n",
      "Epoch:    1/3     Batch:5800/6968  Loss: 3.975900936126709\n",
      "\n",
      "Epoch:    1/3     Batch:5805/6968  Loss: 4.026101160049438\n",
      "\n",
      "Epoch:    1/3     Batch:5810/6968  Loss: 3.9691186428070067\n",
      "\n",
      "Epoch:    1/3     Batch:5815/6968  Loss: 4.087291193008423\n",
      "\n",
      "Epoch:    1/3     Batch:5820/6968  Loss: 4.119428920745849\n",
      "\n",
      "Epoch:    1/3     Batch:5825/6968  Loss: 3.946617317199707\n",
      "\n",
      "Epoch:    1/3     Batch:5830/6968  Loss: 4.225497388839722\n",
      "\n",
      "Epoch:    1/3     Batch:5835/6968  Loss: 4.003216648101807\n",
      "\n",
      "Epoch:    1/3     Batch:5840/6968  Loss: 3.780917739868164\n",
      "\n",
      "Epoch:    1/3     Batch:5845/6968  Loss: 4.2218585968017575\n",
      "\n",
      "Epoch:    1/3     Batch:5850/6968  Loss: 4.12225604057312\n",
      "\n",
      "Epoch:    1/3     Batch:5855/6968  Loss: 4.0179847240447994\n",
      "\n",
      "Epoch:    1/3     Batch:5860/6968  Loss: 3.950698471069336\n",
      "\n",
      "Epoch:    1/3     Batch:5865/6968  Loss: 3.8894495487213137\n",
      "\n",
      "Epoch:    1/3     Batch:5870/6968  Loss: 4.065297842025757\n",
      "\n",
      "Epoch:    1/3     Batch:5875/6968  Loss: 3.9254141330718992\n",
      "\n",
      "Epoch:    1/3     Batch:5880/6968  Loss: 4.055063486099243\n",
      "\n",
      "Epoch:    1/3     Batch:5885/6968  Loss: 4.160956716537475\n",
      "\n",
      "Epoch:    1/3     Batch:5890/6968  Loss: 4.079942893981934\n",
      "\n",
      "Epoch:    1/3     Batch:5895/6968  Loss: 3.94677357673645\n",
      "\n",
      "Epoch:    1/3     Batch:5900/6968  Loss: 4.319372320175171\n",
      "\n",
      "Epoch:    1/3     Batch:5905/6968  Loss: 4.153597497940064\n",
      "\n",
      "Epoch:    1/3     Batch:5910/6968  Loss: 4.091708946228027\n",
      "\n",
      "Epoch:    1/3     Batch:5915/6968  Loss: 3.685486602783203\n",
      "\n",
      "Epoch:    1/3     Batch:5920/6968  Loss: 4.255272960662841\n",
      "\n",
      "Epoch:    1/3     Batch:5925/6968  Loss: 3.749744749069214\n",
      "\n",
      "Epoch:    1/3     Batch:5930/6968  Loss: 4.016441917419433\n",
      "\n",
      "Epoch:    1/3     Batch:5935/6968  Loss: 3.9673100471496583\n",
      "\n",
      "Epoch:    1/3     Batch:5940/6968  Loss: 4.24712119102478\n",
      "\n",
      "Epoch:    1/3     Batch:5945/6968  Loss: 3.9548863887786867\n",
      "\n",
      "Epoch:    1/3     Batch:5950/6968  Loss: 4.225401115417481\n",
      "\n",
      "Epoch:    1/3     Batch:5955/6968  Loss: 3.9664917469024656\n",
      "\n",
      "Epoch:    1/3     Batch:5960/6968  Loss: 4.181810474395752\n",
      "\n",
      "Epoch:    1/3     Batch:5965/6968  Loss: 3.835901403427124\n",
      "\n",
      "Epoch:    1/3     Batch:5970/6968  Loss: 4.135167837142944\n",
      "\n",
      "Epoch:    1/3     Batch:5975/6968  Loss: 4.234442663192749\n",
      "\n",
      "Epoch:    1/3     Batch:5980/6968  Loss: 3.9116312980651857\n",
      "\n",
      "Epoch:    1/3     Batch:5985/6968  Loss: 4.046511840820313\n",
      "\n",
      "Epoch:    1/3     Batch:5990/6968  Loss: 3.996932601928711\n",
      "\n",
      "Epoch:    1/3     Batch:5995/6968  Loss: 4.189312314987182\n",
      "\n",
      "Epoch:    1/3     Batch:6000/6968  Loss: 4.229082536697388\n",
      "\n",
      "Epoch:    1/3     Batch:6005/6968  Loss: 3.9826478004455566\n",
      "\n",
      "Epoch:    1/3     Batch:6010/6968  Loss: 4.176981830596924\n",
      "\n",
      "Epoch:    1/3     Batch:6015/6968  Loss: 3.9665746688842773\n",
      "\n",
      "Epoch:    1/3     Batch:6020/6968  Loss: 4.179813814163208\n",
      "\n",
      "Epoch:    1/3     Batch:6025/6968  Loss: 4.270141983032227\n",
      "\n",
      "Epoch:    1/3     Batch:6030/6968  Loss: 3.829933261871338\n",
      "\n",
      "Epoch:    1/3     Batch:6035/6968  Loss: 4.168768310546875\n",
      "\n",
      "Epoch:    1/3     Batch:6040/6968  Loss: 3.9686264991760254\n",
      "\n",
      "Epoch:    1/3     Batch:6045/6968  Loss: 4.175932455062866\n",
      "\n",
      "Epoch:    1/3     Batch:6050/6968  Loss: 4.335526657104492\n",
      "\n",
      "Epoch:    1/3     Batch:6055/6968  Loss: 4.084734106063843\n",
      "\n",
      "Epoch:    1/3     Batch:6060/6968  Loss: 3.9481568336486816\n",
      "\n",
      "Epoch:    1/3     Batch:6065/6968  Loss: 3.9217551231384276\n",
      "\n",
      "Epoch:    1/3     Batch:6070/6968  Loss: 4.028500032424927\n",
      "\n",
      "Epoch:    1/3     Batch:6075/6968  Loss: 4.015953826904297\n",
      "\n",
      "Epoch:    1/3     Batch:6080/6968  Loss: 4.267898178100586\n",
      "\n",
      "Epoch:    1/3     Batch:6085/6968  Loss: 4.066869878768921\n",
      "\n",
      "Epoch:    1/3     Batch:6090/6968  Loss: 3.942945146560669\n",
      "\n",
      "Epoch:    1/3     Batch:6095/6968  Loss: 4.078152275085449\n",
      "\n",
      "Epoch:    1/3     Batch:6100/6968  Loss: 3.9554257869720457\n",
      "\n",
      "Epoch:    1/3     Batch:6105/6968  Loss: 4.025511169433594\n",
      "\n",
      "Epoch:    1/3     Batch:6110/6968  Loss: 4.252525997161865\n",
      "\n",
      "Epoch:    1/3     Batch:6115/6968  Loss: 4.290149974822998\n",
      "\n",
      "Epoch:    1/3     Batch:6120/6968  Loss: 4.093767786026001\n",
      "\n",
      "Epoch:    1/3     Batch:6125/6968  Loss: 3.9503848552703857\n",
      "\n",
      "Epoch:    1/3     Batch:6130/6968  Loss: 4.007947063446045\n",
      "\n",
      "Epoch:    1/3     Batch:6135/6968  Loss: 4.09467043876648\n",
      "\n",
      "Epoch:    1/3     Batch:6140/6968  Loss: 4.142049169540405\n",
      "\n",
      "Epoch:    1/3     Batch:6145/6968  Loss: 4.330931711196899\n",
      "\n",
      "Epoch:    1/3     Batch:6150/6968  Loss: 4.128264236450195\n",
      "\n",
      "Epoch:    1/3     Batch:6155/6968  Loss: 4.101963949203491\n",
      "\n",
      "Epoch:    1/3     Batch:6160/6968  Loss: 4.087832975387573\n",
      "\n",
      "Epoch:    1/3     Batch:6165/6968  Loss: 4.09395318031311\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    1/3     Batch:6170/6968  Loss: 4.257771635055542\n",
      "\n",
      "Epoch:    1/3     Batch:6175/6968  Loss: 4.157854461669922\n",
      "\n",
      "Epoch:    1/3     Batch:6180/6968  Loss: 3.933509683609009\n",
      "\n",
      "Epoch:    1/3     Batch:6185/6968  Loss: 4.160577011108399\n",
      "\n",
      "Epoch:    1/3     Batch:6190/6968  Loss: 4.10240683555603\n",
      "\n",
      "Epoch:    1/3     Batch:6195/6968  Loss: 4.289689016342163\n",
      "\n",
      "Epoch:    1/3     Batch:6200/6968  Loss: 3.959814500808716\n",
      "\n",
      "Epoch:    1/3     Batch:6205/6968  Loss: 4.054357957839966\n",
      "\n",
      "Epoch:    1/3     Batch:6210/6968  Loss: 4.003375244140625\n",
      "\n",
      "Epoch:    1/3     Batch:6215/6968  Loss: 3.9349711894989015\n",
      "\n",
      "Epoch:    1/3     Batch:6220/6968  Loss: 3.915303945541382\n",
      "\n",
      "Epoch:    1/3     Batch:6225/6968  Loss: 3.9115952491760253\n",
      "\n",
      "Epoch:    1/3     Batch:6230/6968  Loss: 4.2053595066070555\n",
      "\n",
      "Epoch:    1/3     Batch:6235/6968  Loss: 4.1535115242004395\n",
      "\n",
      "Epoch:    1/3     Batch:6240/6968  Loss: 4.24842472076416\n",
      "\n",
      "Epoch:    1/3     Batch:6245/6968  Loss: 4.125619888305664\n",
      "\n",
      "Epoch:    1/3     Batch:6250/6968  Loss: 3.9610643863677977\n",
      "\n",
      "Epoch:    1/3     Batch:6255/6968  Loss: 4.0210045337677\n",
      "\n",
      "Epoch:    1/3     Batch:6260/6968  Loss: 3.8307793140411377\n",
      "\n",
      "Epoch:    1/3     Batch:6265/6968  Loss: 4.08115520477295\n",
      "\n",
      "Epoch:    1/3     Batch:6270/6968  Loss: 3.955375385284424\n",
      "\n",
      "Epoch:    1/3     Batch:6275/6968  Loss: 3.8333730697631836\n",
      "\n",
      "Epoch:    1/3     Batch:6280/6968  Loss: 4.032314443588257\n",
      "\n",
      "Epoch:    1/3     Batch:6285/6968  Loss: 4.137163591384888\n",
      "\n",
      "Epoch:    1/3     Batch:6290/6968  Loss: 3.930086135864258\n",
      "\n",
      "Epoch:    1/3     Batch:6295/6968  Loss: 4.210147476196289\n",
      "\n",
      "Epoch:    1/3     Batch:6300/6968  Loss: 3.847239780426025\n",
      "\n",
      "Epoch:    1/3     Batch:6305/6968  Loss: 3.899891710281372\n",
      "\n",
      "Epoch:    1/3     Batch:6310/6968  Loss: 3.8887802600860595\n",
      "\n",
      "Epoch:    1/3     Batch:6315/6968  Loss: 4.223473167419433\n",
      "\n",
      "Epoch:    1/3     Batch:6320/6968  Loss: 4.180766773223877\n",
      "\n",
      "Epoch:    1/3     Batch:6325/6968  Loss: 4.094694042205811\n",
      "\n",
      "Epoch:    1/3     Batch:6330/6968  Loss: 4.314985942840576\n",
      "\n",
      "Epoch:    1/3     Batch:6335/6968  Loss: 4.1306709289550785\n",
      "\n",
      "Epoch:    1/3     Batch:6340/6968  Loss: 4.34407320022583\n",
      "\n",
      "Epoch:    1/3     Batch:6345/6968  Loss: 4.1382359027862545\n",
      "\n",
      "Epoch:    1/3     Batch:6350/6968  Loss: 3.945073938369751\n",
      "\n",
      "Epoch:    1/3     Batch:6355/6968  Loss: 3.991303730010986\n",
      "\n",
      "Epoch:    1/3     Batch:6360/6968  Loss: 4.014823961257934\n",
      "\n",
      "Epoch:    1/3     Batch:6365/6968  Loss: 4.028110599517822\n",
      "\n",
      "Epoch:    1/3     Batch:6370/6968  Loss: 3.7975093841552736\n",
      "\n",
      "Epoch:    1/3     Batch:6375/6968  Loss: 4.098429441452026\n",
      "\n",
      "Epoch:    1/3     Batch:6380/6968  Loss: 4.101461553573609\n",
      "\n",
      "Epoch:    1/3     Batch:6385/6968  Loss: 4.19731822013855\n",
      "\n",
      "Epoch:    1/3     Batch:6390/6968  Loss: 3.977267837524414\n",
      "\n",
      "Epoch:    1/3     Batch:6395/6968  Loss: 4.29421591758728\n",
      "\n",
      "Epoch:    1/3     Batch:6400/6968  Loss: 3.897159719467163\n",
      "\n",
      "Epoch:    1/3     Batch:6405/6968  Loss: 3.896435022354126\n",
      "\n",
      "Epoch:    1/3     Batch:6410/6968  Loss: 3.8172046661376955\n",
      "\n",
      "Epoch:    1/3     Batch:6415/6968  Loss: 4.104276466369629\n",
      "\n",
      "Epoch:    1/3     Batch:6420/6968  Loss: 4.008066463470459\n",
      "\n",
      "Epoch:    1/3     Batch:6425/6968  Loss: 3.9301151275634765\n",
      "\n",
      "Epoch:    1/3     Batch:6430/6968  Loss: 4.04689359664917\n",
      "\n",
      "Epoch:    1/3     Batch:6435/6968  Loss: 4.008800077438354\n",
      "\n",
      "Epoch:    1/3     Batch:6440/6968  Loss: 4.154408359527588\n",
      "\n",
      "Epoch:    1/3     Batch:6445/6968  Loss: 4.181524229049683\n",
      "\n",
      "Epoch:    1/3     Batch:6450/6968  Loss: 4.118602466583252\n",
      "\n",
      "Epoch:    1/3     Batch:6455/6968  Loss: 3.8309895515441896\n",
      "\n",
      "Epoch:    1/3     Batch:6460/6968  Loss: 4.0939874172210695\n",
      "\n",
      "Epoch:    1/3     Batch:6465/6968  Loss: 3.903503179550171\n",
      "\n",
      "Epoch:    1/3     Batch:6470/6968  Loss: 3.9615105628967284\n",
      "\n",
      "Epoch:    1/3     Batch:6475/6968  Loss: 3.9372912883758544\n",
      "\n",
      "Epoch:    1/3     Batch:6480/6968  Loss: 4.07072696685791\n",
      "\n",
      "Epoch:    1/3     Batch:6485/6968  Loss: 4.027984380722046\n",
      "\n",
      "Epoch:    1/3     Batch:6490/6968  Loss: 4.106580591201782\n",
      "\n",
      "Epoch:    1/3     Batch:6495/6968  Loss: 4.041161060333252\n",
      "\n",
      "Epoch:    1/3     Batch:6500/6968  Loss: 3.919182777404785\n",
      "\n",
      "Epoch:    1/3     Batch:6505/6968  Loss: 3.7771520137786867\n",
      "\n",
      "Epoch:    1/3     Batch:6510/6968  Loss: 3.8429646492004395\n",
      "\n",
      "Epoch:    1/3     Batch:6515/6968  Loss: 4.020415735244751\n",
      "\n",
      "Epoch:    1/3     Batch:6520/6968  Loss: 3.9268330097198487\n",
      "\n",
      "Epoch:    1/3     Batch:6525/6968  Loss: 4.186925411224365\n",
      "\n",
      "Epoch:    1/3     Batch:6530/6968  Loss: 4.338416862487793\n",
      "\n",
      "Epoch:    1/3     Batch:6535/6968  Loss: 4.276811647415161\n",
      "\n",
      "Epoch:    1/3     Batch:6540/6968  Loss: 4.101159191131591\n",
      "\n",
      "Epoch:    1/3     Batch:6545/6968  Loss: 4.2952735900878904\n",
      "\n",
      "Epoch:    1/3     Batch:6550/6968  Loss: 4.128049373626709\n",
      "\n",
      "Epoch:    1/3     Batch:6555/6968  Loss: 4.2475587844848635\n",
      "\n",
      "Epoch:    1/3     Batch:6560/6968  Loss: 3.9087119579315184\n",
      "\n",
      "Epoch:    1/3     Batch:6565/6968  Loss: 3.9673107147216795\n",
      "\n",
      "Epoch:    1/3     Batch:6570/6968  Loss: 3.9733674049377443\n",
      "\n",
      "Epoch:    1/3     Batch:6575/6968  Loss: 3.8436076164245607\n",
      "\n",
      "Epoch:    1/3     Batch:6580/6968  Loss: 3.935231924057007\n",
      "\n",
      "Epoch:    1/3     Batch:6585/6968  Loss: 4.278468132019043\n",
      "\n",
      "Epoch:    1/3     Batch:6590/6968  Loss: 3.9019644260406494\n",
      "\n",
      "Epoch:    1/3     Batch:6595/6968  Loss: 3.9070096969604493\n",
      "\n",
      "Epoch:    1/3     Batch:6600/6968  Loss: 3.7209716796875\n",
      "\n",
      "Epoch:    1/3     Batch:6605/6968  Loss: 4.162387800216675\n",
      "\n",
      "Epoch:    1/3     Batch:6610/6968  Loss: 4.0659760475158695\n",
      "\n",
      "Epoch:    1/3     Batch:6615/6968  Loss: 3.972652864456177\n",
      "\n",
      "Epoch:    1/3     Batch:6620/6968  Loss: 4.010361909866333\n",
      "\n",
      "Epoch:    1/3     Batch:6625/6968  Loss: 4.041689348220825\n",
      "\n",
      "Epoch:    1/3     Batch:6630/6968  Loss: 4.123465728759766\n",
      "\n",
      "Epoch:    1/3     Batch:6635/6968  Loss: 3.8217034339904785\n",
      "\n",
      "Epoch:    1/3     Batch:6640/6968  Loss: 3.96181001663208\n",
      "\n",
      "Epoch:    1/3     Batch:6645/6968  Loss: 4.206220245361328\n",
      "\n",
      "Epoch:    1/3     Batch:6650/6968  Loss: 4.105668592453003\n",
      "\n",
      "Epoch:    1/3     Batch:6655/6968  Loss: 4.035612297058106\n",
      "\n",
      "Epoch:    1/3     Batch:6660/6968  Loss: 4.0694732666015625\n",
      "\n",
      "Epoch:    1/3     Batch:6665/6968  Loss: 3.9020928859710695\n",
      "\n",
      "Epoch:    1/3     Batch:6670/6968  Loss: 4.2384681224823\n",
      "\n",
      "Epoch:    1/3     Batch:6675/6968  Loss: 4.008628940582275\n",
      "\n",
      "Epoch:    1/3     Batch:6680/6968  Loss: 4.038595485687256\n",
      "\n",
      "Epoch:    1/3     Batch:6685/6968  Loss: 3.937582778930664\n",
      "\n",
      "Epoch:    1/3     Batch:6690/6968  Loss: 3.928799533843994\n",
      "\n",
      "Epoch:    1/3     Batch:6695/6968  Loss: 4.34092116355896\n",
      "\n",
      "Epoch:    1/3     Batch:6700/6968  Loss: 4.254423952102661\n",
      "\n",
      "Epoch:    1/3     Batch:6705/6968  Loss: 3.874917984008789\n",
      "\n",
      "Epoch:    1/3     Batch:6710/6968  Loss: 3.9368913173675537\n",
      "\n",
      "Epoch:    1/3     Batch:6715/6968  Loss: 4.2463463306427\n",
      "\n",
      "Epoch:    1/3     Batch:6720/6968  Loss: 3.900852108001709\n",
      "\n",
      "Epoch:    1/3     Batch:6725/6968  Loss: 3.9326494693756104\n",
      "\n",
      "Epoch:    1/3     Batch:6730/6968  Loss: 4.293987703323364\n",
      "\n",
      "Epoch:    1/3     Batch:6735/6968  Loss: 3.9171119213104246\n",
      "\n",
      "Epoch:    1/3     Batch:6740/6968  Loss: 3.749389982223511\n",
      "\n",
      "Epoch:    1/3     Batch:6745/6968  Loss: 4.130141162872315\n",
      "\n",
      "Epoch:    1/3     Batch:6750/6968  Loss: 4.070676660537719\n",
      "\n",
      "Epoch:    1/3     Batch:6755/6968  Loss: 4.107305240631104\n",
      "\n",
      "Epoch:    1/3     Batch:6760/6968  Loss: 3.92112021446228\n",
      "\n",
      "Epoch:    1/3     Batch:6765/6968  Loss: 3.941239833831787\n",
      "\n",
      "Epoch:    1/3     Batch:6770/6968  Loss: 4.135076713562012\n",
      "\n",
      "Epoch:    1/3     Batch:6775/6968  Loss: 3.9890628337860106\n",
      "\n",
      "Epoch:    1/3     Batch:6780/6968  Loss: 4.03505277633667\n",
      "\n",
      "Epoch:    1/3     Batch:6785/6968  Loss: 3.951939916610718\n",
      "\n",
      "Epoch:    1/3     Batch:6790/6968  Loss: 4.053242254257202\n",
      "\n",
      "Epoch:    1/3     Batch:6795/6968  Loss: 3.745275545120239\n",
      "\n",
      "Epoch:    1/3     Batch:6800/6968  Loss: 4.126531076431275\n",
      "\n",
      "Epoch:    1/3     Batch:6805/6968  Loss: 3.9448551654815676\n",
      "\n",
      "Epoch:    1/3     Batch:6810/6968  Loss: 4.103658246994018\n",
      "\n",
      "Epoch:    1/3     Batch:6815/6968  Loss: 4.017889070510864\n",
      "\n",
      "Epoch:    1/3     Batch:6820/6968  Loss: 4.249953079223633\n",
      "\n",
      "Epoch:    1/3     Batch:6825/6968  Loss: 3.9241474628448487\n",
      "\n",
      "Epoch:    1/3     Batch:6830/6968  Loss: 4.004827690124512\n",
      "\n",
      "Epoch:    1/3     Batch:6835/6968  Loss: 4.013932943344116\n",
      "\n",
      "Epoch:    1/3     Batch:6840/6968  Loss: 4.103694725036621\n",
      "\n",
      "Epoch:    1/3     Batch:6845/6968  Loss: 4.13899941444397\n",
      "\n",
      "Epoch:    1/3     Batch:6850/6968  Loss: 4.018004512786865\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    1/3     Batch:6855/6968  Loss: 4.091058921813965\n",
      "\n",
      "Epoch:    1/3     Batch:6860/6968  Loss: 4.222443342208862\n",
      "\n",
      "Epoch:    1/3     Batch:6865/6968  Loss: 4.026665925979614\n",
      "\n",
      "Epoch:    1/3     Batch:6870/6968  Loss: 4.072339248657227\n",
      "\n",
      "Epoch:    1/3     Batch:6875/6968  Loss: 4.0000901222229\n",
      "\n",
      "Epoch:    1/3     Batch:6880/6968  Loss: 4.033051300048828\n",
      "\n",
      "Epoch:    1/3     Batch:6885/6968  Loss: 3.8992119312286375\n",
      "\n",
      "Epoch:    1/3     Batch:6890/6968  Loss: 4.136834716796875\n",
      "\n",
      "Epoch:    1/3     Batch:6895/6968  Loss: 4.22398567199707\n",
      "\n",
      "Epoch:    1/3     Batch:6900/6968  Loss: 3.8585317134857178\n",
      "\n",
      "Epoch:    1/3     Batch:6905/6968  Loss: 4.190039110183716\n",
      "\n",
      "Epoch:    1/3     Batch:6910/6968  Loss: 3.8949381828308107\n",
      "\n",
      "Epoch:    1/3     Batch:6915/6968  Loss: 4.262881231307984\n",
      "\n",
      "Epoch:    1/3     Batch:6920/6968  Loss: 3.9776817321777345\n",
      "\n",
      "Epoch:    1/3     Batch:6925/6968  Loss: 3.873207855224609\n",
      "\n",
      "Epoch:    1/3     Batch:6930/6968  Loss: 4.271067333221436\n",
      "\n",
      "Epoch:    1/3     Batch:6935/6968  Loss: 3.9959056854248045\n",
      "\n",
      "Epoch:    1/3     Batch:6940/6968  Loss: 4.031780433654785\n",
      "\n",
      "Epoch:    1/3     Batch:6945/6968  Loss: 3.781020259857178\n",
      "\n",
      "Epoch:    1/3     Batch:6950/6968  Loss: 4.0664280414581295\n",
      "\n",
      "Epoch:    1/3     Batch:6955/6968  Loss: 3.9990957260131834\n",
      "\n",
      "Epoch:    1/3     Batch:6960/6968  Loss: 3.7046277046203615\n",
      "\n",
      "Epoch:    1/3     Batch:6965/6968  Loss: 4.270756959915161\n",
      "\n",
      "Epoch:    2/3     Batch:   5/6968  Loss: 3.8375951051712036\n",
      "\n",
      "Epoch:    2/3     Batch:  10/6968  Loss: 3.9062339782714846\n",
      "\n",
      "Epoch:    2/3     Batch:  15/6968  Loss: 4.089404344558716\n",
      "\n",
      "Epoch:    2/3     Batch:  20/6968  Loss: 3.804975128173828\n",
      "\n",
      "Epoch:    2/3     Batch:  25/6968  Loss: 3.910044956207275\n",
      "\n",
      "Epoch:    2/3     Batch:  30/6968  Loss: 3.922991228103638\n",
      "\n",
      "Epoch:    2/3     Batch:  35/6968  Loss: 3.6907708644866943\n",
      "\n",
      "Epoch:    2/3     Batch:  40/6968  Loss: 3.6591708660125732\n",
      "\n",
      "Epoch:    2/3     Batch:  45/6968  Loss: 3.7968507766723634\n",
      "\n",
      "Epoch:    2/3     Batch:  50/6968  Loss: 4.009484434127808\n",
      "\n",
      "Epoch:    2/3     Batch:  55/6968  Loss: 3.8541167259216307\n",
      "\n",
      "Epoch:    2/3     Batch:  60/6968  Loss: 4.277485942840576\n",
      "\n",
      "Epoch:    2/3     Batch:  65/6968  Loss: 3.6218573093414306\n",
      "\n",
      "Epoch:    2/3     Batch:  70/6968  Loss: 3.817328691482544\n",
      "\n",
      "Epoch:    2/3     Batch:  75/6968  Loss: 3.9541603565216064\n",
      "\n",
      "Epoch:    2/3     Batch:  80/6968  Loss: 3.8409358978271486\n",
      "\n",
      "Epoch:    2/3     Batch:  85/6968  Loss: 3.769163990020752\n",
      "\n",
      "Epoch:    2/3     Batch:  90/6968  Loss: 3.9137954235076906\n",
      "\n",
      "Epoch:    2/3     Batch:  95/6968  Loss: 3.6616002559661864\n",
      "\n",
      "Epoch:    2/3     Batch: 100/6968  Loss: 3.823439121246338\n",
      "\n",
      "Epoch:    2/3     Batch: 105/6968  Loss: 3.8620104789733887\n",
      "\n",
      "Epoch:    2/3     Batch: 110/6968  Loss: 3.777617883682251\n",
      "\n",
      "Epoch:    2/3     Batch: 115/6968  Loss: 3.6679303646087646\n",
      "\n",
      "Epoch:    2/3     Batch: 120/6968  Loss: 3.9158236980438232\n",
      "\n",
      "Epoch:    2/3     Batch: 125/6968  Loss: 3.9453318119049072\n",
      "\n",
      "Epoch:    2/3     Batch: 130/6968  Loss: 3.728509712219238\n",
      "\n",
      "Epoch:    2/3     Batch: 135/6968  Loss: 3.9871665954589846\n",
      "\n",
      "Epoch:    2/3     Batch: 140/6968  Loss: 3.9119373321533204\n",
      "\n",
      "Epoch:    2/3     Batch: 145/6968  Loss: 3.817793369293213\n",
      "\n",
      "Epoch:    2/3     Batch: 150/6968  Loss: 3.967712926864624\n",
      "\n",
      "Epoch:    2/3     Batch: 155/6968  Loss: 3.8741097450256348\n",
      "\n",
      "Epoch:    2/3     Batch: 160/6968  Loss: 3.860782241821289\n",
      "\n",
      "Epoch:    2/3     Batch: 165/6968  Loss: 3.869411897659302\n",
      "\n",
      "Epoch:    2/3     Batch: 170/6968  Loss: 3.726091241836548\n",
      "\n",
      "Epoch:    2/3     Batch: 175/6968  Loss: 3.8664105892181397\n",
      "\n",
      "Epoch:    2/3     Batch: 180/6968  Loss: 3.9150098323822022\n",
      "\n",
      "Epoch:    2/3     Batch: 185/6968  Loss: 3.6833717823028564\n",
      "\n",
      "Epoch:    2/3     Batch: 190/6968  Loss: 3.997533655166626\n",
      "\n",
      "Epoch:    2/3     Batch: 195/6968  Loss: 3.9912204265594484\n",
      "\n",
      "Epoch:    2/3     Batch: 200/6968  Loss: 3.8463494777679443\n",
      "\n",
      "Epoch:    2/3     Batch: 205/6968  Loss: 3.9363680362701414\n",
      "\n",
      "Epoch:    2/3     Batch: 210/6968  Loss: 3.483928394317627\n",
      "\n",
      "Epoch:    2/3     Batch: 215/6968  Loss: 3.958902931213379\n",
      "\n",
      "Epoch:    2/3     Batch: 220/6968  Loss: 3.755408191680908\n",
      "\n",
      "Epoch:    2/3     Batch: 225/6968  Loss: 3.800084447860718\n",
      "\n",
      "Epoch:    2/3     Batch: 230/6968  Loss: 3.6805238246917726\n",
      "\n",
      "Epoch:    2/3     Batch: 235/6968  Loss: 3.9101760387420654\n",
      "\n",
      "Epoch:    2/3     Batch: 240/6968  Loss: 3.9523999214172365\n",
      "\n",
      "Epoch:    2/3     Batch: 245/6968  Loss: 4.028666400909424\n",
      "\n",
      "Epoch:    2/3     Batch: 250/6968  Loss: 3.9978124141693114\n",
      "\n",
      "Epoch:    2/3     Batch: 255/6968  Loss: 3.8258190155029297\n",
      "\n",
      "Epoch:    2/3     Batch: 260/6968  Loss: 3.6356685638427733\n",
      "\n",
      "Epoch:    2/3     Batch: 265/6968  Loss: 3.910389709472656\n",
      "\n",
      "Epoch:    2/3     Batch: 270/6968  Loss: 3.6231781959533693\n",
      "\n",
      "Epoch:    2/3     Batch: 275/6968  Loss: 3.8388561248779296\n",
      "\n",
      "Epoch:    2/3     Batch: 280/6968  Loss: 3.9868895053863525\n",
      "\n",
      "Epoch:    2/3     Batch: 285/6968  Loss: 3.725834035873413\n",
      "\n",
      "Epoch:    2/3     Batch: 290/6968  Loss: 3.9123509883880616\n",
      "\n",
      "Epoch:    2/3     Batch: 295/6968  Loss: 3.8533121585845946\n",
      "\n",
      "Epoch:    2/3     Batch: 300/6968  Loss: 3.9316743850708007\n",
      "\n",
      "Epoch:    2/3     Batch: 305/6968  Loss: 3.814292287826538\n",
      "\n",
      "Epoch:    2/3     Batch: 310/6968  Loss: 4.00169358253479\n",
      "\n",
      "Epoch:    2/3     Batch: 315/6968  Loss: 3.675992155075073\n",
      "\n",
      "Epoch:    2/3     Batch: 320/6968  Loss: 3.9015693187713625\n",
      "\n",
      "Epoch:    2/3     Batch: 325/6968  Loss: 3.8830682754516603\n",
      "\n",
      "Epoch:    2/3     Batch: 330/6968  Loss: 3.892307472229004\n",
      "\n",
      "Epoch:    2/3     Batch: 335/6968  Loss: 3.752358865737915\n",
      "\n",
      "Epoch:    2/3     Batch: 340/6968  Loss: 3.9860209941864015\n",
      "\n",
      "Epoch:    2/3     Batch: 345/6968  Loss: 3.882274866104126\n",
      "\n",
      "Epoch:    2/3     Batch: 350/6968  Loss: 3.700583028793335\n",
      "\n",
      "Epoch:    2/3     Batch: 355/6968  Loss: 3.7720077991485597\n",
      "\n",
      "Epoch:    2/3     Batch: 360/6968  Loss: 3.794128751754761\n",
      "\n",
      "Epoch:    2/3     Batch: 365/6968  Loss: 3.699369192123413\n",
      "\n",
      "Epoch:    2/3     Batch: 370/6968  Loss: 3.862719011306763\n",
      "\n",
      "Epoch:    2/3     Batch: 375/6968  Loss: 4.150498771667481\n",
      "\n",
      "Epoch:    2/3     Batch: 380/6968  Loss: 3.8788259983062745\n",
      "\n",
      "Epoch:    2/3     Batch: 385/6968  Loss: 3.980928134918213\n",
      "\n",
      "Epoch:    2/3     Batch: 390/6968  Loss: 3.9480064868927003\n",
      "\n",
      "Epoch:    2/3     Batch: 395/6968  Loss: 3.8863452434539796\n",
      "\n",
      "Epoch:    2/3     Batch: 400/6968  Loss: 3.796718788146973\n",
      "\n",
      "Epoch:    2/3     Batch: 405/6968  Loss: 3.962289047241211\n",
      "\n",
      "Epoch:    2/3     Batch: 410/6968  Loss: 4.0734704494476315\n",
      "\n",
      "Epoch:    2/3     Batch: 415/6968  Loss: 3.7415762424468992\n",
      "\n",
      "Epoch:    2/3     Batch: 420/6968  Loss: 4.025351476669312\n",
      "\n",
      "Epoch:    2/3     Batch: 425/6968  Loss: 3.7658036231994627\n",
      "\n",
      "Epoch:    2/3     Batch: 430/6968  Loss: 3.813503932952881\n",
      "\n",
      "Epoch:    2/3     Batch: 435/6968  Loss: 3.928841972351074\n",
      "\n",
      "Epoch:    2/3     Batch: 440/6968  Loss: 3.8925931453704834\n",
      "\n",
      "Epoch:    2/3     Batch: 445/6968  Loss: 3.772309494018555\n",
      "\n",
      "Epoch:    2/3     Batch: 450/6968  Loss: 3.7781546115875244\n",
      "\n",
      "Epoch:    2/3     Batch: 455/6968  Loss: 3.909619760513306\n",
      "\n",
      "Epoch:    2/3     Batch: 460/6968  Loss: 3.854939413070679\n",
      "\n",
      "Epoch:    2/3     Batch: 465/6968  Loss: 3.91589241027832\n",
      "\n",
      "Epoch:    2/3     Batch: 470/6968  Loss: 3.6193267822265627\n",
      "\n",
      "Epoch:    2/3     Batch: 475/6968  Loss: 4.010879325866699\n",
      "\n",
      "Epoch:    2/3     Batch: 480/6968  Loss: 3.7786182403564452\n",
      "\n",
      "Epoch:    2/3     Batch: 485/6968  Loss: 3.605003595352173\n",
      "\n",
      "Epoch:    2/3     Batch: 490/6968  Loss: 3.6912819385528564\n",
      "\n",
      "Epoch:    2/3     Batch: 495/6968  Loss: 3.8754844188690187\n",
      "\n",
      "Epoch:    2/3     Batch: 500/6968  Loss: 3.73557391166687\n",
      "\n",
      "Epoch:    2/3     Batch: 505/6968  Loss: 3.8671061038970946\n",
      "\n",
      "Epoch:    2/3     Batch: 510/6968  Loss: 3.714745283126831\n",
      "\n",
      "Epoch:    2/3     Batch: 515/6968  Loss: 3.9651930809020994\n",
      "\n",
      "Epoch:    2/3     Batch: 520/6968  Loss: 3.6319056510925294\n",
      "\n",
      "Epoch:    2/3     Batch: 525/6968  Loss: 3.739190101623535\n",
      "\n",
      "Epoch:    2/3     Batch: 530/6968  Loss: 4.004917240142822\n",
      "\n",
      "Epoch:    2/3     Batch: 535/6968  Loss: 3.636658811569214\n",
      "\n",
      "Epoch:    2/3     Batch: 540/6968  Loss: 3.8383822441101074\n",
      "\n",
      "Epoch:    2/3     Batch: 545/6968  Loss: 3.8535664558410643\n",
      "\n",
      "Epoch:    2/3     Batch: 550/6968  Loss: 3.7952600002288817\n",
      "\n",
      "Epoch:    2/3     Batch: 555/6968  Loss: 3.8610064029693603\n",
      "\n",
      "Epoch:    2/3     Batch: 560/6968  Loss: 4.1266374588012695\n",
      "\n",
      "Epoch:    2/3     Batch: 565/6968  Loss: 3.79172306060791\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    2/3     Batch: 570/6968  Loss: 3.964973878860474\n",
      "\n",
      "Epoch:    2/3     Batch: 575/6968  Loss: 3.7770575046539308\n",
      "\n",
      "Epoch:    2/3     Batch: 580/6968  Loss: 3.836196041107178\n",
      "\n",
      "Epoch:    2/3     Batch: 585/6968  Loss: 3.8924279689788817\n",
      "\n",
      "Epoch:    2/3     Batch: 590/6968  Loss: 3.7536315441131594\n",
      "\n",
      "Epoch:    2/3     Batch: 595/6968  Loss: 4.139185953140259\n",
      "\n",
      "Epoch:    2/3     Batch: 600/6968  Loss: 3.745117998123169\n",
      "\n",
      "Epoch:    2/3     Batch: 605/6968  Loss: 3.598445701599121\n",
      "\n",
      "Epoch:    2/3     Batch: 610/6968  Loss: 3.7197007656097414\n",
      "\n",
      "Epoch:    2/3     Batch: 615/6968  Loss: 3.770541524887085\n",
      "\n",
      "Epoch:    2/3     Batch: 620/6968  Loss: 3.79781231880188\n",
      "\n",
      "Epoch:    2/3     Batch: 625/6968  Loss: 3.8513878345489503\n",
      "\n",
      "Epoch:    2/3     Batch: 630/6968  Loss: 3.7037079334259033\n",
      "\n",
      "Epoch:    2/3     Batch: 635/6968  Loss: 3.8080775260925295\n",
      "\n",
      "Epoch:    2/3     Batch: 640/6968  Loss: 3.7520079135894777\n",
      "\n",
      "Epoch:    2/3     Batch: 645/6968  Loss: 3.861815929412842\n",
      "\n",
      "Epoch:    2/3     Batch: 650/6968  Loss: 3.8689897537231444\n",
      "\n",
      "Epoch:    2/3     Batch: 655/6968  Loss: 3.9021291732788086\n",
      "\n",
      "Epoch:    2/3     Batch: 660/6968  Loss: 3.8741963863372804\n",
      "\n",
      "Epoch:    2/3     Batch: 665/6968  Loss: 3.918333578109741\n",
      "\n",
      "Epoch:    2/3     Batch: 670/6968  Loss: 3.859319877624512\n",
      "\n",
      "Epoch:    2/3     Batch: 675/6968  Loss: 3.8133037090301514\n",
      "\n",
      "Epoch:    2/3     Batch: 680/6968  Loss: 4.041789197921753\n",
      "\n",
      "Epoch:    2/3     Batch: 685/6968  Loss: 3.856780767440796\n",
      "\n",
      "Epoch:    2/3     Batch: 690/6968  Loss: 3.9580569744110106\n",
      "\n",
      "Epoch:    2/3     Batch: 695/6968  Loss: 3.6706241607666015\n",
      "\n",
      "Epoch:    2/3     Batch: 700/6968  Loss: 3.754789400100708\n",
      "\n",
      "Epoch:    2/3     Batch: 705/6968  Loss: 3.8669171810150145\n",
      "\n",
      "Epoch:    2/3     Batch: 710/6968  Loss: 3.8273064136505126\n",
      "\n",
      "Epoch:    2/3     Batch: 715/6968  Loss: 3.6859689712524415\n",
      "\n",
      "Epoch:    2/3     Batch: 720/6968  Loss: 3.968082809448242\n",
      "\n",
      "Epoch:    2/3     Batch: 725/6968  Loss: 3.931158018112183\n",
      "\n",
      "Epoch:    2/3     Batch: 730/6968  Loss: 3.725516510009766\n",
      "\n",
      "Epoch:    2/3     Batch: 735/6968  Loss: 4.069201135635376\n",
      "\n",
      "Epoch:    2/3     Batch: 740/6968  Loss: 3.920070505142212\n",
      "\n",
      "Epoch:    2/3     Batch: 745/6968  Loss: 3.8487178325653075\n",
      "\n",
      "Epoch:    2/3     Batch: 750/6968  Loss: 3.6529123306274416\n",
      "\n",
      "Epoch:    2/3     Batch: 755/6968  Loss: 3.980982208251953\n",
      "\n",
      "Epoch:    2/3     Batch: 760/6968  Loss: 3.815703773498535\n",
      "\n",
      "Epoch:    2/3     Batch: 765/6968  Loss: 3.9840537548065185\n",
      "\n",
      "Epoch:    2/3     Batch: 770/6968  Loss: 3.8307432174682616\n",
      "\n",
      "Epoch:    2/3     Batch: 775/6968  Loss: 3.6245539665222166\n",
      "\n",
      "Epoch:    2/3     Batch: 780/6968  Loss: 3.8792406558990478\n",
      "\n",
      "Epoch:    2/3     Batch: 785/6968  Loss: 3.720924139022827\n",
      "\n",
      "Epoch:    2/3     Batch: 790/6968  Loss: 3.994836711883545\n",
      "\n",
      "Epoch:    2/3     Batch: 795/6968  Loss: 3.7495229721069334\n",
      "\n",
      "Epoch:    2/3     Batch: 800/6968  Loss: 3.6132747650146486\n",
      "\n",
      "Epoch:    2/3     Batch: 805/6968  Loss: 3.680343008041382\n",
      "\n",
      "Epoch:    2/3     Batch: 810/6968  Loss: 3.872010374069214\n",
      "\n",
      "Epoch:    2/3     Batch: 815/6968  Loss: 3.7152334213256837\n",
      "\n",
      "Epoch:    2/3     Batch: 820/6968  Loss: 3.9764029502868654\n",
      "\n",
      "Epoch:    2/3     Batch: 825/6968  Loss: 3.543178367614746\n",
      "\n",
      "Epoch:    2/3     Batch: 830/6968  Loss: 3.7654757499694824\n",
      "\n",
      "Epoch:    2/3     Batch: 835/6968  Loss: 3.6610458374023436\n",
      "\n",
      "Epoch:    2/3     Batch: 840/6968  Loss: 3.8591031074523925\n",
      "\n",
      "Epoch:    2/3     Batch: 845/6968  Loss: 3.763735055923462\n",
      "\n",
      "Epoch:    2/3     Batch: 850/6968  Loss: 3.857316017150879\n",
      "\n",
      "Epoch:    2/3     Batch: 855/6968  Loss: 3.887679195404053\n",
      "\n",
      "Epoch:    2/3     Batch: 860/6968  Loss: 3.78608660697937\n",
      "\n",
      "Epoch:    2/3     Batch: 865/6968  Loss: 3.8826090335845946\n",
      "\n",
      "Epoch:    2/3     Batch: 870/6968  Loss: 3.974359083175659\n",
      "\n",
      "Epoch:    2/3     Batch: 875/6968  Loss: 3.8407359600067137\n",
      "\n",
      "Epoch:    2/3     Batch: 880/6968  Loss: 3.7570216178894045\n",
      "\n",
      "Epoch:    2/3     Batch: 885/6968  Loss: 3.962090492248535\n",
      "\n",
      "Epoch:    2/3     Batch: 890/6968  Loss: 4.0172563076019285\n",
      "\n",
      "Epoch:    2/3     Batch: 895/6968  Loss: 3.7883159637451174\n",
      "\n",
      "Epoch:    2/3     Batch: 900/6968  Loss: 3.751307725906372\n",
      "\n",
      "Epoch:    2/3     Batch: 905/6968  Loss: 3.7342928409576417\n",
      "\n",
      "Epoch:    2/3     Batch: 910/6968  Loss: 3.581614923477173\n",
      "\n",
      "Epoch:    2/3     Batch: 915/6968  Loss: 3.995918369293213\n",
      "\n",
      "Epoch:    2/3     Batch: 920/6968  Loss: 3.807285737991333\n",
      "\n",
      "Epoch:    2/3     Batch: 925/6968  Loss: 3.907539653778076\n",
      "\n",
      "Epoch:    2/3     Batch: 930/6968  Loss: 4.0112463474273685\n",
      "\n",
      "Epoch:    2/3     Batch: 935/6968  Loss: 3.9719187736511232\n",
      "\n",
      "Epoch:    2/3     Batch: 940/6968  Loss: 3.756560230255127\n",
      "\n",
      "Epoch:    2/3     Batch: 945/6968  Loss: 3.8943817615509033\n",
      "\n",
      "Epoch:    2/3     Batch: 950/6968  Loss: 3.6936638832092283\n",
      "\n",
      "Epoch:    2/3     Batch: 955/6968  Loss: 3.7198426723480225\n",
      "\n",
      "Epoch:    2/3     Batch: 960/6968  Loss: 4.0503215312957765\n",
      "\n",
      "Epoch:    2/3     Batch: 965/6968  Loss: 4.007736873626709\n",
      "\n",
      "Epoch:    2/3     Batch: 970/6968  Loss: 3.6821871280670164\n",
      "\n",
      "Epoch:    2/3     Batch: 975/6968  Loss: 3.6499810218811035\n",
      "\n",
      "Epoch:    2/3     Batch: 980/6968  Loss: 4.078360509872437\n",
      "\n",
      "Epoch:    2/3     Batch: 985/6968  Loss: 3.8547598838806154\n",
      "\n",
      "Epoch:    2/3     Batch: 990/6968  Loss: 3.6830201148986816\n",
      "\n",
      "Epoch:    2/3     Batch: 995/6968  Loss: 3.9580365657806396\n",
      "\n",
      "Epoch:    2/3     Batch:1000/6968  Loss: 3.745392608642578\n",
      "\n",
      "Epoch:    2/3     Batch:1005/6968  Loss: 3.8932136058807374\n",
      "\n",
      "Epoch:    2/3     Batch:1010/6968  Loss: 3.6157264709472656\n",
      "\n",
      "Epoch:    2/3     Batch:1015/6968  Loss: 3.7772214889526365\n",
      "\n",
      "Epoch:    2/3     Batch:1020/6968  Loss: 3.8549685955047606\n",
      "\n",
      "Epoch:    2/3     Batch:1025/6968  Loss: 3.9665921688079835\n",
      "\n",
      "Epoch:    2/3     Batch:1030/6968  Loss: 3.6548436164855955\n",
      "\n",
      "Epoch:    2/3     Batch:1035/6968  Loss: 3.579065036773682\n",
      "\n",
      "Epoch:    2/3     Batch:1040/6968  Loss: 3.7348031997680664\n",
      "\n",
      "Epoch:    2/3     Batch:1045/6968  Loss: 3.8330758571624757\n",
      "\n",
      "Epoch:    2/3     Batch:1050/6968  Loss: 3.6847380638122558\n",
      "\n",
      "Epoch:    2/3     Batch:1055/6968  Loss: 3.7226866722106933\n",
      "\n",
      "Epoch:    2/3     Batch:1060/6968  Loss: 3.9287991523742676\n",
      "\n",
      "Epoch:    2/3     Batch:1065/6968  Loss: 3.854793071746826\n",
      "\n",
      "Epoch:    2/3     Batch:1070/6968  Loss: 3.9674779891967775\n",
      "\n",
      "Epoch:    2/3     Batch:1075/6968  Loss: 3.5952646255493166\n",
      "\n",
      "Epoch:    2/3     Batch:1080/6968  Loss: 3.9953927516937258\n",
      "\n",
      "Epoch:    2/3     Batch:1085/6968  Loss: 3.80636305809021\n",
      "\n",
      "Epoch:    2/3     Batch:1090/6968  Loss: 3.8630652904510496\n",
      "\n",
      "Epoch:    2/3     Batch:1095/6968  Loss: 3.969305992126465\n",
      "\n",
      "Epoch:    2/3     Batch:1100/6968  Loss: 4.056329345703125\n",
      "\n",
      "Epoch:    2/3     Batch:1105/6968  Loss: 3.8300710678100587\n",
      "\n",
      "Epoch:    2/3     Batch:1110/6968  Loss: 3.7298915863037108\n",
      "\n",
      "Epoch:    2/3     Batch:1115/6968  Loss: 4.0641978740692135\n",
      "\n",
      "Epoch:    2/3     Batch:1120/6968  Loss: 3.580919122695923\n",
      "\n",
      "Epoch:    2/3     Batch:1125/6968  Loss: 3.8358169555664063\n",
      "\n",
      "Epoch:    2/3     Batch:1130/6968  Loss: 3.8791144371032713\n",
      "\n",
      "Epoch:    2/3     Batch:1135/6968  Loss: 3.930295133590698\n",
      "\n",
      "Epoch:    2/3     Batch:1140/6968  Loss: 3.780217409133911\n",
      "\n",
      "Epoch:    2/3     Batch:1145/6968  Loss: 4.00704345703125\n",
      "\n",
      "Epoch:    2/3     Batch:1150/6968  Loss: 3.8684270858764647\n",
      "\n",
      "Epoch:    2/3     Batch:1155/6968  Loss: 3.7706190586090087\n",
      "\n",
      "Epoch:    2/3     Batch:1160/6968  Loss: 3.8996145725250244\n",
      "\n",
      "Epoch:    2/3     Batch:1165/6968  Loss: 3.7679762840270996\n",
      "\n",
      "Epoch:    2/3     Batch:1170/6968  Loss: 3.8593116760253907\n",
      "\n",
      "Epoch:    2/3     Batch:1175/6968  Loss: 3.9684235572814943\n",
      "\n",
      "Epoch:    2/3     Batch:1180/6968  Loss: 3.7390982151031493\n",
      "\n",
      "Epoch:    2/3     Batch:1185/6968  Loss: 3.7323689460754395\n",
      "\n",
      "Epoch:    2/3     Batch:1190/6968  Loss: 4.009820032119751\n",
      "\n",
      "Epoch:    2/3     Batch:1195/6968  Loss: 3.8500716209411623\n",
      "\n",
      "Epoch:    2/3     Batch:1200/6968  Loss: 3.7860284805297852\n",
      "\n",
      "Epoch:    2/3     Batch:1205/6968  Loss: 3.971621036529541\n",
      "\n",
      "Epoch:    2/3     Batch:1210/6968  Loss: 3.940987491607666\n",
      "\n",
      "Epoch:    2/3     Batch:1215/6968  Loss: 4.013342618942261\n",
      "\n",
      "Epoch:    2/3     Batch:1220/6968  Loss: 3.7387569904327393\n",
      "\n",
      "Epoch:    2/3     Batch:1225/6968  Loss: 3.72214298248291\n",
      "\n",
      "Epoch:    2/3     Batch:1230/6968  Loss: 3.8657177448272706\n",
      "\n",
      "Epoch:    2/3     Batch:1235/6968  Loss: 3.786039686203003\n",
      "\n",
      "Epoch:    2/3     Batch:1240/6968  Loss: 3.8084160804748537\n",
      "\n",
      "Epoch:    2/3     Batch:1245/6968  Loss: 3.77793288230896\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    2/3     Batch:1250/6968  Loss: 4.037220191955567\n",
      "\n",
      "Epoch:    2/3     Batch:1255/6968  Loss: 3.900098705291748\n",
      "\n",
      "Epoch:    2/3     Batch:1260/6968  Loss: 3.957407093048096\n",
      "\n",
      "Epoch:    2/3     Batch:1265/6968  Loss: 3.612749767303467\n",
      "\n",
      "Epoch:    2/3     Batch:1270/6968  Loss: 4.038437128067017\n",
      "\n",
      "Epoch:    2/3     Batch:1275/6968  Loss: 3.7147902488708495\n",
      "\n",
      "Epoch:    2/3     Batch:1280/6968  Loss: 3.761898946762085\n",
      "\n",
      "Epoch:    2/3     Batch:1285/6968  Loss: 3.9742703437805176\n",
      "\n",
      "Epoch:    2/3     Batch:1290/6968  Loss: 3.861082649230957\n",
      "\n",
      "Epoch:    2/3     Batch:1295/6968  Loss: 3.8209362506866453\n",
      "\n",
      "Epoch:    2/3     Batch:1300/6968  Loss: 3.938722610473633\n",
      "\n",
      "Epoch:    2/3     Batch:1305/6968  Loss: 3.936494064331055\n",
      "\n",
      "Epoch:    2/3     Batch:1310/6968  Loss: 3.8018337726593017\n",
      "\n",
      "Epoch:    2/3     Batch:1315/6968  Loss: 3.7577184200286866\n",
      "\n",
      "Epoch:    2/3     Batch:1320/6968  Loss: 3.7305209159851076\n",
      "\n",
      "Epoch:    2/3     Batch:1325/6968  Loss: 3.8598602294921873\n",
      "\n",
      "Epoch:    2/3     Batch:1330/6968  Loss: 3.914930725097656\n",
      "\n",
      "Epoch:    2/3     Batch:1335/6968  Loss: 3.8563178539276124\n",
      "\n",
      "Epoch:    2/3     Batch:1340/6968  Loss: 3.765540599822998\n",
      "\n",
      "Epoch:    2/3     Batch:1345/6968  Loss: 3.858715534210205\n",
      "\n",
      "Epoch:    2/3     Batch:1350/6968  Loss: 3.8070342540740967\n",
      "\n",
      "Epoch:    2/3     Batch:1355/6968  Loss: 3.7776095867156982\n",
      "\n",
      "Epoch:    2/3     Batch:1360/6968  Loss: 3.734927749633789\n",
      "\n",
      "Epoch:    2/3     Batch:1365/6968  Loss: 3.8869497299194338\n",
      "\n",
      "Epoch:    2/3     Batch:1370/6968  Loss: 3.8483197689056396\n",
      "\n",
      "Epoch:    2/3     Batch:1375/6968  Loss: 3.763175344467163\n",
      "\n",
      "Epoch:    2/3     Batch:1380/6968  Loss: 3.7044602394104005\n",
      "\n",
      "Epoch:    2/3     Batch:1385/6968  Loss: 3.831771898269653\n",
      "\n",
      "Epoch:    2/3     Batch:1390/6968  Loss: 3.7542871475219726\n",
      "\n",
      "Epoch:    2/3     Batch:1395/6968  Loss: 3.9791346073150633\n",
      "\n",
      "Epoch:    2/3     Batch:1400/6968  Loss: 3.6018693447113037\n",
      "\n",
      "Epoch:    2/3     Batch:1405/6968  Loss: 3.8560009479522703\n",
      "\n",
      "Epoch:    2/3     Batch:1410/6968  Loss: 3.7997320652008058\n",
      "\n",
      "Epoch:    2/3     Batch:1415/6968  Loss: 3.6204217433929444\n",
      "\n",
      "Epoch:    2/3     Batch:1420/6968  Loss: 3.868049383163452\n",
      "\n",
      "Epoch:    2/3     Batch:1425/6968  Loss: 3.9317212104797363\n",
      "\n",
      "Epoch:    2/3     Batch:1430/6968  Loss: 3.8561419010162354\n",
      "\n",
      "Epoch:    2/3     Batch:1435/6968  Loss: 3.6729933261871337\n",
      "\n",
      "Epoch:    2/3     Batch:1440/6968  Loss: 3.9520802021026613\n",
      "\n",
      "Epoch:    2/3     Batch:1445/6968  Loss: 3.8779470443725588\n",
      "\n",
      "Epoch:    2/3     Batch:1450/6968  Loss: 3.725126123428345\n",
      "\n",
      "Epoch:    2/3     Batch:1455/6968  Loss: 3.8853254318237305\n",
      "\n",
      "Epoch:    2/3     Batch:1460/6968  Loss: 3.8729175567626952\n",
      "\n",
      "Epoch:    2/3     Batch:1465/6968  Loss: 3.7044800758361816\n",
      "\n",
      "Epoch:    2/3     Batch:1470/6968  Loss: 3.9539040088653565\n",
      "\n",
      "Epoch:    2/3     Batch:1475/6968  Loss: 3.771311330795288\n",
      "\n",
      "Epoch:    2/3     Batch:1480/6968  Loss: 3.8165605545043944\n",
      "\n",
      "Epoch:    2/3     Batch:1485/6968  Loss: 3.789730930328369\n",
      "\n",
      "Epoch:    2/3     Batch:1490/6968  Loss: 3.9117217540740965\n",
      "\n",
      "Epoch:    2/3     Batch:1495/6968  Loss: 3.8581897258758544\n",
      "\n",
      "Epoch:    2/3     Batch:1500/6968  Loss: 3.6830663204193117\n",
      "\n",
      "Epoch:    2/3     Batch:1505/6968  Loss: 3.525708818435669\n",
      "\n",
      "Epoch:    2/3     Batch:1510/6968  Loss: 3.8434690952301027\n",
      "\n",
      "Epoch:    2/3     Batch:1515/6968  Loss: 3.754143238067627\n",
      "\n",
      "Epoch:    2/3     Batch:1520/6968  Loss: 3.675193929672241\n",
      "\n",
      "Epoch:    2/3     Batch:1525/6968  Loss: 3.7412397861480713\n",
      "\n",
      "Epoch:    2/3     Batch:1530/6968  Loss: 4.09549355506897\n",
      "\n",
      "Epoch:    2/3     Batch:1535/6968  Loss: 3.62026629447937\n",
      "\n",
      "Epoch:    2/3     Batch:1540/6968  Loss: 3.6118112564086915\n",
      "\n",
      "Epoch:    2/3     Batch:1545/6968  Loss: 3.996681880950928\n",
      "\n",
      "Epoch:    2/3     Batch:1550/6968  Loss: 3.9329984188079834\n",
      "\n",
      "Epoch:    2/3     Batch:1555/6968  Loss: 3.5707457065582275\n",
      "\n",
      "Epoch:    2/3     Batch:1560/6968  Loss: 3.9003215789794923\n",
      "\n",
      "Epoch:    2/3     Batch:1565/6968  Loss: 3.7032853603363036\n",
      "\n",
      "Epoch:    2/3     Batch:1570/6968  Loss: 4.047675752639771\n",
      "\n",
      "Epoch:    2/3     Batch:1575/6968  Loss: 3.622195816040039\n",
      "\n",
      "Epoch:    2/3     Batch:1580/6968  Loss: 3.6697831630706785\n",
      "\n",
      "Epoch:    2/3     Batch:1585/6968  Loss: 3.8585193157196045\n",
      "\n",
      "Epoch:    2/3     Batch:1590/6968  Loss: 3.7420244216918945\n",
      "\n",
      "Epoch:    2/3     Batch:1595/6968  Loss: 3.484300470352173\n",
      "\n",
      "Epoch:    2/3     Batch:1600/6968  Loss: 3.7842423915863037\n",
      "\n",
      "Epoch:    2/3     Batch:1605/6968  Loss: 3.973865270614624\n",
      "\n",
      "Epoch:    2/3     Batch:1610/6968  Loss: 3.81049165725708\n",
      "\n",
      "Epoch:    2/3     Batch:1615/6968  Loss: 3.8224810123443604\n",
      "\n",
      "Epoch:    2/3     Batch:1620/6968  Loss: 4.021304607391357\n",
      "\n",
      "Epoch:    2/3     Batch:1625/6968  Loss: 3.7227671146392822\n",
      "\n",
      "Epoch:    2/3     Batch:1630/6968  Loss: 3.717947006225586\n",
      "\n",
      "Epoch:    2/3     Batch:1635/6968  Loss: 3.9313355445861817\n",
      "\n",
      "Epoch:    2/3     Batch:1640/6968  Loss: 3.9453797817230223\n",
      "\n",
      "Epoch:    2/3     Batch:1645/6968  Loss: 3.7436477184295653\n",
      "\n",
      "Epoch:    2/3     Batch:1650/6968  Loss: 4.061315870285034\n",
      "\n",
      "Epoch:    2/3     Batch:1655/6968  Loss: 3.7294242858886717\n",
      "\n",
      "Epoch:    2/3     Batch:1660/6968  Loss: 3.796406364440918\n",
      "\n",
      "Epoch:    2/3     Batch:1665/6968  Loss: 3.950821304321289\n",
      "\n",
      "Epoch:    2/3     Batch:1670/6968  Loss: 4.009830951690674\n",
      "\n",
      "Epoch:    2/3     Batch:1675/6968  Loss: 3.9806040287017823\n",
      "\n",
      "Epoch:    2/3     Batch:1680/6968  Loss: 3.7486163139343263\n",
      "\n",
      "Epoch:    2/3     Batch:1685/6968  Loss: 3.848438358306885\n",
      "\n",
      "Epoch:    2/3     Batch:1690/6968  Loss: 3.8581528186798097\n",
      "\n",
      "Epoch:    2/3     Batch:1695/6968  Loss: 3.78392972946167\n",
      "\n",
      "Epoch:    2/3     Batch:1700/6968  Loss: 3.7726036071777345\n",
      "\n",
      "Epoch:    2/3     Batch:1705/6968  Loss: 4.0768430709838865\n",
      "\n",
      "Epoch:    2/3     Batch:1710/6968  Loss: 3.833471584320068\n",
      "\n",
      "Epoch:    2/3     Batch:1715/6968  Loss: 3.798276090621948\n",
      "\n",
      "Epoch:    2/3     Batch:1720/6968  Loss: 3.967251110076904\n",
      "\n",
      "Epoch:    2/3     Batch:1725/6968  Loss: 3.8685608863830567\n",
      "\n",
      "Epoch:    2/3     Batch:1730/6968  Loss: 3.845307445526123\n",
      "\n",
      "Epoch:    2/3     Batch:1735/6968  Loss: 3.8811989784240724\n",
      "\n",
      "Epoch:    2/3     Batch:1740/6968  Loss: 3.9275514602661135\n",
      "\n",
      "Epoch:    2/3     Batch:1745/6968  Loss: 3.7358846187591555\n",
      "\n",
      "Epoch:    2/3     Batch:1750/6968  Loss: 3.9420443058013914\n",
      "\n",
      "Epoch:    2/3     Batch:1755/6968  Loss: 3.8348363876342773\n",
      "\n",
      "Epoch:    2/3     Batch:1760/6968  Loss: 3.8442283630371095\n",
      "\n",
      "Epoch:    2/3     Batch:1765/6968  Loss: 3.6802461624145506\n",
      "\n",
      "Epoch:    2/3     Batch:1770/6968  Loss: 3.9475886821746826\n",
      "\n",
      "Epoch:    2/3     Batch:1775/6968  Loss: 3.8683441638946534\n",
      "\n",
      "Epoch:    2/3     Batch:1780/6968  Loss: 3.7186834812164307\n",
      "\n",
      "Epoch:    2/3     Batch:1785/6968  Loss: 3.708201026916504\n",
      "\n",
      "Epoch:    2/3     Batch:1790/6968  Loss: 3.728901767730713\n",
      "\n",
      "Epoch:    2/3     Batch:1795/6968  Loss: 3.5988816261291503\n",
      "\n",
      "Epoch:    2/3     Batch:1800/6968  Loss: 3.7646665573120117\n",
      "\n",
      "Epoch:    2/3     Batch:1805/6968  Loss: 3.6838566780090334\n",
      "\n",
      "Epoch:    2/3     Batch:1810/6968  Loss: 3.723570394515991\n",
      "\n",
      "Epoch:    2/3     Batch:1815/6968  Loss: 3.777377557754517\n",
      "\n",
      "Epoch:    2/3     Batch:1820/6968  Loss: 3.7415854930877686\n",
      "\n",
      "Epoch:    2/3     Batch:1825/6968  Loss: 3.799643564224243\n",
      "\n",
      "Epoch:    2/3     Batch:1830/6968  Loss: 4.09712438583374\n",
      "\n",
      "Epoch:    2/3     Batch:1835/6968  Loss: 3.775523805618286\n",
      "\n",
      "Epoch:    2/3     Batch:1840/6968  Loss: 3.8996250152587892\n",
      "\n",
      "Epoch:    2/3     Batch:1845/6968  Loss: 3.618529939651489\n",
      "\n",
      "Epoch:    2/3     Batch:1850/6968  Loss: 3.8085102081298827\n",
      "\n",
      "Epoch:    2/3     Batch:1855/6968  Loss: 3.893229293823242\n",
      "\n",
      "Epoch:    2/3     Batch:1860/6968  Loss: 3.817907285690308\n",
      "\n",
      "Epoch:    2/3     Batch:1865/6968  Loss: 3.8118121147155763\n",
      "\n",
      "Epoch:    2/3     Batch:1870/6968  Loss: 3.9923301696777345\n",
      "\n",
      "Epoch:    2/3     Batch:1875/6968  Loss: 3.953151512145996\n",
      "\n",
      "Epoch:    2/3     Batch:1880/6968  Loss: 3.735127067565918\n",
      "\n",
      "Epoch:    2/3     Batch:1885/6968  Loss: 3.8926906108856203\n",
      "\n",
      "Epoch:    2/3     Batch:1890/6968  Loss: 3.909463882446289\n",
      "\n",
      "Epoch:    2/3     Batch:1895/6968  Loss: 3.784296083450317\n",
      "\n",
      "Epoch:    2/3     Batch:1900/6968  Loss: 4.025813722610474\n",
      "\n",
      "Epoch:    2/3     Batch:1905/6968  Loss: 3.863383722305298\n",
      "\n",
      "Epoch:    2/3     Batch:1910/6968  Loss: 3.7861154556274412\n",
      "\n",
      "Epoch:    2/3     Batch:1915/6968  Loss: 3.9203742027282713\n",
      "\n",
      "Epoch:    2/3     Batch:1920/6968  Loss: 3.876270055770874\n",
      "\n",
      "Epoch:    2/3     Batch:1925/6968  Loss: 3.7816556453704835\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    2/3     Batch:1930/6968  Loss: 3.9867280960083007\n",
      "\n",
      "Epoch:    2/3     Batch:1935/6968  Loss: 3.81814923286438\n",
      "\n",
      "Epoch:    2/3     Batch:1940/6968  Loss: 3.737736368179321\n",
      "\n",
      "Epoch:    2/3     Batch:1945/6968  Loss: 4.023219013214112\n",
      "\n",
      "Epoch:    2/3     Batch:1950/6968  Loss: 4.012900066375733\n",
      "\n",
      "Epoch:    2/3     Batch:1955/6968  Loss: 3.8611116886138914\n",
      "\n",
      "Epoch:    2/3     Batch:1960/6968  Loss: 3.6398823738098143\n",
      "\n",
      "Epoch:    2/3     Batch:1965/6968  Loss: 3.7452325344085695\n",
      "\n",
      "Epoch:    2/3     Batch:1970/6968  Loss: 3.874494791030884\n",
      "\n",
      "Epoch:    2/3     Batch:1975/6968  Loss: 4.0256494045257565\n",
      "\n",
      "Epoch:    2/3     Batch:1980/6968  Loss: 3.95802526473999\n",
      "\n",
      "Epoch:    2/3     Batch:1985/6968  Loss: 3.741858434677124\n",
      "\n",
      "Epoch:    2/3     Batch:1990/6968  Loss: 3.785379409790039\n",
      "\n",
      "Epoch:    2/3     Batch:1995/6968  Loss: 3.717906618118286\n",
      "\n",
      "Epoch:    2/3     Batch:2000/6968  Loss: 3.7878899574279785\n",
      "\n",
      "Epoch:    2/3     Batch:2005/6968  Loss: 3.747963285446167\n",
      "\n",
      "Epoch:    2/3     Batch:2010/6968  Loss: 3.7388654708862306\n",
      "\n",
      "Epoch:    2/3     Batch:2015/6968  Loss: 3.7420934200286866\n",
      "\n",
      "Epoch:    2/3     Batch:2020/6968  Loss: 3.7302515506744385\n",
      "\n",
      "Epoch:    2/3     Batch:2025/6968  Loss: 3.709047222137451\n",
      "\n",
      "Epoch:    2/3     Batch:2030/6968  Loss: 3.8993531703948974\n",
      "\n",
      "Epoch:    2/3     Batch:2035/6968  Loss: 3.3853816986083984\n",
      "\n",
      "Epoch:    2/3     Batch:2040/6968  Loss: 3.950835084915161\n",
      "\n",
      "Epoch:    2/3     Batch:2045/6968  Loss: 3.8385371208190917\n",
      "\n",
      "Epoch:    2/3     Batch:2050/6968  Loss: 3.699126863479614\n",
      "\n",
      "Epoch:    2/3     Batch:2055/6968  Loss: 3.7608283519744874\n",
      "\n",
      "Epoch:    2/3     Batch:2060/6968  Loss: 3.827928066253662\n",
      "\n",
      "Epoch:    2/3     Batch:2065/6968  Loss: 3.6586838245391844\n",
      "\n",
      "Epoch:    2/3     Batch:2070/6968  Loss: 3.7921221256256104\n",
      "\n",
      "Epoch:    2/3     Batch:2075/6968  Loss: 3.711209201812744\n",
      "\n",
      "Epoch:    2/3     Batch:2080/6968  Loss: 3.9981040477752687\n",
      "\n",
      "Epoch:    2/3     Batch:2085/6968  Loss: 3.7587168216705322\n",
      "\n",
      "Epoch:    2/3     Batch:2090/6968  Loss: 3.7234172344207765\n",
      "\n",
      "Epoch:    2/3     Batch:2095/6968  Loss: 3.8894345283508303\n",
      "\n",
      "Epoch:    2/3     Batch:2100/6968  Loss: 3.7993282794952394\n",
      "\n",
      "Epoch:    2/3     Batch:2105/6968  Loss: 3.7759538650512696\n",
      "\n",
      "Epoch:    2/3     Batch:2110/6968  Loss: 3.63962607383728\n",
      "\n",
      "Epoch:    2/3     Batch:2115/6968  Loss: 3.8171058177947996\n",
      "\n",
      "Epoch:    2/3     Batch:2120/6968  Loss: 3.8185833930969237\n",
      "\n",
      "Epoch:    2/3     Batch:2125/6968  Loss: 3.826556921005249\n",
      "\n",
      "Epoch:    2/3     Batch:2130/6968  Loss: 3.811104106903076\n",
      "\n",
      "Epoch:    2/3     Batch:2135/6968  Loss: 3.872007656097412\n",
      "\n",
      "Epoch:    2/3     Batch:2140/6968  Loss: 3.7881505489349365\n",
      "\n",
      "Epoch:    2/3     Batch:2145/6968  Loss: 3.679667854309082\n",
      "\n",
      "Epoch:    2/3     Batch:2150/6968  Loss: 3.78685622215271\n",
      "\n",
      "Epoch:    2/3     Batch:2155/6968  Loss: 3.853411912918091\n",
      "\n",
      "Epoch:    2/3     Batch:2160/6968  Loss: 3.7715206146240234\n",
      "\n",
      "Epoch:    2/3     Batch:2165/6968  Loss: 3.818566989898682\n",
      "\n",
      "Epoch:    2/3     Batch:2170/6968  Loss: 3.6108815670013428\n",
      "\n",
      "Epoch:    2/3     Batch:2175/6968  Loss: 3.6365866661071777\n",
      "\n",
      "Epoch:    2/3     Batch:2180/6968  Loss: 3.7307904720306397\n",
      "\n",
      "Epoch:    2/3     Batch:2185/6968  Loss: 3.705310821533203\n",
      "\n",
      "Epoch:    2/3     Batch:2190/6968  Loss: 3.8641992092132567\n",
      "\n",
      "Epoch:    2/3     Batch:2195/6968  Loss: 3.8065799713134765\n",
      "\n",
      "Epoch:    2/3     Batch:2200/6968  Loss: 3.924285650253296\n",
      "\n",
      "Epoch:    2/3     Batch:2205/6968  Loss: 3.7275469303131104\n",
      "\n",
      "Epoch:    2/3     Batch:2210/6968  Loss: 3.8305778026580812\n",
      "\n",
      "Epoch:    2/3     Batch:2215/6968  Loss: 3.745634746551514\n",
      "\n",
      "Epoch:    2/3     Batch:2220/6968  Loss: 3.7552730083465575\n",
      "\n",
      "Epoch:    2/3     Batch:2225/6968  Loss: 4.08147931098938\n",
      "\n",
      "Epoch:    2/3     Batch:2230/6968  Loss: 3.7785776615142823\n",
      "\n",
      "Epoch:    2/3     Batch:2235/6968  Loss: 3.7688887119293213\n",
      "\n",
      "Epoch:    2/3     Batch:2240/6968  Loss: 4.081325387954712\n",
      "\n",
      "Epoch:    2/3     Batch:2245/6968  Loss: 3.850904846191406\n",
      "\n",
      "Epoch:    2/3     Batch:2250/6968  Loss: 3.7850892543792725\n",
      "\n",
      "Epoch:    2/3     Batch:2255/6968  Loss: 3.744734859466553\n",
      "\n",
      "Epoch:    2/3     Batch:2260/6968  Loss: 3.623085641860962\n",
      "\n",
      "Epoch:    2/3     Batch:2265/6968  Loss: 3.7752312660217284\n",
      "\n",
      "Epoch:    2/3     Batch:2270/6968  Loss: 3.92191596031189\n",
      "\n",
      "Epoch:    2/3     Batch:2275/6968  Loss: 3.7137385845184325\n",
      "\n",
      "Epoch:    2/3     Batch:2280/6968  Loss: 3.8096375942230223\n",
      "\n",
      "Epoch:    2/3     Batch:2285/6968  Loss: 3.854039716720581\n",
      "\n",
      "Epoch:    2/3     Batch:2290/6968  Loss: 3.6694971561431884\n",
      "\n",
      "Epoch:    2/3     Batch:2295/6968  Loss: 3.772541379928589\n",
      "\n",
      "Epoch:    2/3     Batch:2300/6968  Loss: 3.8326509952545167\n",
      "\n",
      "Epoch:    2/3     Batch:2305/6968  Loss: 3.7614909648895263\n",
      "\n",
      "Epoch:    2/3     Batch:2310/6968  Loss: 3.753717374801636\n",
      "\n",
      "Epoch:    2/3     Batch:2315/6968  Loss: 3.5857261180877686\n",
      "\n",
      "Epoch:    2/3     Batch:2320/6968  Loss: 3.845506525039673\n",
      "\n",
      "Epoch:    2/3     Batch:2325/6968  Loss: 3.8303924560546876\n",
      "\n",
      "Epoch:    2/3     Batch:2330/6968  Loss: 4.272803592681885\n",
      "\n",
      "Epoch:    2/3     Batch:2335/6968  Loss: 3.744550657272339\n",
      "\n",
      "Epoch:    2/3     Batch:2340/6968  Loss: 3.6801337242126464\n",
      "\n",
      "Epoch:    2/3     Batch:2345/6968  Loss: 3.851455879211426\n",
      "\n",
      "Epoch:    2/3     Batch:2350/6968  Loss: 3.7675381183624266\n",
      "\n",
      "Epoch:    2/3     Batch:2355/6968  Loss: 3.723871088027954\n",
      "\n",
      "Epoch:    2/3     Batch:2360/6968  Loss: 3.7448760986328127\n",
      "\n",
      "Epoch:    2/3     Batch:2365/6968  Loss: 3.851464796066284\n",
      "\n",
      "Epoch:    2/3     Batch:2370/6968  Loss: 3.867191457748413\n",
      "\n",
      "Epoch:    2/3     Batch:2375/6968  Loss: 3.896096420288086\n",
      "\n",
      "Epoch:    2/3     Batch:2380/6968  Loss: 3.7737543106079103\n",
      "\n",
      "Epoch:    2/3     Batch:2385/6968  Loss: 4.013754606246948\n",
      "\n",
      "Epoch:    2/3     Batch:2390/6968  Loss: 3.931321620941162\n",
      "\n",
      "Epoch:    2/3     Batch:2395/6968  Loss: 3.9156768798828123\n",
      "\n",
      "Epoch:    2/3     Batch:2400/6968  Loss: 3.7261486530303953\n",
      "\n",
      "Epoch:    2/3     Batch:2405/6968  Loss: 3.97701096534729\n",
      "\n",
      "Epoch:    2/3     Batch:2410/6968  Loss: 3.829995107650757\n",
      "\n",
      "Epoch:    2/3     Batch:2415/6968  Loss: 4.033468198776245\n",
      "\n",
      "Epoch:    2/3     Batch:2420/6968  Loss: 3.904250717163086\n",
      "\n",
      "Epoch:    2/3     Batch:2425/6968  Loss: 3.647354173660278\n",
      "\n",
      "Epoch:    2/3     Batch:2430/6968  Loss: 3.8434038162231445\n",
      "\n",
      "Epoch:    2/3     Batch:2435/6968  Loss: 3.8820343971252442\n",
      "\n",
      "Epoch:    2/3     Batch:2440/6968  Loss: 3.7974079132080076\n",
      "\n",
      "Epoch:    2/3     Batch:2445/6968  Loss: 3.6815853118896484\n",
      "\n",
      "Epoch:    2/3     Batch:2450/6968  Loss: 3.761085271835327\n",
      "\n",
      "Epoch:    2/3     Batch:2455/6968  Loss: 3.917209529876709\n",
      "\n",
      "Epoch:    2/3     Batch:2460/6968  Loss: 3.8428303241729735\n",
      "\n",
      "Epoch:    2/3     Batch:2465/6968  Loss: 3.70514121055603\n",
      "\n",
      "Epoch:    2/3     Batch:2470/6968  Loss: 4.074564647674561\n",
      "\n",
      "Epoch:    2/3     Batch:2475/6968  Loss: 4.02179799079895\n",
      "\n",
      "Epoch:    2/3     Batch:2480/6968  Loss: 3.643019771575928\n",
      "\n",
      "Epoch:    2/3     Batch:2485/6968  Loss: 3.7331735134124755\n",
      "\n",
      "Epoch:    2/3     Batch:2490/6968  Loss: 3.8838226318359377\n",
      "\n",
      "Epoch:    2/3     Batch:2495/6968  Loss: 3.890218496322632\n",
      "\n",
      "Epoch:    2/3     Batch:2500/6968  Loss: 3.9333348274230957\n",
      "\n",
      "Epoch:    2/3     Batch:2505/6968  Loss: 3.918655204772949\n",
      "\n",
      "Epoch:    2/3     Batch:2510/6968  Loss: 4.133155584335327\n",
      "\n",
      "Epoch:    2/3     Batch:2515/6968  Loss: 3.861595058441162\n",
      "\n",
      "Epoch:    2/3     Batch:2520/6968  Loss: 3.7108808040618895\n",
      "\n",
      "Epoch:    2/3     Batch:2525/6968  Loss: 3.5587257385253905\n",
      "\n",
      "Epoch:    2/3     Batch:2530/6968  Loss: 3.931730365753174\n",
      "\n",
      "Epoch:    2/3     Batch:2535/6968  Loss: 3.8835505485534667\n",
      "\n",
      "Epoch:    2/3     Batch:2540/6968  Loss: 3.712506103515625\n",
      "\n",
      "Epoch:    2/3     Batch:2545/6968  Loss: 3.7709096908569335\n",
      "\n",
      "Epoch:    2/3     Batch:2550/6968  Loss: 4.034548997879028\n",
      "\n",
      "Epoch:    2/3     Batch:2555/6968  Loss: 3.787094306945801\n",
      "\n",
      "Epoch:    2/3     Batch:2560/6968  Loss: 3.7133595943450928\n",
      "\n",
      "Epoch:    2/3     Batch:2565/6968  Loss: 3.787220573425293\n",
      "\n",
      "Epoch:    2/3     Batch:2570/6968  Loss: 3.654358148574829\n",
      "\n",
      "Epoch:    2/3     Batch:2575/6968  Loss: 3.934198570251465\n",
      "\n",
      "Epoch:    2/3     Batch:2580/6968  Loss: 3.6478575229644776\n",
      "\n",
      "Epoch:    2/3     Batch:2585/6968  Loss: 3.7748085498809814\n",
      "\n",
      "Epoch:    2/3     Batch:2590/6968  Loss: 3.773224687576294\n",
      "\n",
      "Epoch:    2/3     Batch:2595/6968  Loss: 3.896327543258667\n",
      "\n",
      "Epoch:    2/3     Batch:2600/6968  Loss: 3.6581674098968504\n",
      "\n",
      "Epoch:    2/3     Batch:2605/6968  Loss: 3.836458110809326\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    2/3     Batch:2610/6968  Loss: 3.631416749954224\n",
      "\n",
      "Epoch:    2/3     Batch:2615/6968  Loss: 3.7482368469238283\n",
      "\n",
      "Epoch:    2/3     Batch:2620/6968  Loss: 3.9918766975402833\n",
      "\n",
      "Epoch:    2/3     Batch:2625/6968  Loss: 3.8989760875701904\n",
      "\n",
      "Epoch:    2/3     Batch:2630/6968  Loss: 3.922643852233887\n",
      "\n",
      "Epoch:    2/3     Batch:2635/6968  Loss: 4.180158996582032\n",
      "\n",
      "Epoch:    2/3     Batch:2640/6968  Loss: 3.882936191558838\n",
      "\n",
      "Epoch:    2/3     Batch:2645/6968  Loss: 3.6973315715789794\n",
      "\n",
      "Epoch:    2/3     Batch:2650/6968  Loss: 4.104988861083984\n",
      "\n",
      "Epoch:    2/3     Batch:2655/6968  Loss: 3.8025761604309083\n",
      "\n",
      "Epoch:    2/3     Batch:2660/6968  Loss: 3.694377374649048\n",
      "\n",
      "Epoch:    2/3     Batch:2665/6968  Loss: 3.6665382385253906\n",
      "\n",
      "Epoch:    2/3     Batch:2670/6968  Loss: 3.9422879219055176\n",
      "\n",
      "Epoch:    2/3     Batch:2675/6968  Loss: 3.671692228317261\n",
      "\n",
      "Epoch:    2/3     Batch:2680/6968  Loss: 3.776192331314087\n",
      "\n",
      "Epoch:    2/3     Batch:2685/6968  Loss: 3.845983076095581\n",
      "\n",
      "Epoch:    2/3     Batch:2690/6968  Loss: 3.952080583572388\n",
      "\n",
      "Epoch:    2/3     Batch:2695/6968  Loss: 3.668755865097046\n",
      "\n",
      "Epoch:    2/3     Batch:2700/6968  Loss: 3.5732890605926513\n",
      "\n",
      "Epoch:    2/3     Batch:2705/6968  Loss: 3.6585154056549074\n",
      "\n",
      "Epoch:    2/3     Batch:2710/6968  Loss: 4.025655078887939\n",
      "\n",
      "Epoch:    2/3     Batch:2715/6968  Loss: 3.9005666732788087\n",
      "\n",
      "Epoch:    2/3     Batch:2720/6968  Loss: 3.794078493118286\n",
      "\n",
      "Epoch:    2/3     Batch:2725/6968  Loss: 3.9384854316711424\n",
      "\n",
      "Epoch:    2/3     Batch:2730/6968  Loss: 3.711523723602295\n",
      "\n",
      "Epoch:    2/3     Batch:2735/6968  Loss: 3.9695727825164795\n",
      "\n",
      "Epoch:    2/3     Batch:2740/6968  Loss: 4.044424200057984\n",
      "\n",
      "Epoch:    2/3     Batch:2745/6968  Loss: 4.121242332458496\n",
      "\n",
      "Epoch:    2/3     Batch:2750/6968  Loss: 3.7999868392944336\n",
      "\n",
      "Epoch:    2/3     Batch:2755/6968  Loss: 3.719509744644165\n",
      "\n",
      "Epoch:    2/3     Batch:2760/6968  Loss: 4.006004524230957\n",
      "\n",
      "Epoch:    2/3     Batch:2765/6968  Loss: 3.8575300693511965\n",
      "\n",
      "Epoch:    2/3     Batch:2770/6968  Loss: 3.7178223609924315\n",
      "\n",
      "Epoch:    2/3     Batch:2775/6968  Loss: 3.825666379928589\n",
      "\n",
      "Epoch:    2/3     Batch:2780/6968  Loss: 3.857037878036499\n",
      "\n",
      "Epoch:    2/3     Batch:2785/6968  Loss: 3.8858324527740478\n",
      "\n",
      "Epoch:    2/3     Batch:2790/6968  Loss: 3.9516919612884522\n",
      "\n",
      "Epoch:    2/3     Batch:2795/6968  Loss: 3.945497226715088\n",
      "\n",
      "Epoch:    2/3     Batch:2800/6968  Loss: 3.7514079093933104\n",
      "\n",
      "Epoch:    2/3     Batch:2805/6968  Loss: 3.7715267658233644\n",
      "\n",
      "Epoch:    2/3     Batch:2810/6968  Loss: 3.737295627593994\n",
      "\n",
      "Epoch:    2/3     Batch:2815/6968  Loss: 3.7709816455841065\n",
      "\n",
      "Epoch:    2/3     Batch:2820/6968  Loss: 3.726697301864624\n",
      "\n",
      "Epoch:    2/3     Batch:2825/6968  Loss: 3.720134973526001\n",
      "\n",
      "Epoch:    2/3     Batch:2830/6968  Loss: 3.840155506134033\n",
      "\n",
      "Epoch:    2/3     Batch:2835/6968  Loss: 3.860430431365967\n",
      "\n",
      "Epoch:    2/3     Batch:2840/6968  Loss: 3.6724467277526855\n",
      "\n",
      "Epoch:    2/3     Batch:2845/6968  Loss: 3.7493390083312987\n",
      "\n",
      "Epoch:    2/3     Batch:2850/6968  Loss: 3.7133966445922852\n",
      "\n",
      "Epoch:    2/3     Batch:2855/6968  Loss: 3.981497287750244\n",
      "\n",
      "Epoch:    2/3     Batch:2860/6968  Loss: 3.6598348140716555\n",
      "\n",
      "Epoch:    2/3     Batch:2865/6968  Loss: 3.7400871753692626\n",
      "\n",
      "Epoch:    2/3     Batch:2870/6968  Loss: 3.737101745605469\n",
      "\n",
      "Epoch:    2/3     Batch:2875/6968  Loss: 3.9611079692840576\n",
      "\n",
      "Epoch:    2/3     Batch:2880/6968  Loss: 3.8012221813201905\n",
      "\n",
      "Epoch:    2/3     Batch:2885/6968  Loss: 3.9111308574676515\n",
      "\n",
      "Epoch:    2/3     Batch:2890/6968  Loss: 4.066039943695069\n",
      "\n",
      "Epoch:    2/3     Batch:2895/6968  Loss: 3.918242931365967\n",
      "\n",
      "Epoch:    2/3     Batch:2900/6968  Loss: 3.711919069290161\n",
      "\n",
      "Epoch:    2/3     Batch:2905/6968  Loss: 3.6768939971923826\n",
      "\n",
      "Epoch:    2/3     Batch:2910/6968  Loss: 3.7355939865112306\n",
      "\n",
      "Epoch:    2/3     Batch:2915/6968  Loss: 3.8269925117492676\n",
      "\n",
      "Epoch:    2/3     Batch:2920/6968  Loss: 3.709271478652954\n",
      "\n",
      "Epoch:    2/3     Batch:2925/6968  Loss: 3.907550048828125\n",
      "\n",
      "Epoch:    2/3     Batch:2930/6968  Loss: 3.955762529373169\n",
      "\n",
      "Epoch:    2/3     Batch:2935/6968  Loss: 3.886966323852539\n",
      "\n",
      "Epoch:    2/3     Batch:2940/6968  Loss: 3.7431396007537843\n",
      "\n",
      "Epoch:    2/3     Batch:2945/6968  Loss: 3.8316093921661376\n",
      "\n",
      "Epoch:    2/3     Batch:2950/6968  Loss: 3.703019905090332\n",
      "\n",
      "Epoch:    2/3     Batch:2955/6968  Loss: 3.7478278160095213\n",
      "\n",
      "Epoch:    2/3     Batch:2960/6968  Loss: 3.7892537117004395\n",
      "\n",
      "Epoch:    2/3     Batch:2965/6968  Loss: 4.076878404617309\n",
      "\n",
      "Epoch:    2/3     Batch:2970/6968  Loss: 3.7526691913604737\n",
      "\n",
      "Epoch:    2/3     Batch:2975/6968  Loss: 4.061344480514526\n",
      "\n",
      "Epoch:    2/3     Batch:2980/6968  Loss: 3.7457024574279787\n",
      "\n",
      "Epoch:    2/3     Batch:2985/6968  Loss: 3.768692874908447\n",
      "\n",
      "Epoch:    2/3     Batch:2990/6968  Loss: 3.63804407119751\n",
      "\n",
      "Epoch:    2/3     Batch:2995/6968  Loss: 3.551225757598877\n",
      "\n",
      "Epoch:    2/3     Batch:3000/6968  Loss: 3.927251100540161\n",
      "\n",
      "Epoch:    2/3     Batch:3005/6968  Loss: 3.8793282508850098\n",
      "\n",
      "Epoch:    2/3     Batch:3010/6968  Loss: 3.7666780948638916\n",
      "\n",
      "Epoch:    2/3     Batch:3015/6968  Loss: 3.776017761230469\n",
      "\n",
      "Epoch:    2/3     Batch:3020/6968  Loss: 3.803324794769287\n",
      "\n",
      "Epoch:    2/3     Batch:3025/6968  Loss: 3.8124513149261476\n",
      "\n",
      "Epoch:    2/3     Batch:3030/6968  Loss: 4.02666654586792\n",
      "\n",
      "Epoch:    2/3     Batch:3035/6968  Loss: 3.9639494895935057\n",
      "\n",
      "Epoch:    2/3     Batch:3040/6968  Loss: 3.564542770385742\n",
      "\n",
      "Epoch:    2/3     Batch:3045/6968  Loss: 3.7848785400390623\n",
      "\n",
      "Epoch:    2/3     Batch:3050/6968  Loss: 3.7308498859405517\n",
      "\n",
      "Epoch:    2/3     Batch:3055/6968  Loss: 3.832296276092529\n",
      "\n",
      "Epoch:    2/3     Batch:3060/6968  Loss: 4.050561571121216\n",
      "\n",
      "Epoch:    2/3     Batch:3065/6968  Loss: 3.8601332664489747\n",
      "\n",
      "Epoch:    2/3     Batch:3070/6968  Loss: 3.7989269256591798\n",
      "\n",
      "Epoch:    2/3     Batch:3075/6968  Loss: 3.7552237510681152\n",
      "\n",
      "Epoch:    2/3     Batch:3080/6968  Loss: 3.7122019290924073\n",
      "\n",
      "Epoch:    2/3     Batch:3085/6968  Loss: 3.656076955795288\n",
      "\n",
      "Epoch:    2/3     Batch:3090/6968  Loss: 3.7391995429992675\n",
      "\n",
      "Epoch:    2/3     Batch:3095/6968  Loss: 3.964790153503418\n",
      "\n",
      "Epoch:    2/3     Batch:3100/6968  Loss: 3.706728792190552\n",
      "\n",
      "Epoch:    2/3     Batch:3105/6968  Loss: 3.7296092987060545\n",
      "\n",
      "Epoch:    2/3     Batch:3110/6968  Loss: 4.01254711151123\n",
      "\n",
      "Epoch:    2/3     Batch:3115/6968  Loss: 3.5623119831085206\n",
      "\n",
      "Epoch:    2/3     Batch:3120/6968  Loss: 3.858728361129761\n",
      "\n",
      "Epoch:    2/3     Batch:3125/6968  Loss: 3.701939344406128\n",
      "\n",
      "Epoch:    2/3     Batch:3130/6968  Loss: 3.737935209274292\n",
      "\n",
      "Epoch:    2/3     Batch:3135/6968  Loss: 3.811740016937256\n",
      "\n",
      "Epoch:    2/3     Batch:3140/6968  Loss: 3.8748549461364745\n",
      "\n",
      "Epoch:    2/3     Batch:3145/6968  Loss: 3.782530498504639\n",
      "\n",
      "Epoch:    2/3     Batch:3150/6968  Loss: 3.6623048305511476\n",
      "\n",
      "Epoch:    2/3     Batch:3155/6968  Loss: 3.711509084701538\n",
      "\n",
      "Epoch:    2/3     Batch:3160/6968  Loss: 3.8401946067810058\n",
      "\n",
      "Epoch:    2/3     Batch:3165/6968  Loss: 3.976603078842163\n",
      "\n",
      "Epoch:    2/3     Batch:3170/6968  Loss: 3.958208751678467\n",
      "\n",
      "Epoch:    2/3     Batch:3175/6968  Loss: 3.83687539100647\n",
      "\n",
      "Epoch:    2/3     Batch:3180/6968  Loss: 4.002006244659424\n",
      "\n",
      "Epoch:    2/3     Batch:3185/6968  Loss: 3.799088144302368\n",
      "\n",
      "Epoch:    2/3     Batch:3190/6968  Loss: 3.9181472301483153\n",
      "\n",
      "Epoch:    2/3     Batch:3195/6968  Loss: 3.7357004165649412\n",
      "\n",
      "Epoch:    2/3     Batch:3200/6968  Loss: 3.663999652862549\n",
      "\n",
      "Epoch:    2/3     Batch:3205/6968  Loss: 3.7227864265441895\n",
      "\n",
      "Epoch:    2/3     Batch:3210/6968  Loss: 3.613157033920288\n",
      "\n",
      "Epoch:    2/3     Batch:3215/6968  Loss: 3.739572286605835\n",
      "\n",
      "Epoch:    2/3     Batch:3220/6968  Loss: 3.914030361175537\n",
      "\n",
      "Epoch:    2/3     Batch:3225/6968  Loss: 4.018492841720581\n",
      "\n",
      "Epoch:    2/3     Batch:3230/6968  Loss: 3.8647281646728517\n",
      "\n",
      "Epoch:    2/3     Batch:3235/6968  Loss: 3.9207081317901613\n",
      "\n",
      "Epoch:    2/3     Batch:3240/6968  Loss: 3.999860429763794\n",
      "\n",
      "Epoch:    2/3     Batch:3245/6968  Loss: 3.807867240905762\n",
      "\n",
      "Epoch:    2/3     Batch:3250/6968  Loss: 3.677493190765381\n",
      "\n",
      "Epoch:    2/3     Batch:3255/6968  Loss: 3.8487929821014406\n",
      "\n",
      "Epoch:    2/3     Batch:3260/6968  Loss: 3.7746654987335204\n",
      "\n",
      "Epoch:    2/3     Batch:3265/6968  Loss: 3.8439849376678468\n",
      "\n",
      "Epoch:    2/3     Batch:3270/6968  Loss: 3.792592096328735\n",
      "\n",
      "Epoch:    2/3     Batch:3275/6968  Loss: 3.6126287937164308\n",
      "\n",
      "Epoch:    2/3     Batch:3280/6968  Loss: 3.775276756286621\n",
      "\n",
      "Epoch:    2/3     Batch:3285/6968  Loss: 3.792679786682129\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    2/3     Batch:3290/6968  Loss: 3.7507766246795655\n",
      "\n",
      "Epoch:    2/3     Batch:3295/6968  Loss: 3.9559173583984375\n",
      "\n",
      "Epoch:    2/3     Batch:3300/6968  Loss: 3.9949387550354003\n",
      "\n",
      "Epoch:    2/3     Batch:3305/6968  Loss: 3.5590884685516357\n",
      "\n",
      "Epoch:    2/3     Batch:3310/6968  Loss: 3.736787939071655\n",
      "\n",
      "Epoch:    2/3     Batch:3315/6968  Loss: 4.108086442947387\n",
      "\n",
      "Epoch:    2/3     Batch:3320/6968  Loss: 3.870104694366455\n",
      "\n",
      "Epoch:    2/3     Batch:3325/6968  Loss: 3.9322906017303465\n",
      "\n",
      "Epoch:    2/3     Batch:3330/6968  Loss: 3.631488037109375\n",
      "\n",
      "Epoch:    2/3     Batch:3335/6968  Loss: 4.24185733795166\n",
      "\n",
      "Epoch:    2/3     Batch:3340/6968  Loss: 3.92414927482605\n",
      "\n",
      "Epoch:    2/3     Batch:3345/6968  Loss: 3.7884681701660154\n",
      "\n",
      "Epoch:    2/3     Batch:3350/6968  Loss: 3.7977845668792725\n",
      "\n",
      "Epoch:    2/3     Batch:3355/6968  Loss: 3.9120495319366455\n",
      "\n",
      "Epoch:    2/3     Batch:3360/6968  Loss: 3.6455427169799806\n",
      "\n",
      "Epoch:    2/3     Batch:3365/6968  Loss: 3.755256414413452\n",
      "\n",
      "Epoch:    2/3     Batch:3370/6968  Loss: 3.852244663238525\n",
      "\n",
      "Epoch:    2/3     Batch:3375/6968  Loss: 3.8093879222869873\n",
      "\n",
      "Epoch:    2/3     Batch:3380/6968  Loss: 3.8234682083129883\n",
      "\n",
      "Epoch:    2/3     Batch:3385/6968  Loss: 3.7090171813964843\n",
      "\n",
      "Epoch:    2/3     Batch:3390/6968  Loss: 3.874358797073364\n",
      "\n",
      "Epoch:    2/3     Batch:3395/6968  Loss: 3.6950907707214355\n",
      "\n",
      "Epoch:    2/3     Batch:3400/6968  Loss: 3.973257303237915\n",
      "\n",
      "Epoch:    2/3     Batch:3405/6968  Loss: 3.714118003845215\n",
      "\n",
      "Epoch:    2/3     Batch:3410/6968  Loss: 3.823012447357178\n",
      "\n",
      "Epoch:    2/3     Batch:3415/6968  Loss: 3.6843523025512694\n",
      "\n",
      "Epoch:    2/3     Batch:3420/6968  Loss: 3.9925539016723635\n",
      "\n",
      "Epoch:    2/3     Batch:3425/6968  Loss: 3.970104217529297\n",
      "\n",
      "Epoch:    2/3     Batch:3430/6968  Loss: 3.680158185958862\n",
      "\n",
      "Epoch:    2/3     Batch:3435/6968  Loss: 3.740778398513794\n",
      "\n",
      "Epoch:    2/3     Batch:3440/6968  Loss: 3.6279393672943114\n",
      "\n",
      "Epoch:    2/3     Batch:3445/6968  Loss: 3.7504598617553713\n",
      "\n",
      "Epoch:    2/3     Batch:3450/6968  Loss: 3.8048753261566164\n",
      "\n",
      "Epoch:    2/3     Batch:3455/6968  Loss: 3.798804187774658\n",
      "\n",
      "Epoch:    2/3     Batch:3460/6968  Loss: 3.822109031677246\n",
      "\n",
      "Epoch:    2/3     Batch:3465/6968  Loss: 3.855903720855713\n",
      "\n",
      "Epoch:    2/3     Batch:3470/6968  Loss: 3.655005693435669\n",
      "\n",
      "Epoch:    2/3     Batch:3475/6968  Loss: 3.7219342231750487\n",
      "\n",
      "Epoch:    2/3     Batch:3480/6968  Loss: 3.9439745426177977\n",
      "\n",
      "Epoch:    2/3     Batch:3485/6968  Loss: 3.8703564167022706\n",
      "\n",
      "Epoch:    2/3     Batch:3490/6968  Loss: 3.7403165340423583\n",
      "\n",
      "Epoch:    2/3     Batch:3495/6968  Loss: 3.742691087722778\n",
      "\n",
      "Epoch:    2/3     Batch:3500/6968  Loss: 3.7785880088806154\n",
      "\n",
      "Epoch:    2/3     Batch:3505/6968  Loss: 3.7199524879455566\n",
      "\n",
      "Epoch:    2/3     Batch:3510/6968  Loss: 3.866621255874634\n",
      "\n",
      "Epoch:    2/3     Batch:3515/6968  Loss: 3.562051296234131\n",
      "\n",
      "Epoch:    2/3     Batch:3520/6968  Loss: 4.034075593948364\n",
      "\n",
      "Epoch:    2/3     Batch:3525/6968  Loss: 4.019994163513184\n",
      "\n",
      "Epoch:    2/3     Batch:3530/6968  Loss: 4.0265425682067875\n",
      "\n",
      "Epoch:    2/3     Batch:3535/6968  Loss: 3.572662878036499\n",
      "\n",
      "Epoch:    2/3     Batch:3540/6968  Loss: 3.859357213973999\n",
      "\n",
      "Epoch:    2/3     Batch:3545/6968  Loss: 3.9142780780792235\n",
      "\n",
      "Epoch:    2/3     Batch:3550/6968  Loss: 3.767061185836792\n",
      "\n",
      "Epoch:    2/3     Batch:3555/6968  Loss: 3.834211587905884\n",
      "\n",
      "Epoch:    2/3     Batch:3560/6968  Loss: 3.821006488800049\n",
      "\n",
      "Epoch:    2/3     Batch:3565/6968  Loss: 3.591128349304199\n",
      "\n",
      "Epoch:    2/3     Batch:3570/6968  Loss: 3.8898508548736572\n",
      "\n",
      "Epoch:    2/3     Batch:3575/6968  Loss: 3.9326735973358153\n",
      "\n",
      "Epoch:    2/3     Batch:3580/6968  Loss: 3.855867528915405\n",
      "\n",
      "Epoch:    2/3     Batch:3585/6968  Loss: 3.7852617740631103\n",
      "\n",
      "Epoch:    2/3     Batch:3590/6968  Loss: 3.8761348724365234\n",
      "\n",
      "Epoch:    2/3     Batch:3595/6968  Loss: 3.890468883514404\n",
      "\n",
      "Epoch:    2/3     Batch:3600/6968  Loss: 3.732526445388794\n",
      "\n",
      "Epoch:    2/3     Batch:3605/6968  Loss: 3.743197298049927\n",
      "\n",
      "Epoch:    2/3     Batch:3610/6968  Loss: 3.991197919845581\n",
      "\n",
      "Epoch:    2/3     Batch:3615/6968  Loss: 3.613530969619751\n",
      "\n",
      "Epoch:    2/3     Batch:3620/6968  Loss: 3.9048662185668945\n",
      "\n",
      "Epoch:    2/3     Batch:3625/6968  Loss: 3.9634655952453612\n",
      "\n",
      "Epoch:    2/3     Batch:3630/6968  Loss: 3.7571299076080322\n",
      "\n",
      "Epoch:    2/3     Batch:3635/6968  Loss: 3.81469521522522\n",
      "\n",
      "Epoch:    2/3     Batch:3640/6968  Loss: 3.9522969722747803\n",
      "\n",
      "Epoch:    2/3     Batch:3645/6968  Loss: 3.772557497024536\n",
      "\n",
      "Epoch:    2/3     Batch:3650/6968  Loss: 3.6328585624694822\n",
      "\n",
      "Epoch:    2/3     Batch:3655/6968  Loss: 3.5438125133514404\n",
      "\n",
      "Epoch:    2/3     Batch:3660/6968  Loss: 3.677974319458008\n",
      "\n",
      "Epoch:    2/3     Batch:3665/6968  Loss: 3.8072911739349364\n",
      "\n",
      "Epoch:    2/3     Batch:3670/6968  Loss: 3.800987482070923\n",
      "\n",
      "Epoch:    2/3     Batch:3675/6968  Loss: 3.7098808765411375\n",
      "\n",
      "Epoch:    2/3     Batch:3680/6968  Loss: 3.8703965187072753\n",
      "\n",
      "Epoch:    2/3     Batch:3685/6968  Loss: 3.6594841957092283\n",
      "\n",
      "Epoch:    2/3     Batch:3690/6968  Loss: 3.783639144897461\n",
      "\n",
      "Epoch:    2/3     Batch:3695/6968  Loss: 3.9480847835540773\n",
      "\n",
      "Epoch:    2/3     Batch:3700/6968  Loss: 3.6993968963623045\n",
      "\n",
      "Epoch:    2/3     Batch:3705/6968  Loss: 3.8699435234069823\n",
      "\n",
      "Epoch:    2/3     Batch:3710/6968  Loss: 3.5268548488616944\n",
      "\n",
      "Epoch:    2/3     Batch:3715/6968  Loss: 3.8331616878509522\n",
      "\n",
      "Epoch:    2/3     Batch:3720/6968  Loss: 3.881550741195679\n",
      "\n",
      "Epoch:    2/3     Batch:3725/6968  Loss: 3.8724882125854494\n",
      "\n",
      "Epoch:    2/3     Batch:3730/6968  Loss: 3.9124233722686768\n",
      "\n",
      "Epoch:    2/3     Batch:3735/6968  Loss: 3.874689245223999\n",
      "\n",
      "Epoch:    2/3     Batch:3740/6968  Loss: 3.8106953620910646\n",
      "\n",
      "Epoch:    2/3     Batch:3745/6968  Loss: 3.6751869201660154\n",
      "\n",
      "Epoch:    2/3     Batch:3750/6968  Loss: 3.9950690269470215\n",
      "\n",
      "Epoch:    2/3     Batch:3755/6968  Loss: 3.762118339538574\n",
      "\n",
      "Epoch:    2/3     Batch:3760/6968  Loss: 3.6767271995544433\n",
      "\n",
      "Epoch:    2/3     Batch:3765/6968  Loss: 3.7038620471954347\n",
      "\n",
      "Epoch:    2/3     Batch:3770/6968  Loss: 3.9493306636810304\n",
      "\n",
      "Epoch:    2/3     Batch:3775/6968  Loss: 3.7197397232055662\n",
      "\n",
      "Epoch:    2/3     Batch:3780/6968  Loss: 3.5160892963409425\n",
      "\n",
      "Epoch:    2/3     Batch:3785/6968  Loss: 3.8122325420379637\n",
      "\n",
      "Epoch:    2/3     Batch:3790/6968  Loss: 3.817281436920166\n",
      "\n",
      "Epoch:    2/3     Batch:3795/6968  Loss: 3.6629955768585205\n",
      "\n",
      "Epoch:    2/3     Batch:3800/6968  Loss: 3.8857725143432615\n",
      "\n",
      "Epoch:    2/3     Batch:3805/6968  Loss: 3.8475083351135253\n",
      "\n",
      "Epoch:    2/3     Batch:3810/6968  Loss: 3.8200123786926268\n",
      "\n",
      "Epoch:    2/3     Batch:3815/6968  Loss: 3.778355598449707\n",
      "\n",
      "Epoch:    2/3     Batch:3820/6968  Loss: 3.805120611190796\n",
      "\n",
      "Epoch:    2/3     Batch:3825/6968  Loss: 3.8127100467681885\n",
      "\n",
      "Epoch:    2/3     Batch:3830/6968  Loss: 3.9412793636322023\n",
      "\n",
      "Epoch:    2/3     Batch:3835/6968  Loss: 3.8874773025512694\n",
      "\n",
      "Epoch:    2/3     Batch:3840/6968  Loss: 3.66614146232605\n",
      "\n",
      "Epoch:    2/3     Batch:3845/6968  Loss: 3.8193092346191406\n",
      "\n",
      "Epoch:    2/3     Batch:3850/6968  Loss: 3.812577486038208\n",
      "\n",
      "Epoch:    2/3     Batch:3855/6968  Loss: 3.710073947906494\n",
      "\n",
      "Epoch:    2/3     Batch:3860/6968  Loss: 3.907406806945801\n",
      "\n",
      "Epoch:    2/3     Batch:3865/6968  Loss: 3.8283599376678468\n",
      "\n",
      "Epoch:    2/3     Batch:3870/6968  Loss: 3.853131341934204\n",
      "\n",
      "Epoch:    2/3     Batch:3875/6968  Loss: 3.747030019760132\n",
      "\n",
      "Epoch:    2/3     Batch:3880/6968  Loss: 3.922444534301758\n",
      "\n",
      "Epoch:    2/3     Batch:3885/6968  Loss: 3.8983850955963133\n",
      "\n",
      "Epoch:    2/3     Batch:3890/6968  Loss: 4.021721839904785\n",
      "\n",
      "Epoch:    2/3     Batch:3895/6968  Loss: 3.8084764957427977\n",
      "\n",
      "Epoch:    2/3     Batch:3900/6968  Loss: 3.9348856925964357\n",
      "\n",
      "Epoch:    2/3     Batch:3905/6968  Loss: 3.8135788440704346\n",
      "\n",
      "Epoch:    2/3     Batch:3910/6968  Loss: 3.780546474456787\n",
      "\n",
      "Epoch:    2/3     Batch:3915/6968  Loss: 3.722021293640137\n",
      "\n",
      "Epoch:    2/3     Batch:3920/6968  Loss: 3.787913608551025\n",
      "\n",
      "Epoch:    2/3     Batch:3925/6968  Loss: 3.712563133239746\n",
      "\n",
      "Epoch:    2/3     Batch:3930/6968  Loss: 3.6970916271209715\n",
      "\n",
      "Epoch:    2/3     Batch:3935/6968  Loss: 3.8277362823486327\n",
      "\n",
      "Epoch:    2/3     Batch:3940/6968  Loss: 4.134661436080933\n",
      "\n",
      "Epoch:    2/3     Batch:3945/6968  Loss: 3.8610344409942625\n",
      "\n",
      "Epoch:    2/3     Batch:3950/6968  Loss: 4.00558295249939\n",
      "\n",
      "Epoch:    2/3     Batch:3955/6968  Loss: 3.6624378681182863\n",
      "\n",
      "Epoch:    2/3     Batch:3960/6968  Loss: 3.7456600666046143\n",
      "\n",
      "Epoch:    2/3     Batch:3965/6968  Loss: 3.9126715660095215\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    2/3     Batch:3970/6968  Loss: 3.967330503463745\n",
      "\n",
      "Epoch:    2/3     Batch:3975/6968  Loss: 3.7241886615753175\n",
      "\n",
      "Epoch:    2/3     Batch:3980/6968  Loss: 3.9308534145355223\n",
      "\n",
      "Epoch:    2/3     Batch:3985/6968  Loss: 3.595307159423828\n",
      "\n",
      "Epoch:    2/3     Batch:3990/6968  Loss: 3.6305511474609373\n",
      "\n",
      "Epoch:    2/3     Batch:3995/6968  Loss: 4.061184740066528\n",
      "\n",
      "Epoch:    2/3     Batch:4000/6968  Loss: 3.6942914485931397\n",
      "\n",
      "Epoch:    2/3     Batch:4005/6968  Loss: 3.7456281185150146\n",
      "\n",
      "Epoch:    2/3     Batch:4010/6968  Loss: 3.801266050338745\n",
      "\n",
      "Epoch:    2/3     Batch:4015/6968  Loss: 3.89742226600647\n",
      "\n",
      "Epoch:    2/3     Batch:4020/6968  Loss: 3.8126247406005858\n",
      "\n",
      "Epoch:    2/3     Batch:4025/6968  Loss: 3.8139456272125245\n",
      "\n",
      "Epoch:    2/3     Batch:4030/6968  Loss: 3.7419179916381835\n",
      "\n",
      "Epoch:    2/3     Batch:4035/6968  Loss: 3.875190019607544\n",
      "\n",
      "Epoch:    2/3     Batch:4040/6968  Loss: 3.7667833805084228\n",
      "\n",
      "Epoch:    2/3     Batch:4045/6968  Loss: 3.6570215225219727\n",
      "\n",
      "Epoch:    2/3     Batch:4050/6968  Loss: 3.828149604797363\n",
      "\n",
      "Epoch:    2/3     Batch:4055/6968  Loss: 3.813998079299927\n",
      "\n",
      "Epoch:    2/3     Batch:4060/6968  Loss: 3.783851671218872\n",
      "\n",
      "Epoch:    2/3     Batch:4065/6968  Loss: 3.834431028366089\n",
      "\n",
      "Epoch:    2/3     Batch:4070/6968  Loss: 3.8369438648223877\n",
      "\n",
      "Epoch:    2/3     Batch:4075/6968  Loss: 3.8827052116394043\n",
      "\n",
      "Epoch:    2/3     Batch:4080/6968  Loss: 3.543907308578491\n",
      "\n",
      "Epoch:    2/3     Batch:4085/6968  Loss: 3.9228017330169678\n",
      "\n",
      "Epoch:    2/3     Batch:4090/6968  Loss: 3.6586844444274904\n",
      "\n",
      "Epoch:    2/3     Batch:4095/6968  Loss: 3.7738433837890626\n",
      "\n",
      "Epoch:    2/3     Batch:4100/6968  Loss: 3.845727825164795\n",
      "\n",
      "Epoch:    2/3     Batch:4105/6968  Loss: 3.8210122108459474\n",
      "\n",
      "Epoch:    2/3     Batch:4110/6968  Loss: 3.565903377532959\n",
      "\n",
      "Epoch:    2/3     Batch:4115/6968  Loss: 3.5781461715698244\n",
      "\n",
      "Epoch:    2/3     Batch:4120/6968  Loss: 3.8295400619506834\n",
      "\n",
      "Epoch:    2/3     Batch:4125/6968  Loss: 3.8028568744659426\n",
      "\n",
      "Epoch:    2/3     Batch:4130/6968  Loss: 3.858531045913696\n",
      "\n",
      "Epoch:    2/3     Batch:4135/6968  Loss: 4.10901575088501\n",
      "\n",
      "Epoch:    2/3     Batch:4140/6968  Loss: 3.7640085220336914\n",
      "\n",
      "Epoch:    2/3     Batch:4145/6968  Loss: 3.871538686752319\n",
      "\n",
      "Epoch:    2/3     Batch:4150/6968  Loss: 3.8971161365509035\n",
      "\n",
      "Epoch:    2/3     Batch:4155/6968  Loss: 3.7781480312347413\n",
      "\n",
      "Epoch:    2/3     Batch:4160/6968  Loss: 3.79625883102417\n",
      "\n",
      "Epoch:    2/3     Batch:4165/6968  Loss: 3.854441452026367\n",
      "\n",
      "Epoch:    2/3     Batch:4170/6968  Loss: 3.6837642669677733\n",
      "\n",
      "Epoch:    2/3     Batch:4175/6968  Loss: 3.7603599071502685\n",
      "\n",
      "Epoch:    2/3     Batch:4180/6968  Loss: 3.737722873687744\n",
      "\n",
      "Epoch:    2/3     Batch:4185/6968  Loss: 3.7133147716522217\n",
      "\n",
      "Epoch:    2/3     Batch:4190/6968  Loss: 3.6999560832977294\n",
      "\n",
      "Epoch:    2/3     Batch:4195/6968  Loss: 3.979008913040161\n",
      "\n",
      "Epoch:    2/3     Batch:4200/6968  Loss: 3.8665321350097654\n",
      "\n",
      "Epoch:    2/3     Batch:4205/6968  Loss: 3.7692816734313963\n",
      "\n",
      "Epoch:    2/3     Batch:4210/6968  Loss: 3.631047582626343\n",
      "\n",
      "Epoch:    2/3     Batch:4215/6968  Loss: 3.8678516864776613\n",
      "\n",
      "Epoch:    2/3     Batch:4220/6968  Loss: 3.7308631420135496\n",
      "\n",
      "Epoch:    2/3     Batch:4225/6968  Loss: 3.802954816818237\n",
      "\n",
      "Epoch:    2/3     Batch:4230/6968  Loss: 3.774156904220581\n",
      "\n",
      "Epoch:    2/3     Batch:4235/6968  Loss: 3.8608302593231203\n",
      "\n",
      "Epoch:    2/3     Batch:4240/6968  Loss: 3.806098461151123\n",
      "\n",
      "Epoch:    2/3     Batch:4245/6968  Loss: 3.707586669921875\n",
      "\n",
      "Epoch:    2/3     Batch:4250/6968  Loss: 3.7321086883544923\n",
      "\n",
      "Epoch:    2/3     Batch:4255/6968  Loss: 4.012761497497559\n",
      "\n",
      "Epoch:    2/3     Batch:4260/6968  Loss: 3.7172225952148437\n",
      "\n",
      "Epoch:    2/3     Batch:4265/6968  Loss: 3.8466036319732666\n",
      "\n",
      "Epoch:    2/3     Batch:4270/6968  Loss: 4.027705430984497\n",
      "\n",
      "Epoch:    2/3     Batch:4275/6968  Loss: 3.573508930206299\n",
      "\n",
      "Epoch:    2/3     Batch:4280/6968  Loss: 3.5965593338012694\n",
      "\n",
      "Epoch:    2/3     Batch:4285/6968  Loss: 3.7198168277740478\n",
      "\n",
      "Epoch:    2/3     Batch:4290/6968  Loss: 3.9721930503845213\n",
      "\n",
      "Epoch:    2/3     Batch:4295/6968  Loss: 3.6486268043518066\n",
      "\n",
      "Epoch:    2/3     Batch:4300/6968  Loss: 3.869005632400513\n",
      "\n",
      "Epoch:    2/3     Batch:4305/6968  Loss: 3.6951632499694824\n",
      "\n",
      "Epoch:    2/3     Batch:4310/6968  Loss: 3.835023832321167\n",
      "\n",
      "Epoch:    2/3     Batch:4315/6968  Loss: 3.9352313041687013\n",
      "\n",
      "Epoch:    2/3     Batch:4320/6968  Loss: 3.7291749477386475\n",
      "\n",
      "Epoch:    2/3     Batch:4325/6968  Loss: 3.8788068771362303\n",
      "\n",
      "Epoch:    2/3     Batch:4330/6968  Loss: 3.837403392791748\n",
      "\n",
      "Epoch:    2/3     Batch:4335/6968  Loss: 3.8165910720825194\n",
      "\n",
      "Epoch:    2/3     Batch:4340/6968  Loss: 3.731826066970825\n",
      "\n",
      "Epoch:    2/3     Batch:4345/6968  Loss: 3.9616861820220945\n",
      "\n",
      "Epoch:    2/3     Batch:4350/6968  Loss: 3.8674950122833254\n",
      "\n",
      "Epoch:    2/3     Batch:4355/6968  Loss: 3.7798759937286377\n",
      "\n",
      "Epoch:    2/3     Batch:4360/6968  Loss: 3.918657970428467\n",
      "\n",
      "Epoch:    2/3     Batch:4365/6968  Loss: 3.882863759994507\n",
      "\n",
      "Epoch:    2/3     Batch:4370/6968  Loss: 3.7563642978668215\n",
      "\n",
      "Epoch:    2/3     Batch:4375/6968  Loss: 3.93784875869751\n",
      "\n",
      "Epoch:    2/3     Batch:4380/6968  Loss: 3.7877395153045654\n",
      "\n",
      "Epoch:    2/3     Batch:4385/6968  Loss: 3.893427038192749\n",
      "\n",
      "Epoch:    2/3     Batch:4390/6968  Loss: 3.959363603591919\n",
      "\n",
      "Epoch:    2/3     Batch:4395/6968  Loss: 3.8017326831817626\n",
      "\n",
      "Epoch:    2/3     Batch:4400/6968  Loss: 3.948644733428955\n",
      "\n",
      "Epoch:    2/3     Batch:4405/6968  Loss: 3.9983798027038575\n",
      "\n",
      "Epoch:    2/3     Batch:4410/6968  Loss: 3.8518464088439943\n",
      "\n",
      "Epoch:    2/3     Batch:4415/6968  Loss: 3.6011910438537598\n",
      "\n",
      "Epoch:    2/3     Batch:4420/6968  Loss: 3.9743422508239745\n",
      "\n",
      "Epoch:    2/3     Batch:4425/6968  Loss: 3.7028861045837402\n",
      "\n",
      "Epoch:    2/3     Batch:4430/6968  Loss: 3.8893850803375245\n",
      "\n",
      "Epoch:    2/3     Batch:4435/6968  Loss: 3.796844720840454\n",
      "\n",
      "Epoch:    2/3     Batch:4440/6968  Loss: 3.900302505493164\n",
      "\n",
      "Epoch:    2/3     Batch:4445/6968  Loss: 3.872003126144409\n",
      "\n",
      "Epoch:    2/3     Batch:4450/6968  Loss: 3.887040138244629\n",
      "\n",
      "Epoch:    2/3     Batch:4455/6968  Loss: 3.8627460956573487\n",
      "\n",
      "Epoch:    2/3     Batch:4460/6968  Loss: 3.800565242767334\n",
      "\n",
      "Epoch:    2/3     Batch:4465/6968  Loss: 3.778953790664673\n",
      "\n",
      "Epoch:    2/3     Batch:4470/6968  Loss: 3.6027809619903564\n",
      "\n",
      "Epoch:    2/3     Batch:4475/6968  Loss: 3.9538224220275877\n",
      "\n",
      "Epoch:    2/3     Batch:4480/6968  Loss: 3.799280071258545\n",
      "\n",
      "Epoch:    2/3     Batch:4485/6968  Loss: 4.053705453872681\n",
      "\n",
      "Epoch:    2/3     Batch:4490/6968  Loss: 3.998576259613037\n",
      "\n",
      "Epoch:    2/3     Batch:4495/6968  Loss: 3.7091891765594482\n",
      "\n",
      "Epoch:    2/3     Batch:4500/6968  Loss: 3.6482106685638427\n",
      "\n",
      "Epoch:    2/3     Batch:4505/6968  Loss: 3.7541004180908204\n",
      "\n",
      "Epoch:    2/3     Batch:4510/6968  Loss: 3.9536949634552\n",
      "\n",
      "Epoch:    2/3     Batch:4515/6968  Loss: 3.626797151565552\n",
      "\n",
      "Epoch:    2/3     Batch:4520/6968  Loss: 3.8158031463623048\n",
      "\n",
      "Epoch:    2/3     Batch:4525/6968  Loss: 3.751353120803833\n",
      "\n",
      "Epoch:    2/3     Batch:4530/6968  Loss: 3.8648490428924562\n",
      "\n",
      "Epoch:    2/3     Batch:4535/6968  Loss: 3.756338024139404\n",
      "\n",
      "Epoch:    2/3     Batch:4540/6968  Loss: 4.011962461471557\n",
      "\n",
      "Epoch:    2/3     Batch:4545/6968  Loss: 3.7892268180847166\n",
      "\n",
      "Epoch:    2/3     Batch:4550/6968  Loss: 3.923501443862915\n",
      "\n",
      "Epoch:    2/3     Batch:4555/6968  Loss: 3.635318374633789\n",
      "\n",
      "Epoch:    2/3     Batch:4560/6968  Loss: 3.8164352893829347\n",
      "\n",
      "Epoch:    2/3     Batch:4565/6968  Loss: 3.758690929412842\n",
      "\n",
      "Epoch:    2/3     Batch:4570/6968  Loss: 3.65616455078125\n",
      "\n",
      "Epoch:    2/3     Batch:4575/6968  Loss: 3.877512979507446\n",
      "\n",
      "Epoch:    2/3     Batch:4580/6968  Loss: 3.7956383228302\n",
      "\n",
      "Epoch:    2/3     Batch:4585/6968  Loss: 3.822966194152832\n",
      "\n",
      "Epoch:    2/3     Batch:4590/6968  Loss: 3.896741533279419\n",
      "\n",
      "Epoch:    2/3     Batch:4595/6968  Loss: 3.795627164840698\n",
      "\n",
      "Epoch:    2/3     Batch:4600/6968  Loss: 3.8024343967437746\n",
      "\n",
      "Epoch:    2/3     Batch:4605/6968  Loss: 3.712254190444946\n",
      "\n",
      "Epoch:    2/3     Batch:4610/6968  Loss: 3.850968265533447\n",
      "\n",
      "Epoch:    2/3     Batch:4615/6968  Loss: 3.9492304801940916\n",
      "\n",
      "Epoch:    2/3     Batch:4620/6968  Loss: 3.826610231399536\n",
      "\n",
      "Epoch:    2/3     Batch:4625/6968  Loss: 3.716632080078125\n",
      "\n",
      "Epoch:    2/3     Batch:4630/6968  Loss: 3.627717113494873\n",
      "\n",
      "Epoch:    2/3     Batch:4635/6968  Loss: 3.7798937797546386\n",
      "\n",
      "Epoch:    2/3     Batch:4640/6968  Loss: 3.7500918388366697\n",
      "\n",
      "Epoch:    2/3     Batch:4645/6968  Loss: 3.9709583282470704\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    2/3     Batch:4650/6968  Loss: 3.6047362804412844\n",
      "\n",
      "Epoch:    2/3     Batch:4655/6968  Loss: 3.660362720489502\n",
      "\n",
      "Epoch:    2/3     Batch:4660/6968  Loss: 3.752304935455322\n",
      "\n",
      "Epoch:    2/3     Batch:4665/6968  Loss: 3.664357900619507\n",
      "\n",
      "Epoch:    2/3     Batch:4670/6968  Loss: 3.8813587188720704\n",
      "\n",
      "Epoch:    2/3     Batch:4675/6968  Loss: 3.8313999652862547\n",
      "\n",
      "Epoch:    2/3     Batch:4680/6968  Loss: 3.7130356788635255\n",
      "\n",
      "Epoch:    2/3     Batch:4685/6968  Loss: 3.8269375801086425\n",
      "\n",
      "Epoch:    2/3     Batch:4690/6968  Loss: 3.881352758407593\n",
      "\n",
      "Epoch:    2/3     Batch:4695/6968  Loss: 3.701217222213745\n",
      "\n",
      "Epoch:    2/3     Batch:4700/6968  Loss: 3.822355318069458\n",
      "\n",
      "Epoch:    2/3     Batch:4705/6968  Loss: 3.793835926055908\n",
      "\n",
      "Epoch:    2/3     Batch:4710/6968  Loss: 3.606548309326172\n",
      "\n",
      "Epoch:    2/3     Batch:4715/6968  Loss: 3.971988153457642\n",
      "\n",
      "Epoch:    2/3     Batch:4720/6968  Loss: 3.7730435848236086\n",
      "\n",
      "Epoch:    2/3     Batch:4725/6968  Loss: 3.9121283531188964\n",
      "\n",
      "Epoch:    2/3     Batch:4730/6968  Loss: 3.8440186977386475\n",
      "\n",
      "Epoch:    2/3     Batch:4735/6968  Loss: 3.70219087600708\n",
      "\n",
      "Epoch:    2/3     Batch:4740/6968  Loss: 3.7293145179748537\n",
      "\n",
      "Epoch:    2/3     Batch:4745/6968  Loss: 3.641485023498535\n",
      "\n",
      "Epoch:    2/3     Batch:4750/6968  Loss: 3.9384342670440673\n",
      "\n",
      "Epoch:    2/3     Batch:4755/6968  Loss: 3.7368030071258547\n",
      "\n",
      "Epoch:    2/3     Batch:4760/6968  Loss: 3.9378607273101807\n",
      "\n",
      "Epoch:    2/3     Batch:4765/6968  Loss: 3.687113332748413\n",
      "\n",
      "Epoch:    2/3     Batch:4770/6968  Loss: 3.8116581439971924\n",
      "\n",
      "Epoch:    2/3     Batch:4775/6968  Loss: 3.9208476066589357\n",
      "\n",
      "Epoch:    2/3     Batch:4780/6968  Loss: 3.746925449371338\n",
      "\n",
      "Epoch:    2/3     Batch:4785/6968  Loss: 4.000230741500855\n",
      "\n",
      "Epoch:    2/3     Batch:4790/6968  Loss: 3.749787616729736\n",
      "\n",
      "Epoch:    2/3     Batch:4795/6968  Loss: 3.9894710063934324\n",
      "\n",
      "Epoch:    2/3     Batch:4800/6968  Loss: 3.8923125743865965\n",
      "\n",
      "Epoch:    2/3     Batch:4805/6968  Loss: 3.859662580490112\n",
      "\n",
      "Epoch:    2/3     Batch:4810/6968  Loss: 3.669241189956665\n",
      "\n",
      "Epoch:    2/3     Batch:4815/6968  Loss: 3.8840662002563477\n",
      "\n",
      "Epoch:    2/3     Batch:4820/6968  Loss: 3.9350257396697996\n",
      "\n",
      "Epoch:    2/3     Batch:4825/6968  Loss: 3.6626636505126955\n",
      "\n",
      "Epoch:    2/3     Batch:4830/6968  Loss: 3.8792489051818846\n",
      "\n",
      "Epoch:    2/3     Batch:4835/6968  Loss: 3.710391712188721\n",
      "\n",
      "Epoch:    2/3     Batch:4840/6968  Loss: 3.607288932800293\n",
      "\n",
      "Epoch:    2/3     Batch:4845/6968  Loss: 3.8046284675598145\n",
      "\n",
      "Epoch:    2/3     Batch:4850/6968  Loss: 3.684242105484009\n",
      "\n",
      "Epoch:    2/3     Batch:4855/6968  Loss: 3.838816785812378\n",
      "\n",
      "Epoch:    2/3     Batch:4860/6968  Loss: 3.6813046455383303\n",
      "\n",
      "Epoch:    2/3     Batch:4865/6968  Loss: 3.571989107131958\n",
      "\n",
      "Epoch:    2/3     Batch:4870/6968  Loss: 3.665253925323486\n",
      "\n",
      "Epoch:    2/3     Batch:4875/6968  Loss: 3.8723639965057375\n",
      "\n",
      "Epoch:    2/3     Batch:4880/6968  Loss: 3.8689038276672365\n",
      "\n",
      "Epoch:    2/3     Batch:4885/6968  Loss: 3.780787992477417\n",
      "\n",
      "Epoch:    2/3     Batch:4890/6968  Loss: 3.974315118789673\n",
      "\n",
      "Epoch:    2/3     Batch:4895/6968  Loss: 3.8156746864318847\n",
      "\n",
      "Epoch:    2/3     Batch:4900/6968  Loss: 3.551452159881592\n",
      "\n",
      "Epoch:    2/3     Batch:4905/6968  Loss: 3.5908109188079833\n",
      "\n",
      "Epoch:    2/3     Batch:4910/6968  Loss: 3.7803528785705565\n",
      "\n",
      "Epoch:    2/3     Batch:4915/6968  Loss: 3.8649012088775634\n",
      "\n",
      "Epoch:    2/3     Batch:4920/6968  Loss: 3.880794143676758\n",
      "\n",
      "Epoch:    2/3     Batch:4925/6968  Loss: 3.880186986923218\n",
      "\n",
      "Epoch:    2/3     Batch:4930/6968  Loss: 3.8917582988739015\n",
      "\n",
      "Epoch:    2/3     Batch:4935/6968  Loss: 3.875769329071045\n",
      "\n",
      "Epoch:    2/3     Batch:4940/6968  Loss: 3.917366361618042\n",
      "\n",
      "Epoch:    2/3     Batch:4945/6968  Loss: 3.572869873046875\n",
      "\n",
      "Epoch:    2/3     Batch:4950/6968  Loss: 3.653928279876709\n",
      "\n",
      "Epoch:    2/3     Batch:4955/6968  Loss: 3.8540396690368652\n",
      "\n",
      "Epoch:    2/3     Batch:4960/6968  Loss: 3.937170934677124\n",
      "\n",
      "Epoch:    2/3     Batch:4965/6968  Loss: 3.930921268463135\n",
      "\n",
      "Epoch:    2/3     Batch:4970/6968  Loss: 3.758626174926758\n",
      "\n",
      "Epoch:    2/3     Batch:4975/6968  Loss: 3.751812696456909\n",
      "\n",
      "Epoch:    2/3     Batch:4980/6968  Loss: 3.9600820541381836\n",
      "\n",
      "Epoch:    2/3     Batch:4985/6968  Loss: 3.781915521621704\n",
      "\n",
      "Epoch:    2/3     Batch:4990/6968  Loss: 3.8891060829162596\n",
      "\n",
      "Epoch:    2/3     Batch:4995/6968  Loss: 3.4768307209014893\n",
      "\n",
      "Epoch:    2/3     Batch:5000/6968  Loss: 3.6753122329711916\n",
      "\n",
      "Epoch:    2/3     Batch:5005/6968  Loss: 3.860502099990845\n",
      "\n",
      "Epoch:    2/3     Batch:5010/6968  Loss: 4.157723426818848\n",
      "\n",
      "Epoch:    2/3     Batch:5015/6968  Loss: 3.8448861598968507\n",
      "\n",
      "Epoch:    2/3     Batch:5020/6968  Loss: 3.619510126113892\n",
      "\n",
      "Epoch:    2/3     Batch:5025/6968  Loss: 3.5687415599823\n",
      "\n",
      "Epoch:    2/3     Batch:5030/6968  Loss: 3.717589998245239\n",
      "\n",
      "Epoch:    2/3     Batch:5035/6968  Loss: 3.71960654258728\n",
      "\n",
      "Epoch:    2/3     Batch:5040/6968  Loss: 3.8860732078552247\n",
      "\n",
      "Epoch:    2/3     Batch:5045/6968  Loss: 3.9902493953704834\n",
      "\n",
      "Epoch:    2/3     Batch:5050/6968  Loss: 3.7820221900939943\n",
      "\n",
      "Epoch:    2/3     Batch:5055/6968  Loss: 3.7497735977172852\n",
      "\n",
      "Epoch:    2/3     Batch:5060/6968  Loss: 3.756177043914795\n",
      "\n",
      "Epoch:    2/3     Batch:5065/6968  Loss: 3.544881296157837\n",
      "\n",
      "Epoch:    2/3     Batch:5070/6968  Loss: 3.6128429889678957\n",
      "\n",
      "Epoch:    2/3     Batch:5075/6968  Loss: 3.7687217712402346\n",
      "\n",
      "Epoch:    2/3     Batch:5080/6968  Loss: 3.748007345199585\n",
      "\n",
      "Epoch:    2/3     Batch:5085/6968  Loss: 3.806677150726318\n",
      "\n",
      "Epoch:    2/3     Batch:5090/6968  Loss: 3.786609745025635\n",
      "\n",
      "Epoch:    2/3     Batch:5095/6968  Loss: 3.647055149078369\n",
      "\n",
      "Epoch:    2/3     Batch:5100/6968  Loss: 3.839758777618408\n",
      "\n",
      "Epoch:    2/3     Batch:5105/6968  Loss: 3.86921911239624\n",
      "\n",
      "Epoch:    2/3     Batch:5110/6968  Loss: 4.014265298843384\n",
      "\n",
      "Epoch:    2/3     Batch:5115/6968  Loss: 3.871881341934204\n",
      "\n",
      "Epoch:    2/3     Batch:5120/6968  Loss: 3.7089086055755613\n",
      "\n",
      "Epoch:    2/3     Batch:5125/6968  Loss: 3.985237741470337\n",
      "\n",
      "Epoch:    2/3     Batch:5130/6968  Loss: 3.73539342880249\n",
      "\n",
      "Epoch:    2/3     Batch:5135/6968  Loss: 3.956566667556763\n",
      "\n",
      "Epoch:    2/3     Batch:5140/6968  Loss: 3.7530921936035155\n",
      "\n",
      "Epoch:    2/3     Batch:5145/6968  Loss: 3.7524054527282713\n",
      "\n",
      "Epoch:    2/3     Batch:5150/6968  Loss: 3.716826391220093\n",
      "\n",
      "Epoch:    2/3     Batch:5155/6968  Loss: 3.685003471374512\n",
      "\n",
      "Epoch:    2/3     Batch:5160/6968  Loss: 3.690700578689575\n",
      "\n",
      "Epoch:    2/3     Batch:5165/6968  Loss: 3.6956920623779297\n",
      "\n",
      "Epoch:    2/3     Batch:5170/6968  Loss: 3.735127019882202\n",
      "\n",
      "Epoch:    2/3     Batch:5175/6968  Loss: 3.6889935970306396\n",
      "\n",
      "Epoch:    2/3     Batch:5180/6968  Loss: 3.868269348144531\n",
      "\n",
      "Epoch:    2/3     Batch:5185/6968  Loss: 3.7797190666198732\n",
      "\n",
      "Epoch:    2/3     Batch:5190/6968  Loss: 3.8140671253204346\n",
      "\n",
      "Epoch:    2/3     Batch:5195/6968  Loss: 3.535310697555542\n",
      "\n",
      "Epoch:    2/3     Batch:5200/6968  Loss: 3.6718507289886473\n",
      "\n",
      "Epoch:    2/3     Batch:5205/6968  Loss: 3.72452597618103\n",
      "\n",
      "Epoch:    2/3     Batch:5210/6968  Loss: 3.9014747619628904\n",
      "\n",
      "Epoch:    2/3     Batch:5215/6968  Loss: 4.008692073822021\n",
      "\n",
      "Epoch:    2/3     Batch:5220/6968  Loss: 3.77560133934021\n",
      "\n",
      "Epoch:    2/3     Batch:5225/6968  Loss: 3.9034440994262694\n",
      "\n",
      "Epoch:    2/3     Batch:5230/6968  Loss: 3.7044257640838625\n",
      "\n",
      "Epoch:    2/3     Batch:5235/6968  Loss: 3.7279579639434814\n",
      "\n",
      "Epoch:    2/3     Batch:5240/6968  Loss: 3.8710721015930174\n",
      "\n",
      "Epoch:    2/3     Batch:5245/6968  Loss: 3.777504253387451\n",
      "\n",
      "Epoch:    2/3     Batch:5250/6968  Loss: 3.8089990615844727\n",
      "\n",
      "Epoch:    2/3     Batch:5255/6968  Loss: 3.7637922763824463\n",
      "\n",
      "Epoch:    2/3     Batch:5260/6968  Loss: 4.0493714809417725\n",
      "\n",
      "Epoch:    2/3     Batch:5265/6968  Loss: 3.828854513168335\n",
      "\n",
      "Epoch:    2/3     Batch:5270/6968  Loss: 3.7374429225921633\n",
      "\n",
      "Epoch:    2/3     Batch:5275/6968  Loss: 3.701526641845703\n",
      "\n",
      "Epoch:    2/3     Batch:5280/6968  Loss: 3.7734423160552977\n",
      "\n",
      "Epoch:    2/3     Batch:5285/6968  Loss: 3.8559055805206297\n",
      "\n",
      "Epoch:    2/3     Batch:5290/6968  Loss: 3.6839399337768555\n",
      "\n",
      "Epoch:    2/3     Batch:5295/6968  Loss: 4.006041526794434\n",
      "\n",
      "Epoch:    2/3     Batch:5300/6968  Loss: 3.8240095138549806\n",
      "\n",
      "Epoch:    2/3     Batch:5305/6968  Loss: 3.9110809803009032\n",
      "\n",
      "Epoch:    2/3     Batch:5310/6968  Loss: 4.025661993026733\n",
      "\n",
      "Epoch:    2/3     Batch:5315/6968  Loss: 3.9421458721160887\n",
      "\n",
      "Epoch:    2/3     Batch:5320/6968  Loss: 3.813225841522217\n",
      "\n",
      "Epoch:    2/3     Batch:5325/6968  Loss: 3.786539840698242\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    2/3     Batch:5330/6968  Loss: 3.68320255279541\n",
      "\n",
      "Epoch:    2/3     Batch:5335/6968  Loss: 3.8930083751678466\n",
      "\n",
      "Epoch:    2/3     Batch:5340/6968  Loss: 3.7782255172729493\n",
      "\n",
      "Epoch:    2/3     Batch:5345/6968  Loss: 3.900032472610474\n",
      "\n",
      "Epoch:    2/3     Batch:5350/6968  Loss: 3.8756505489349364\n",
      "\n",
      "Epoch:    2/3     Batch:5355/6968  Loss: 3.7825984001159667\n",
      "\n",
      "Epoch:    2/3     Batch:5360/6968  Loss: 3.9927688121795653\n",
      "\n",
      "Epoch:    2/3     Batch:5365/6968  Loss: 3.511931324005127\n",
      "\n",
      "Epoch:    2/3     Batch:5370/6968  Loss: 3.9027687072753907\n",
      "\n",
      "Epoch:    2/3     Batch:5375/6968  Loss: 3.802293300628662\n",
      "\n",
      "Epoch:    2/3     Batch:5380/6968  Loss: 4.010817909240723\n",
      "\n",
      "Epoch:    2/3     Batch:5385/6968  Loss: 3.80305438041687\n",
      "\n",
      "Epoch:    2/3     Batch:5390/6968  Loss: 3.5982384204864504\n",
      "\n",
      "Epoch:    2/3     Batch:5395/6968  Loss: 3.8440289974212645\n",
      "\n",
      "Epoch:    2/3     Batch:5400/6968  Loss: 3.7002503871917725\n",
      "\n",
      "Epoch:    2/3     Batch:5405/6968  Loss: 3.5877443313598634\n",
      "\n",
      "Epoch:    2/3     Batch:5410/6968  Loss: 3.5269056797027587\n",
      "\n",
      "Epoch:    2/3     Batch:5415/6968  Loss: 3.6006008625030517\n",
      "\n",
      "Epoch:    2/3     Batch:5420/6968  Loss: 3.959483003616333\n",
      "\n",
      "Epoch:    2/3     Batch:5425/6968  Loss: 3.940917634963989\n",
      "\n",
      "Epoch:    2/3     Batch:5430/6968  Loss: 3.6797909259796144\n",
      "\n",
      "Epoch:    2/3     Batch:5435/6968  Loss: 3.840840768814087\n",
      "\n",
      "Epoch:    2/3     Batch:5440/6968  Loss: 3.972723388671875\n",
      "\n",
      "Epoch:    2/3     Batch:5445/6968  Loss: 3.8252586841583254\n",
      "\n",
      "Epoch:    2/3     Batch:5450/6968  Loss: 4.004106521606445\n",
      "\n",
      "Epoch:    2/3     Batch:5455/6968  Loss: 3.8812140464782714\n",
      "\n",
      "Epoch:    2/3     Batch:5460/6968  Loss: 3.864964485168457\n",
      "\n",
      "Epoch:    2/3     Batch:5465/6968  Loss: 3.702120542526245\n",
      "\n",
      "Epoch:    2/3     Batch:5470/6968  Loss: 3.797405815124512\n",
      "\n",
      "Epoch:    2/3     Batch:5475/6968  Loss: 3.8005198001861573\n",
      "\n",
      "Epoch:    2/3     Batch:5480/6968  Loss: 3.537800693511963\n",
      "\n",
      "Epoch:    2/3     Batch:5485/6968  Loss: 3.69293794631958\n",
      "\n",
      "Epoch:    2/3     Batch:5490/6968  Loss: 3.9200605869293215\n",
      "\n",
      "Epoch:    2/3     Batch:5495/6968  Loss: 3.8300156116485597\n",
      "\n",
      "Epoch:    2/3     Batch:5500/6968  Loss: 3.8856515884399414\n",
      "\n",
      "Epoch:    2/3     Batch:5505/6968  Loss: 3.8603660583496096\n",
      "\n",
      "Epoch:    2/3     Batch:5510/6968  Loss: 3.844838762283325\n",
      "\n",
      "Epoch:    2/3     Batch:5515/6968  Loss: 3.8498600006103514\n",
      "\n",
      "Epoch:    2/3     Batch:5520/6968  Loss: 3.7076387882232664\n",
      "\n",
      "Epoch:    2/3     Batch:5525/6968  Loss: 3.8281198501586915\n",
      "\n",
      "Epoch:    2/3     Batch:5530/6968  Loss: 3.805523920059204\n",
      "\n",
      "Epoch:    2/3     Batch:5535/6968  Loss: 3.680460786819458\n",
      "\n",
      "Epoch:    2/3     Batch:5540/6968  Loss: 3.527017068862915\n",
      "\n",
      "Epoch:    2/3     Batch:5545/6968  Loss: 3.7990195751190186\n",
      "\n",
      "Epoch:    2/3     Batch:5550/6968  Loss: 3.9687788486480713\n",
      "\n",
      "Epoch:    2/3     Batch:5555/6968  Loss: 3.9166440963745117\n",
      "\n",
      "Epoch:    2/3     Batch:5560/6968  Loss: 3.567858600616455\n",
      "\n",
      "Epoch:    2/3     Batch:5565/6968  Loss: 3.950114679336548\n",
      "\n",
      "Epoch:    2/3     Batch:5570/6968  Loss: 3.81457781791687\n",
      "\n",
      "Epoch:    2/3     Batch:5575/6968  Loss: 3.695238542556763\n",
      "\n",
      "Epoch:    2/3     Batch:5580/6968  Loss: 3.663605546951294\n",
      "\n",
      "Epoch:    2/3     Batch:5585/6968  Loss: 3.816784477233887\n",
      "\n",
      "Epoch:    2/3     Batch:5590/6968  Loss: 3.5286942958831786\n",
      "\n",
      "Epoch:    2/3     Batch:5595/6968  Loss: 3.8376379013061523\n",
      "\n",
      "Epoch:    2/3     Batch:5600/6968  Loss: 3.7535130977630615\n",
      "\n",
      "Epoch:    2/3     Batch:5605/6968  Loss: 3.9835880756378175\n",
      "\n",
      "Epoch:    2/3     Batch:5610/6968  Loss: 3.7697237014770506\n",
      "\n",
      "Epoch:    2/3     Batch:5615/6968  Loss: 3.514635419845581\n",
      "\n",
      "Epoch:    2/3     Batch:5620/6968  Loss: 3.8343801498413086\n",
      "\n",
      "Epoch:    2/3     Batch:5625/6968  Loss: 3.796005201339722\n",
      "\n",
      "Epoch:    2/3     Batch:5630/6968  Loss: 3.745051860809326\n",
      "\n",
      "Epoch:    2/3     Batch:5635/6968  Loss: 3.7380823135375976\n",
      "\n",
      "Epoch:    2/3     Batch:5640/6968  Loss: 3.7181622982025146\n",
      "\n",
      "Epoch:    2/3     Batch:5645/6968  Loss: 3.860401248931885\n",
      "\n",
      "Epoch:    2/3     Batch:5650/6968  Loss: 3.950218391418457\n",
      "\n",
      "Epoch:    2/3     Batch:5655/6968  Loss: 3.596905469894409\n",
      "\n",
      "Epoch:    2/3     Batch:5660/6968  Loss: 3.9102593421936036\n",
      "\n",
      "Epoch:    2/3     Batch:5665/6968  Loss: 3.846509075164795\n",
      "\n",
      "Epoch:    2/3     Batch:5670/6968  Loss: 3.778007984161377\n",
      "\n",
      "Epoch:    2/3     Batch:5675/6968  Loss: 3.6308975219726562\n",
      "\n",
      "Epoch:    2/3     Batch:5680/6968  Loss: 3.819341945648193\n",
      "\n",
      "Epoch:    2/3     Batch:5685/6968  Loss: 3.871180868148804\n",
      "\n",
      "Epoch:    2/3     Batch:5690/6968  Loss: 3.962388515472412\n",
      "\n",
      "Epoch:    2/3     Batch:5695/6968  Loss: 3.706780958175659\n",
      "\n",
      "Epoch:    2/3     Batch:5700/6968  Loss: 3.729506826400757\n",
      "\n",
      "Epoch:    2/3     Batch:5705/6968  Loss: 3.5978854656219483\n",
      "\n",
      "Epoch:    2/3     Batch:5710/6968  Loss: 3.9636510848999023\n",
      "\n",
      "Epoch:    2/3     Batch:5715/6968  Loss: 3.75668888092041\n",
      "\n",
      "Epoch:    2/3     Batch:5720/6968  Loss: 3.8313477993011475\n",
      "\n",
      "Epoch:    2/3     Batch:5725/6968  Loss: 3.92723708152771\n",
      "\n",
      "Epoch:    2/3     Batch:5730/6968  Loss: 3.7259711742401125\n",
      "\n",
      "Epoch:    2/3     Batch:5735/6968  Loss: 3.9683191776275635\n",
      "\n",
      "Epoch:    2/3     Batch:5740/6968  Loss: 3.7435958862304686\n",
      "\n",
      "Epoch:    2/3     Batch:5745/6968  Loss: 3.9316650867462157\n",
      "\n",
      "Epoch:    2/3     Batch:5750/6968  Loss: 3.9196541786193846\n",
      "\n",
      "Epoch:    2/3     Batch:5755/6968  Loss: 3.8822437286376954\n",
      "\n",
      "Epoch:    2/3     Batch:5760/6968  Loss: 4.020914220809937\n",
      "\n",
      "Epoch:    2/3     Batch:5765/6968  Loss: 3.531723642349243\n",
      "\n",
      "Epoch:    2/3     Batch:5770/6968  Loss: 3.6881717681884765\n",
      "\n",
      "Epoch:    2/3     Batch:5775/6968  Loss: 3.7998681545257567\n",
      "\n",
      "Epoch:    2/3     Batch:5780/6968  Loss: 3.5496941089630125\n",
      "\n",
      "Epoch:    2/3     Batch:5785/6968  Loss: 3.682414436340332\n",
      "\n",
      "Epoch:    2/3     Batch:5790/6968  Loss: 3.6519689083099367\n",
      "\n",
      "Epoch:    2/3     Batch:5795/6968  Loss: 3.7243484973907472\n",
      "\n",
      "Epoch:    2/3     Batch:5800/6968  Loss: 3.930482006072998\n",
      "\n",
      "Epoch:    2/3     Batch:5805/6968  Loss: 3.905490493774414\n",
      "\n",
      "Epoch:    2/3     Batch:5810/6968  Loss: 3.7858598709106444\n",
      "\n",
      "Epoch:    2/3     Batch:5815/6968  Loss: 3.804247283935547\n",
      "\n",
      "Epoch:    2/3     Batch:5820/6968  Loss: 3.8736939907073973\n",
      "\n",
      "Epoch:    2/3     Batch:5825/6968  Loss: 3.7672388553619385\n",
      "\n",
      "Epoch:    2/3     Batch:5830/6968  Loss: 3.7590107917785645\n",
      "\n",
      "Epoch:    2/3     Batch:5835/6968  Loss: 3.7047331809997557\n",
      "\n",
      "Epoch:    2/3     Batch:5840/6968  Loss: 3.6796552658081056\n",
      "\n",
      "Epoch:    2/3     Batch:5845/6968  Loss: 4.148186492919922\n",
      "\n",
      "Epoch:    2/3     Batch:5850/6968  Loss: 3.6819260120391846\n",
      "\n",
      "Epoch:    2/3     Batch:5855/6968  Loss: 4.028375148773193\n",
      "\n",
      "Epoch:    2/3     Batch:5860/6968  Loss: 3.741037940979004\n",
      "\n",
      "Epoch:    2/3     Batch:5865/6968  Loss: 3.8345877170562743\n",
      "\n",
      "Epoch:    2/3     Batch:5870/6968  Loss: 3.724333381652832\n",
      "\n",
      "Epoch:    2/3     Batch:5875/6968  Loss: 3.943711996078491\n",
      "\n",
      "Epoch:    2/3     Batch:5880/6968  Loss: 3.722988748550415\n",
      "\n",
      "Epoch:    2/3     Batch:5885/6968  Loss: 3.5643782138824465\n",
      "\n",
      "Epoch:    2/3     Batch:5890/6968  Loss: 3.9198320865631104\n",
      "\n",
      "Epoch:    2/3     Batch:5895/6968  Loss: 3.8803576469421386\n",
      "\n",
      "Epoch:    2/3     Batch:5900/6968  Loss: 3.8245989799499513\n",
      "\n",
      "Epoch:    2/3     Batch:5905/6968  Loss: 3.8050004482269286\n",
      "\n",
      "Epoch:    2/3     Batch:5910/6968  Loss: 3.7049973011016846\n",
      "\n",
      "Epoch:    2/3     Batch:5915/6968  Loss: 3.7317565441131593\n",
      "\n",
      "Epoch:    2/3     Batch:5920/6968  Loss: 3.69374361038208\n",
      "\n",
      "Epoch:    2/3     Batch:5925/6968  Loss: 3.6830416679382325\n",
      "\n",
      "Epoch:    2/3     Batch:5930/6968  Loss: 3.675428104400635\n",
      "\n",
      "Epoch:    2/3     Batch:5935/6968  Loss: 3.8075681209564207\n",
      "\n",
      "Epoch:    2/3     Batch:5940/6968  Loss: 3.7619019031524656\n",
      "\n",
      "Epoch:    2/3     Batch:5945/6968  Loss: 3.702407646179199\n",
      "\n",
      "Epoch:    2/3     Batch:5950/6968  Loss: 4.06443223953247\n",
      "\n",
      "Epoch:    2/3     Batch:5955/6968  Loss: 3.694730520248413\n",
      "\n",
      "Epoch:    2/3     Batch:5960/6968  Loss: 3.7416991233825683\n",
      "\n",
      "Epoch:    2/3     Batch:5965/6968  Loss: 3.960767459869385\n",
      "\n",
      "Epoch:    2/3     Batch:5970/6968  Loss: 4.009275817871094\n",
      "\n",
      "Epoch:    2/3     Batch:5975/6968  Loss: 3.5832213401794433\n",
      "\n",
      "Epoch:    2/3     Batch:5980/6968  Loss: 3.8709181785583495\n",
      "\n",
      "Epoch:    2/3     Batch:5985/6968  Loss: 3.63589186668396\n",
      "\n",
      "Epoch:    2/3     Batch:5990/6968  Loss: 3.760638475418091\n",
      "\n",
      "Epoch:    2/3     Batch:5995/6968  Loss: 3.6152361392974854\n",
      "\n",
      "Epoch:    2/3     Batch:6000/6968  Loss: 3.848209285736084\n",
      "\n",
      "Epoch:    2/3     Batch:6005/6968  Loss: 3.8279114723205567\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    2/3     Batch:6010/6968  Loss: 3.6278922080993654\n",
      "\n",
      "Epoch:    2/3     Batch:6015/6968  Loss: 4.014967441558838\n",
      "\n",
      "Epoch:    2/3     Batch:6020/6968  Loss: 3.733966112136841\n",
      "\n",
      "Epoch:    2/3     Batch:6025/6968  Loss: 3.9373778820037844\n",
      "\n",
      "Epoch:    2/3     Batch:6030/6968  Loss: 3.761404514312744\n",
      "\n",
      "Epoch:    2/3     Batch:6035/6968  Loss: 3.9901735305786135\n",
      "\n",
      "Epoch:    2/3     Batch:6040/6968  Loss: 3.6298941135406495\n",
      "\n",
      "Epoch:    2/3     Batch:6045/6968  Loss: 3.5523863792419434\n",
      "\n",
      "Epoch:    2/3     Batch:6050/6968  Loss: 3.70329909324646\n",
      "\n",
      "Epoch:    2/3     Batch:6055/6968  Loss: 3.6428714275360106\n",
      "\n",
      "Epoch:    2/3     Batch:6060/6968  Loss: 3.8667835712432863\n",
      "\n",
      "Epoch:    2/3     Batch:6065/6968  Loss: 3.6544984340667725\n",
      "\n",
      "Epoch:    2/3     Batch:6070/6968  Loss: 3.7299103260040285\n",
      "\n",
      "Epoch:    2/3     Batch:6075/6968  Loss: 3.5699492931365966\n",
      "\n",
      "Epoch:    2/3     Batch:6080/6968  Loss: 3.7758718013763426\n",
      "\n",
      "Epoch:    2/3     Batch:6085/6968  Loss: 3.976449489593506\n",
      "\n",
      "Epoch:    2/3     Batch:6090/6968  Loss: 3.8055620193481445\n",
      "\n",
      "Epoch:    2/3     Batch:6095/6968  Loss: 3.6148557662963867\n",
      "\n",
      "Epoch:    2/3     Batch:6100/6968  Loss: 3.8608991146087646\n",
      "\n",
      "Epoch:    2/3     Batch:6105/6968  Loss: 3.616529083251953\n",
      "\n",
      "Epoch:    2/3     Batch:6110/6968  Loss: 3.7277751922607423\n",
      "\n",
      "Epoch:    2/3     Batch:6115/6968  Loss: 3.7369155406951906\n",
      "\n",
      "Epoch:    2/3     Batch:6120/6968  Loss: 3.812205171585083\n",
      "\n",
      "Epoch:    2/3     Batch:6125/6968  Loss: 3.8298744678497316\n",
      "\n",
      "Epoch:    2/3     Batch:6130/6968  Loss: 3.567494535446167\n",
      "\n",
      "Epoch:    2/3     Batch:6135/6968  Loss: 3.661056661605835\n",
      "\n",
      "Epoch:    2/3     Batch:6140/6968  Loss: 3.8985729217529297\n",
      "\n",
      "Epoch:    2/3     Batch:6145/6968  Loss: 3.6672897338867188\n",
      "\n",
      "Epoch:    2/3     Batch:6150/6968  Loss: 3.7416802883148192\n",
      "\n",
      "Epoch:    2/3     Batch:6155/6968  Loss: 3.7821882724761964\n",
      "\n",
      "Epoch:    2/3     Batch:6160/6968  Loss: 3.878731060028076\n",
      "\n",
      "Epoch:    2/3     Batch:6165/6968  Loss: 3.6893060207366943\n",
      "\n",
      "Epoch:    2/3     Batch:6170/6968  Loss: 3.779603385925293\n",
      "\n",
      "Epoch:    2/3     Batch:6175/6968  Loss: 3.813228797912598\n",
      "\n",
      "Epoch:    2/3     Batch:6180/6968  Loss: 3.537567472457886\n",
      "\n",
      "Epoch:    2/3     Batch:6185/6968  Loss: 3.750779628753662\n",
      "\n",
      "Epoch:    2/3     Batch:6190/6968  Loss: 3.6727201461791994\n",
      "\n",
      "Epoch:    2/3     Batch:6195/6968  Loss: 3.9579509258270265\n",
      "\n",
      "Epoch:    2/3     Batch:6200/6968  Loss: 3.9105717658996584\n",
      "\n",
      "Epoch:    2/3     Batch:6205/6968  Loss: 3.63733491897583\n",
      "\n",
      "Epoch:    2/3     Batch:6210/6968  Loss: 3.738428544998169\n",
      "\n",
      "Epoch:    2/3     Batch:6215/6968  Loss: 3.5593494892120363\n",
      "\n",
      "Epoch:    2/3     Batch:6220/6968  Loss: 3.652137279510498\n",
      "\n",
      "Epoch:    2/3     Batch:6225/6968  Loss: 3.6912729263305666\n",
      "\n",
      "Epoch:    2/3     Batch:6230/6968  Loss: 3.8394750118255616\n",
      "\n",
      "Epoch:    2/3     Batch:6235/6968  Loss: 3.5813997268676756\n",
      "\n",
      "Epoch:    2/3     Batch:6240/6968  Loss: 3.868043231964111\n",
      "\n",
      "Epoch:    2/3     Batch:6245/6968  Loss: 3.8961409091949464\n",
      "\n",
      "Epoch:    2/3     Batch:6250/6968  Loss: 3.9639179706573486\n",
      "\n",
      "Epoch:    2/3     Batch:6255/6968  Loss: 4.032614612579346\n",
      "\n",
      "Epoch:    2/3     Batch:6260/6968  Loss: 3.651796340942383\n",
      "\n",
      "Epoch:    2/3     Batch:6265/6968  Loss: 3.8172940731048586\n",
      "\n",
      "Epoch:    2/3     Batch:6270/6968  Loss: 3.648298406600952\n",
      "\n",
      "Epoch:    2/3     Batch:6275/6968  Loss: 3.799195098876953\n",
      "\n",
      "Epoch:    2/3     Batch:6280/6968  Loss: 3.592885065078735\n",
      "\n",
      "Epoch:    2/3     Batch:6285/6968  Loss: 3.9089008808135985\n",
      "\n",
      "Epoch:    2/3     Batch:6290/6968  Loss: 3.7652563095092773\n",
      "\n",
      "Epoch:    2/3     Batch:6295/6968  Loss: 3.8363876819610594\n",
      "\n",
      "Epoch:    2/3     Batch:6300/6968  Loss: 3.69888014793396\n",
      "\n",
      "Epoch:    2/3     Batch:6305/6968  Loss: 3.916761112213135\n",
      "\n",
      "Epoch:    2/3     Batch:6310/6968  Loss: 3.869602823257446\n",
      "\n",
      "Epoch:    2/3     Batch:6315/6968  Loss: 3.944055700302124\n",
      "\n",
      "Epoch:    2/3     Batch:6320/6968  Loss: 3.8664872646331787\n",
      "\n",
      "Epoch:    2/3     Batch:6325/6968  Loss: 3.691211986541748\n",
      "\n",
      "Epoch:    2/3     Batch:6330/6968  Loss: 3.546167087554932\n",
      "\n",
      "Epoch:    2/3     Batch:6335/6968  Loss: 4.066275596618652\n",
      "\n",
      "Epoch:    2/3     Batch:6340/6968  Loss: 3.7330461978912353\n",
      "\n",
      "Epoch:    2/3     Batch:6345/6968  Loss: 3.5858615398406983\n",
      "\n",
      "Epoch:    2/3     Batch:6350/6968  Loss: 3.781831407546997\n",
      "\n",
      "Epoch:    2/3     Batch:6355/6968  Loss: 3.6970726013183595\n",
      "\n",
      "Epoch:    2/3     Batch:6360/6968  Loss: 3.7835633754730225\n",
      "\n",
      "Epoch:    2/3     Batch:6365/6968  Loss: 3.7317237854003906\n",
      "\n",
      "Epoch:    2/3     Batch:6370/6968  Loss: 3.927298069000244\n",
      "\n",
      "Epoch:    2/3     Batch:6375/6968  Loss: 3.7883073329925536\n",
      "\n",
      "Epoch:    2/3     Batch:6380/6968  Loss: 3.7518592357635496\n",
      "\n",
      "Epoch:    2/3     Batch:6385/6968  Loss: 3.7211266040802\n",
      "\n",
      "Epoch:    2/3     Batch:6390/6968  Loss: 3.7538405895233153\n",
      "\n",
      "Epoch:    2/3     Batch:6395/6968  Loss: 3.611737871170044\n",
      "\n",
      "Epoch:    2/3     Batch:6400/6968  Loss: 3.7383306503295897\n",
      "\n",
      "Epoch:    2/3     Batch:6405/6968  Loss: 3.6913058280944826\n",
      "\n",
      "Epoch:    2/3     Batch:6410/6968  Loss: 3.7620886325836183\n",
      "\n",
      "Epoch:    2/3     Batch:6415/6968  Loss: 3.7485207080841065\n",
      "\n",
      "Epoch:    2/3     Batch:6420/6968  Loss: 3.650413751602173\n",
      "\n",
      "Epoch:    2/3     Batch:6425/6968  Loss: 3.767499876022339\n",
      "\n",
      "Epoch:    2/3     Batch:6430/6968  Loss: 3.867537832260132\n",
      "\n",
      "Epoch:    2/3     Batch:6435/6968  Loss: 3.746376657485962\n",
      "\n",
      "Epoch:    2/3     Batch:6440/6968  Loss: 3.7995378971099854\n",
      "\n",
      "Epoch:    2/3     Batch:6445/6968  Loss: 3.7675484657287597\n",
      "\n",
      "Epoch:    2/3     Batch:6450/6968  Loss: 3.700354051589966\n",
      "\n",
      "Epoch:    2/3     Batch:6455/6968  Loss: 3.926440715789795\n",
      "\n",
      "Epoch:    2/3     Batch:6460/6968  Loss: 4.009967899322509\n",
      "\n",
      "Epoch:    2/3     Batch:6465/6968  Loss: 3.7422088623046874\n",
      "\n",
      "Epoch:    2/3     Batch:6470/6968  Loss: 3.6487988471984862\n",
      "\n",
      "Epoch:    2/3     Batch:6475/6968  Loss: 3.6700655937194826\n",
      "\n",
      "Epoch:    2/3     Batch:6480/6968  Loss: 3.9412786960601807\n",
      "\n",
      "Epoch:    2/3     Batch:6485/6968  Loss: 3.6841495990753175\n",
      "\n",
      "Epoch:    2/3     Batch:6490/6968  Loss: 3.758524751663208\n",
      "\n",
      "Epoch:    2/3     Batch:6495/6968  Loss: 3.8079421520233154\n",
      "\n",
      "Epoch:    2/3     Batch:6500/6968  Loss: 3.8114938735961914\n",
      "\n",
      "Epoch:    2/3     Batch:6505/6968  Loss: 3.7556233406066895\n",
      "\n",
      "Epoch:    2/3     Batch:6510/6968  Loss: 3.730550765991211\n",
      "\n",
      "Epoch:    2/3     Batch:6515/6968  Loss: 3.634989070892334\n",
      "\n",
      "Epoch:    2/3     Batch:6520/6968  Loss: 3.8244009971618653\n",
      "\n",
      "Epoch:    2/3     Batch:6525/6968  Loss: 3.961148262023926\n",
      "\n",
      "Epoch:    2/3     Batch:6530/6968  Loss: 4.022764062881469\n",
      "\n",
      "Epoch:    2/3     Batch:6535/6968  Loss: 3.8826576232910157\n",
      "\n",
      "Epoch:    2/3     Batch:6540/6968  Loss: 3.865569496154785\n",
      "\n",
      "Epoch:    2/3     Batch:6545/6968  Loss: 3.8589718341827393\n",
      "\n",
      "Epoch:    2/3     Batch:6550/6968  Loss: 3.8211535453796386\n",
      "\n",
      "Epoch:    2/3     Batch:6555/6968  Loss: 3.8295716285705566\n",
      "\n",
      "Epoch:    2/3     Batch:6560/6968  Loss: 3.795553112030029\n",
      "\n",
      "Epoch:    2/3     Batch:6565/6968  Loss: 3.4805044651031496\n",
      "\n",
      "Epoch:    2/3     Batch:6570/6968  Loss: 3.8704670906066894\n",
      "\n",
      "Epoch:    2/3     Batch:6575/6968  Loss: 3.7334307193756104\n",
      "\n",
      "Epoch:    2/3     Batch:6580/6968  Loss: 3.825508165359497\n",
      "\n",
      "Epoch:    2/3     Batch:6585/6968  Loss: 3.6479750156402586\n",
      "\n",
      "Epoch:    2/3     Batch:6590/6968  Loss: 3.8868908882141113\n",
      "\n",
      "Epoch:    2/3     Batch:6595/6968  Loss: 3.695976209640503\n",
      "\n",
      "Epoch:    2/3     Batch:6600/6968  Loss: 3.758809804916382\n",
      "\n",
      "Epoch:    2/3     Batch:6605/6968  Loss: 3.8041239261627195\n",
      "\n",
      "Epoch:    2/3     Batch:6610/6968  Loss: 3.574992609024048\n",
      "\n",
      "Epoch:    2/3     Batch:6615/6968  Loss: 3.6163626670837403\n",
      "\n",
      "Epoch:    2/3     Batch:6620/6968  Loss: 3.7435518741607665\n",
      "\n",
      "Epoch:    2/3     Batch:6625/6968  Loss: 3.768134117126465\n",
      "\n",
      "Epoch:    2/3     Batch:6630/6968  Loss: 3.5850710391998293\n",
      "\n",
      "Epoch:    2/3     Batch:6635/6968  Loss: 3.646034812927246\n",
      "\n",
      "Epoch:    2/3     Batch:6640/6968  Loss: 3.768400716781616\n",
      "\n",
      "Epoch:    2/3     Batch:6645/6968  Loss: 3.796685266494751\n",
      "\n",
      "Epoch:    2/3     Batch:6650/6968  Loss: 3.771783542633057\n",
      "\n",
      "Epoch:    2/3     Batch:6655/6968  Loss: 3.901655387878418\n",
      "\n",
      "Epoch:    2/3     Batch:6660/6968  Loss: 3.931461238861084\n",
      "\n",
      "Epoch:    2/3     Batch:6665/6968  Loss: 3.720384359359741\n",
      "\n",
      "Epoch:    2/3     Batch:6670/6968  Loss: 3.8112346649169924\n",
      "\n",
      "Epoch:    2/3     Batch:6675/6968  Loss: 3.6691885948181153\n",
      "\n",
      "Epoch:    2/3     Batch:6680/6968  Loss: 3.8434768199920653\n",
      "\n",
      "Epoch:    2/3     Batch:6685/6968  Loss: 3.6865410804748535\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    2/3     Batch:6690/6968  Loss: 3.879372262954712\n",
      "\n",
      "Epoch:    2/3     Batch:6695/6968  Loss: 3.6817486763000487\n",
      "\n",
      "Epoch:    2/3     Batch:6700/6968  Loss: 4.009530019760132\n",
      "\n",
      "Epoch:    2/3     Batch:6705/6968  Loss: 3.708557891845703\n",
      "\n",
      "Epoch:    2/3     Batch:6710/6968  Loss: 3.997045660018921\n",
      "\n",
      "Epoch:    2/3     Batch:6715/6968  Loss: 3.9972421646118166\n",
      "\n",
      "Epoch:    2/3     Batch:6720/6968  Loss: 3.8048273086547852\n",
      "\n",
      "Epoch:    2/3     Batch:6725/6968  Loss: 3.677508735656738\n",
      "\n",
      "Epoch:    2/3     Batch:6730/6968  Loss: 3.6277017116546633\n",
      "\n",
      "Epoch:    2/3     Batch:6735/6968  Loss: 3.896971035003662\n",
      "\n",
      "Epoch:    2/3     Batch:6740/6968  Loss: 3.6659164905548094\n",
      "\n",
      "Epoch:    2/3     Batch:6745/6968  Loss: 3.8291818618774416\n",
      "\n",
      "Epoch:    2/3     Batch:6750/6968  Loss: 3.8095068454742433\n",
      "\n",
      "Epoch:    2/3     Batch:6755/6968  Loss: 3.876169443130493\n",
      "\n",
      "Epoch:    2/3     Batch:6760/6968  Loss: 3.591035270690918\n",
      "\n",
      "Epoch:    2/3     Batch:6765/6968  Loss: 3.743227815628052\n",
      "\n",
      "Epoch:    2/3     Batch:6770/6968  Loss: 3.6921011447906493\n",
      "\n",
      "Epoch:    2/3     Batch:6775/6968  Loss: 3.692604684829712\n",
      "\n",
      "Epoch:    2/3     Batch:6780/6968  Loss: 3.8129337787628175\n",
      "\n",
      "Epoch:    2/3     Batch:6785/6968  Loss: 3.873627281188965\n",
      "\n",
      "Epoch:    2/3     Batch:6790/6968  Loss: 3.695583391189575\n",
      "\n",
      "Epoch:    2/3     Batch:6795/6968  Loss: 3.6072182178497316\n",
      "\n",
      "Epoch:    2/3     Batch:6800/6968  Loss: 3.874393367767334\n",
      "\n",
      "Epoch:    2/3     Batch:6805/6968  Loss: 3.68955512046814\n",
      "\n",
      "Epoch:    2/3     Batch:6810/6968  Loss: 3.629424238204956\n",
      "\n",
      "Epoch:    2/3     Batch:6815/6968  Loss: 3.645617151260376\n",
      "\n",
      "Epoch:    2/3     Batch:6820/6968  Loss: 3.725057077407837\n",
      "\n",
      "Epoch:    2/3     Batch:6825/6968  Loss: 3.568912220001221\n",
      "\n",
      "Epoch:    2/3     Batch:6830/6968  Loss: 3.7161574840545653\n",
      "\n",
      "Epoch:    2/3     Batch:6835/6968  Loss: 3.9002062320709228\n",
      "\n",
      "Epoch:    2/3     Batch:6840/6968  Loss: 3.8337443351745604\n",
      "\n",
      "Epoch:    2/3     Batch:6845/6968  Loss: 3.807475471496582\n",
      "\n",
      "Epoch:    2/3     Batch:6850/6968  Loss: 3.9182435512542724\n",
      "\n",
      "Epoch:    2/3     Batch:6855/6968  Loss: 3.7759806632995607\n",
      "\n",
      "Epoch:    2/3     Batch:6860/6968  Loss: 3.6221845626831053\n",
      "\n",
      "Epoch:    2/3     Batch:6865/6968  Loss: 4.03461709022522\n",
      "\n",
      "Epoch:    2/3     Batch:6870/6968  Loss: 3.800092887878418\n",
      "\n",
      "Epoch:    2/3     Batch:6875/6968  Loss: 3.7545970916748046\n",
      "\n",
      "Epoch:    2/3     Batch:6880/6968  Loss: 3.8535961627960207\n",
      "\n",
      "Epoch:    2/3     Batch:6885/6968  Loss: 3.6163867950439452\n",
      "\n",
      "Epoch:    2/3     Batch:6890/6968  Loss: 3.8296167850494385\n",
      "\n",
      "Epoch:    2/3     Batch:6895/6968  Loss: 3.737715148925781\n",
      "\n",
      "Epoch:    2/3     Batch:6900/6968  Loss: 3.899084281921387\n",
      "\n",
      "Epoch:    2/3     Batch:6905/6968  Loss: 3.9330979347229005\n",
      "\n",
      "Epoch:    2/3     Batch:6910/6968  Loss: 3.6625740051269533\n",
      "\n",
      "Epoch:    2/3     Batch:6915/6968  Loss: 3.818955135345459\n",
      "\n",
      "Epoch:    2/3     Batch:6920/6968  Loss: 3.7592360973358154\n",
      "\n",
      "Epoch:    2/3     Batch:6925/6968  Loss: 3.94740571975708\n",
      "\n",
      "Epoch:    2/3     Batch:6930/6968  Loss: 3.9202566146850586\n",
      "\n",
      "Epoch:    2/3     Batch:6935/6968  Loss: 3.9123544692993164\n",
      "\n",
      "Epoch:    2/3     Batch:6940/6968  Loss: 3.709820032119751\n",
      "\n",
      "Epoch:    2/3     Batch:6945/6968  Loss: 4.042907619476319\n",
      "\n",
      "Epoch:    2/3     Batch:6950/6968  Loss: 3.7675751209259034\n",
      "\n",
      "Epoch:    2/3     Batch:6955/6968  Loss: 4.0081139087677\n",
      "\n",
      "Epoch:    2/3     Batch:6960/6968  Loss: 3.498247814178467\n",
      "\n",
      "Epoch:    2/3     Batch:6965/6968  Loss: 3.8692666053771974\n",
      "\n",
      "Epoch:    3/3     Batch:   5/6968  Loss: 3.74532413482666\n",
      "\n",
      "Epoch:    3/3     Batch:  10/6968  Loss: 3.506707048416138\n",
      "\n",
      "Epoch:    3/3     Batch:  15/6968  Loss: 3.4739593505859374\n",
      "\n",
      "Epoch:    3/3     Batch:  20/6968  Loss: 3.737801027297974\n",
      "\n",
      "Epoch:    3/3     Batch:  25/6968  Loss: 3.5303303718566896\n",
      "\n",
      "Epoch:    3/3     Batch:  30/6968  Loss: 3.5122796058654786\n",
      "\n",
      "Epoch:    3/3     Batch:  35/6968  Loss: 3.6543426513671875\n",
      "\n",
      "Epoch:    3/3     Batch:  40/6968  Loss: 3.4921521186828612\n",
      "\n",
      "Epoch:    3/3     Batch:  45/6968  Loss: 3.616956186294556\n",
      "\n",
      "Epoch:    3/3     Batch:  50/6968  Loss: 3.5751731395721436\n",
      "\n",
      "Epoch:    3/3     Batch:  55/6968  Loss: 3.576810884475708\n",
      "\n",
      "Epoch:    3/3     Batch:  60/6968  Loss: 3.643922138214111\n",
      "\n",
      "Epoch:    3/3     Batch:  65/6968  Loss: 3.534649133682251\n",
      "\n",
      "Epoch:    3/3     Batch:  70/6968  Loss: 3.65991792678833\n",
      "\n",
      "Epoch:    3/3     Batch:  75/6968  Loss: 3.6323529720306396\n",
      "\n",
      "Epoch:    3/3     Batch:  80/6968  Loss: 3.397623300552368\n",
      "\n",
      "Epoch:    3/3     Batch:  85/6968  Loss: 3.390326166152954\n",
      "\n",
      "Epoch:    3/3     Batch:  90/6968  Loss: 3.553705406188965\n",
      "\n",
      "Epoch:    3/3     Batch:  95/6968  Loss: 3.591114044189453\n",
      "\n",
      "Epoch:    3/3     Batch: 100/6968  Loss: 3.667836618423462\n",
      "\n",
      "Epoch:    3/3     Batch: 105/6968  Loss: 3.482713460922241\n",
      "\n",
      "Epoch:    3/3     Batch: 110/6968  Loss: 3.881641912460327\n",
      "\n",
      "Epoch:    3/3     Batch: 115/6968  Loss: 3.478510046005249\n",
      "\n",
      "Epoch:    3/3     Batch: 120/6968  Loss: 3.645093870162964\n",
      "\n",
      "Epoch:    3/3     Batch: 125/6968  Loss: 3.623690462112427\n",
      "\n",
      "Epoch:    3/3     Batch: 130/6968  Loss: 3.6146166801452635\n",
      "\n",
      "Epoch:    3/3     Batch: 135/6968  Loss: 3.778203821182251\n",
      "\n",
      "Epoch:    3/3     Batch: 140/6968  Loss: 3.4826337337493896\n",
      "\n",
      "Epoch:    3/3     Batch: 145/6968  Loss: 3.51853985786438\n",
      "\n",
      "Epoch:    3/3     Batch: 150/6968  Loss: 3.718672752380371\n",
      "\n",
      "Epoch:    3/3     Batch: 155/6968  Loss: 3.6434960842132567\n",
      "\n",
      "Epoch:    3/3     Batch: 160/6968  Loss: 3.735189342498779\n",
      "\n",
      "Epoch:    3/3     Batch: 165/6968  Loss: 3.739183712005615\n",
      "\n",
      "Epoch:    3/3     Batch: 170/6968  Loss: 3.6352636337280275\n",
      "\n",
      "Epoch:    3/3     Batch: 175/6968  Loss: 3.5508423328399656\n",
      "\n",
      "Epoch:    3/3     Batch: 180/6968  Loss: 3.491068124771118\n",
      "\n",
      "Epoch:    3/3     Batch: 185/6968  Loss: 3.634555721282959\n",
      "\n",
      "Epoch:    3/3     Batch: 190/6968  Loss: 3.484794092178345\n",
      "\n",
      "Epoch:    3/3     Batch: 195/6968  Loss: 3.5365655422210693\n",
      "\n",
      "Epoch:    3/3     Batch: 200/6968  Loss: 3.442864179611206\n",
      "\n",
      "Epoch:    3/3     Batch: 205/6968  Loss: 3.6008103847503663\n",
      "\n",
      "Epoch:    3/3     Batch: 210/6968  Loss: 3.5983438014984133\n",
      "\n",
      "Epoch:    3/3     Batch: 215/6968  Loss: 3.46445894241333\n",
      "\n",
      "Epoch:    3/3     Batch: 220/6968  Loss: 3.5155694007873537\n",
      "\n",
      "Epoch:    3/3     Batch: 225/6968  Loss: 3.75209379196167\n",
      "\n",
      "Epoch:    3/3     Batch: 230/6968  Loss: 3.5225564002990724\n",
      "\n",
      "Epoch:    3/3     Batch: 235/6968  Loss: 3.532099390029907\n",
      "\n",
      "Epoch:    3/3     Batch: 240/6968  Loss: 3.630946493148804\n",
      "\n",
      "Epoch:    3/3     Batch: 245/6968  Loss: 3.598681592941284\n",
      "\n",
      "Epoch:    3/3     Batch: 250/6968  Loss: 3.4493127822875977\n",
      "\n",
      "Epoch:    3/3     Batch: 255/6968  Loss: 3.3562123775482178\n",
      "\n",
      "Epoch:    3/3     Batch: 260/6968  Loss: 3.5768386840820314\n",
      "\n",
      "Epoch:    3/3     Batch: 265/6968  Loss: 3.493946599960327\n",
      "\n",
      "Epoch:    3/3     Batch: 270/6968  Loss: 3.5321750164031984\n",
      "\n",
      "Epoch:    3/3     Batch: 275/6968  Loss: 3.3895614624023436\n",
      "\n",
      "Epoch:    3/3     Batch: 280/6968  Loss: 3.4636843681335447\n",
      "\n",
      "Epoch:    3/3     Batch: 285/6968  Loss: 3.423673677444458\n",
      "\n",
      "Epoch:    3/3     Batch: 290/6968  Loss: 3.510104703903198\n",
      "\n",
      "Epoch:    3/3     Batch: 295/6968  Loss: 3.3528778076171877\n",
      "\n",
      "Epoch:    3/3     Batch: 300/6968  Loss: 3.4922300815582275\n",
      "\n",
      "Epoch:    3/3     Batch: 305/6968  Loss: 3.565320539474487\n",
      "\n",
      "Epoch:    3/3     Batch: 310/6968  Loss: 3.6864203929901125\n",
      "\n",
      "Epoch:    3/3     Batch: 315/6968  Loss: 3.586622190475464\n",
      "\n",
      "Epoch:    3/3     Batch: 320/6968  Loss: 3.8149410247802735\n",
      "\n",
      "Epoch:    3/3     Batch: 325/6968  Loss: 3.5931532859802244\n",
      "\n",
      "Epoch:    3/3     Batch: 330/6968  Loss: 3.398590612411499\n",
      "\n",
      "Epoch:    3/3     Batch: 335/6968  Loss: 3.8307938098907472\n",
      "\n",
      "Epoch:    3/3     Batch: 340/6968  Loss: 3.42021803855896\n",
      "\n",
      "Epoch:    3/3     Batch: 345/6968  Loss: 3.511857748031616\n",
      "\n",
      "Epoch:    3/3     Batch: 350/6968  Loss: 3.725905704498291\n",
      "\n",
      "Epoch:    3/3     Batch: 355/6968  Loss: 3.705960416793823\n",
      "\n",
      "Epoch:    3/3     Batch: 360/6968  Loss: 3.6088601112365724\n",
      "\n",
      "Epoch:    3/3     Batch: 365/6968  Loss: 3.6014490604400633\n",
      "\n",
      "Epoch:    3/3     Batch: 370/6968  Loss: 3.390352725982666\n",
      "\n",
      "Epoch:    3/3     Batch: 375/6968  Loss: 3.4251763820648193\n",
      "\n",
      "Epoch:    3/3     Batch: 380/6968  Loss: 3.470739555358887\n",
      "\n",
      "Epoch:    3/3     Batch: 385/6968  Loss: 3.6205021858215334\n",
      "\n",
      "Epoch:    3/3     Batch: 390/6968  Loss: 3.4976595401763917\n",
      "\n",
      "Epoch:    3/3     Batch: 395/6968  Loss: 3.6107216835021974\n",
      "\n",
      "Epoch:    3/3     Batch: 400/6968  Loss: 3.362589168548584\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    3/3     Batch: 405/6968  Loss: 3.4857606410980226\n",
      "\n",
      "Epoch:    3/3     Batch: 410/6968  Loss: 3.483559799194336\n",
      "\n",
      "Epoch:    3/3     Batch: 415/6968  Loss: 3.4021045207977294\n",
      "\n",
      "Epoch:    3/3     Batch: 420/6968  Loss: 3.574001693725586\n",
      "\n",
      "Epoch:    3/3     Batch: 425/6968  Loss: 3.499673271179199\n",
      "\n",
      "Epoch:    3/3     Batch: 430/6968  Loss: 3.60718994140625\n",
      "\n",
      "Epoch:    3/3     Batch: 435/6968  Loss: 3.623507595062256\n",
      "\n",
      "Epoch:    3/3     Batch: 440/6968  Loss: 3.306043529510498\n",
      "\n",
      "Epoch:    3/3     Batch: 445/6968  Loss: 3.6270862102508543\n",
      "\n",
      "Epoch:    3/3     Batch: 450/6968  Loss: 3.4511202335357667\n",
      "\n",
      "Epoch:    3/3     Batch: 455/6968  Loss: 3.529038667678833\n",
      "\n",
      "Epoch:    3/3     Batch: 460/6968  Loss: 3.6599810123443604\n",
      "\n",
      "Epoch:    3/3     Batch: 465/6968  Loss: 3.7152843952178953\n",
      "\n",
      "Epoch:    3/3     Batch: 470/6968  Loss: 3.3022836685180663\n",
      "\n",
      "Epoch:    3/3     Batch: 475/6968  Loss: 3.4970457553863525\n",
      "\n",
      "Epoch:    3/3     Batch: 480/6968  Loss: 3.2659651756286623\n",
      "\n",
      "Epoch:    3/3     Batch: 485/6968  Loss: 3.404490041732788\n",
      "\n",
      "Epoch:    3/3     Batch: 490/6968  Loss: 3.617421102523804\n",
      "\n",
      "Epoch:    3/3     Batch: 495/6968  Loss: 3.6123838901519774\n",
      "\n",
      "Epoch:    3/3     Batch: 500/6968  Loss: 3.5362692356109617\n",
      "\n",
      "Epoch:    3/3     Batch: 505/6968  Loss: 3.7524295330047606\n",
      "\n",
      "Epoch:    3/3     Batch: 510/6968  Loss: 3.780023431777954\n",
      "\n",
      "Epoch:    3/3     Batch: 515/6968  Loss: 3.668222665786743\n",
      "\n",
      "Epoch:    3/3     Batch: 520/6968  Loss: 3.6041738986968994\n",
      "\n",
      "Epoch:    3/3     Batch: 525/6968  Loss: 3.510259199142456\n",
      "\n",
      "Epoch:    3/3     Batch: 530/6968  Loss: 3.3952081203460693\n",
      "\n",
      "Epoch:    3/3     Batch: 535/6968  Loss: 3.4715964794158936\n",
      "\n",
      "Epoch:    3/3     Batch: 540/6968  Loss: 3.6559349060058595\n",
      "\n",
      "Epoch:    3/3     Batch: 545/6968  Loss: 3.6037383556365965\n",
      "\n",
      "Epoch:    3/3     Batch: 550/6968  Loss: 3.498757171630859\n",
      "\n",
      "Epoch:    3/3     Batch: 555/6968  Loss: 3.670085096359253\n",
      "\n",
      "Epoch:    3/3     Batch: 560/6968  Loss: 3.537448501586914\n",
      "\n",
      "Epoch:    3/3     Batch: 565/6968  Loss: 3.6960652351379393\n",
      "\n",
      "Epoch:    3/3     Batch: 570/6968  Loss: 3.5048380851745606\n",
      "\n",
      "Epoch:    3/3     Batch: 575/6968  Loss: 3.4686002254486086\n",
      "\n",
      "Epoch:    3/3     Batch: 580/6968  Loss: 3.5557799339294434\n",
      "\n",
      "Epoch:    3/3     Batch: 585/6968  Loss: 3.5533536434173585\n",
      "\n",
      "Epoch:    3/3     Batch: 590/6968  Loss: 3.577843999862671\n",
      "\n",
      "Epoch:    3/3     Batch: 595/6968  Loss: 3.6408170223236085\n",
      "\n",
      "Epoch:    3/3     Batch: 600/6968  Loss: 3.5669507026672362\n",
      "\n",
      "Epoch:    3/3     Batch: 605/6968  Loss: 3.4542805671691896\n",
      "\n",
      "Epoch:    3/3     Batch: 610/6968  Loss: 3.4652921199798583\n",
      "\n",
      "Epoch:    3/3     Batch: 615/6968  Loss: 3.507093000411987\n",
      "\n",
      "Epoch:    3/3     Batch: 620/6968  Loss: 3.6414413928985594\n",
      "\n",
      "Epoch:    3/3     Batch: 625/6968  Loss: 3.5829437732696534\n",
      "\n",
      "Epoch:    3/3     Batch: 630/6968  Loss: 3.3895571708679197\n",
      "\n",
      "Epoch:    3/3     Batch: 635/6968  Loss: 3.705070161819458\n",
      "\n",
      "Epoch:    3/3     Batch: 640/6968  Loss: 3.6222016334533693\n",
      "\n",
      "Epoch:    3/3     Batch: 645/6968  Loss: 3.440762233734131\n",
      "\n",
      "Epoch:    3/3     Batch: 650/6968  Loss: 3.6342113494873045\n",
      "\n",
      "Epoch:    3/3     Batch: 655/6968  Loss: 3.5588482856750487\n",
      "\n",
      "Epoch:    3/3     Batch: 660/6968  Loss: 3.7693176746368406\n",
      "\n",
      "Epoch:    3/3     Batch: 665/6968  Loss: 3.741651248931885\n",
      "\n",
      "Epoch:    3/3     Batch: 670/6968  Loss: 3.4537357330322265\n",
      "\n",
      "Epoch:    3/3     Batch: 675/6968  Loss: 3.6357882022857666\n",
      "\n",
      "Epoch:    3/3     Batch: 680/6968  Loss: 3.747841548919678\n",
      "\n",
      "Epoch:    3/3     Batch: 685/6968  Loss: 3.5642930030822755\n",
      "\n",
      "Epoch:    3/3     Batch: 690/6968  Loss: 3.571466827392578\n",
      "\n",
      "Epoch:    3/3     Batch: 695/6968  Loss: 3.6863401889801026\n",
      "\n",
      "Epoch:    3/3     Batch: 700/6968  Loss: 3.6397751808166503\n",
      "\n",
      "Epoch:    3/3     Batch: 705/6968  Loss: 3.5652657985687255\n",
      "\n",
      "Epoch:    3/3     Batch: 710/6968  Loss: 3.741885709762573\n",
      "\n",
      "Epoch:    3/3     Batch: 715/6968  Loss: 3.217140960693359\n",
      "\n",
      "Epoch:    3/3     Batch: 720/6968  Loss: 3.28931040763855\n",
      "\n",
      "Epoch:    3/3     Batch: 725/6968  Loss: 3.5497509002685548\n",
      "\n",
      "Epoch:    3/3     Batch: 730/6968  Loss: 3.5656857967376707\n",
      "\n",
      "Epoch:    3/3     Batch: 735/6968  Loss: 3.60715799331665\n",
      "\n",
      "Epoch:    3/3     Batch: 740/6968  Loss: 3.5528477668762206\n",
      "\n",
      "Epoch:    3/3     Batch: 745/6968  Loss: 3.442074251174927\n",
      "\n",
      "Epoch:    3/3     Batch: 750/6968  Loss: 3.5690212726593016\n",
      "\n",
      "Epoch:    3/3     Batch: 755/6968  Loss: 3.5413283824920656\n",
      "\n",
      "Epoch:    3/3     Batch: 760/6968  Loss: 3.3913357734680174\n",
      "\n",
      "Epoch:    3/3     Batch: 765/6968  Loss: 3.5400087356567385\n",
      "\n",
      "Epoch:    3/3     Batch: 770/6968  Loss: 3.554926109313965\n",
      "\n",
      "Epoch:    3/3     Batch: 775/6968  Loss: 3.7702245235443117\n",
      "\n",
      "Epoch:    3/3     Batch: 780/6968  Loss: 3.602027940750122\n",
      "\n",
      "Epoch:    3/3     Batch: 785/6968  Loss: 3.5722591400146486\n",
      "\n",
      "Epoch:    3/3     Batch: 790/6968  Loss: 3.7478270053863527\n",
      "\n",
      "Epoch:    3/3     Batch: 795/6968  Loss: 3.4670684337615967\n",
      "\n",
      "Epoch:    3/3     Batch: 800/6968  Loss: 3.3893322944641113\n",
      "\n",
      "Epoch:    3/3     Batch: 805/6968  Loss: 3.5507737159729005\n",
      "\n",
      "Epoch:    3/3     Batch: 810/6968  Loss: 3.6625349044799806\n",
      "\n",
      "Epoch:    3/3     Batch: 815/6968  Loss: 3.4309270858764647\n",
      "\n",
      "Epoch:    3/3     Batch: 820/6968  Loss: 3.3506407260894777\n",
      "\n",
      "Epoch:    3/3     Batch: 825/6968  Loss: 3.4709394931793214\n",
      "\n",
      "Epoch:    3/3     Batch: 830/6968  Loss: 3.524344062805176\n",
      "\n",
      "Epoch:    3/3     Batch: 835/6968  Loss: 3.554994297027588\n",
      "\n",
      "Epoch:    3/3     Batch: 840/6968  Loss: 3.5263779163360596\n",
      "\n",
      "Epoch:    3/3     Batch: 845/6968  Loss: 3.669694185256958\n",
      "\n",
      "Epoch:    3/3     Batch: 850/6968  Loss: 3.5767666816711428\n",
      "\n",
      "Epoch:    3/3     Batch: 855/6968  Loss: 3.370372486114502\n",
      "\n",
      "Epoch:    3/3     Batch: 860/6968  Loss: 3.5239416122436524\n",
      "\n",
      "Epoch:    3/3     Batch: 865/6968  Loss: 3.611713171005249\n",
      "\n",
      "Epoch:    3/3     Batch: 870/6968  Loss: 3.4148083686828614\n",
      "\n",
      "Epoch:    3/3     Batch: 875/6968  Loss: 3.5877027988433836\n",
      "\n",
      "Epoch:    3/3     Batch: 880/6968  Loss: 3.4031731605529787\n",
      "\n",
      "Epoch:    3/3     Batch: 885/6968  Loss: 3.540995788574219\n",
      "\n",
      "Epoch:    3/3     Batch: 890/6968  Loss: 3.5083195686340334\n",
      "\n",
      "Epoch:    3/3     Batch: 895/6968  Loss: 3.6314239501953125\n",
      "\n",
      "Epoch:    3/3     Batch: 900/6968  Loss: 3.493776321411133\n",
      "\n",
      "Epoch:    3/3     Batch: 905/6968  Loss: 3.7391705989837645\n",
      "\n",
      "Epoch:    3/3     Batch: 910/6968  Loss: 3.5789275646209715\n",
      "\n",
      "Epoch:    3/3     Batch: 915/6968  Loss: 3.486683893203735\n",
      "\n",
      "Epoch:    3/3     Batch: 920/6968  Loss: 3.5204506874084474\n",
      "\n",
      "Epoch:    3/3     Batch: 925/6968  Loss: 3.5353265762329102\n",
      "\n",
      "Epoch:    3/3     Batch: 930/6968  Loss: 3.5313003063201904\n",
      "\n",
      "Epoch:    3/3     Batch: 935/6968  Loss: 3.667047643661499\n",
      "\n",
      "Epoch:    3/3     Batch: 940/6968  Loss: 3.626927042007446\n",
      "\n",
      "Epoch:    3/3     Batch: 945/6968  Loss: 3.5371463775634764\n",
      "\n",
      "Epoch:    3/3     Batch: 950/6968  Loss: 3.566564178466797\n",
      "\n",
      "Epoch:    3/3     Batch: 955/6968  Loss: 3.452839803695679\n",
      "\n",
      "Epoch:    3/3     Batch: 960/6968  Loss: 3.345441198348999\n",
      "\n",
      "Epoch:    3/3     Batch: 965/6968  Loss: 3.5111344337463377\n",
      "\n",
      "Epoch:    3/3     Batch: 970/6968  Loss: 3.583448886871338\n",
      "\n",
      "Epoch:    3/3     Batch: 975/6968  Loss: 3.46555233001709\n",
      "\n",
      "Epoch:    3/3     Batch: 980/6968  Loss: 3.5093146324157716\n",
      "\n",
      "Epoch:    3/3     Batch: 985/6968  Loss: 3.4213568687438967\n",
      "\n",
      "Epoch:    3/3     Batch: 990/6968  Loss: 3.589538335800171\n",
      "\n",
      "Epoch:    3/3     Batch: 995/6968  Loss: 3.5089694976806642\n",
      "\n",
      "Epoch:    3/3     Batch:1000/6968  Loss: 3.5692554473876954\n",
      "\n",
      "Epoch:    3/3     Batch:1005/6968  Loss: 3.7190041065216066\n",
      "\n",
      "Epoch:    3/3     Batch:1010/6968  Loss: 3.6860084533691406\n",
      "\n",
      "Epoch:    3/3     Batch:1015/6968  Loss: 3.4593395233154296\n",
      "\n",
      "Epoch:    3/3     Batch:1020/6968  Loss: 3.6296021938323975\n",
      "\n",
      "Epoch:    3/3     Batch:1025/6968  Loss: 3.7390533447265626\n",
      "\n",
      "Epoch:    3/3     Batch:1030/6968  Loss: 3.5550233840942385\n",
      "\n",
      "Epoch:    3/3     Batch:1035/6968  Loss: 3.3933869361877442\n",
      "\n",
      "Epoch:    3/3     Batch:1040/6968  Loss: 3.581329345703125\n",
      "\n",
      "Epoch:    3/3     Batch:1045/6968  Loss: 3.594980812072754\n",
      "\n",
      "Epoch:    3/3     Batch:1050/6968  Loss: 3.5311889171600344\n",
      "\n",
      "Epoch:    3/3     Batch:1055/6968  Loss: 3.575428533554077\n",
      "\n",
      "Epoch:    3/3     Batch:1060/6968  Loss: 3.666060447692871\n",
      "\n",
      "Epoch:    3/3     Batch:1065/6968  Loss: 3.352311897277832\n",
      "\n",
      "Epoch:    3/3     Batch:1070/6968  Loss: 3.559816312789917\n",
      "\n",
      "Epoch:    3/3     Batch:1075/6968  Loss: 3.61649866104126\n",
      "\n",
      "Epoch:    3/3     Batch:1080/6968  Loss: 3.561978054046631\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    3/3     Batch:1085/6968  Loss: 3.8552395820617678\n",
      "\n",
      "Epoch:    3/3     Batch:1090/6968  Loss: 3.683876323699951\n",
      "\n",
      "Epoch:    3/3     Batch:1095/6968  Loss: 3.578583526611328\n",
      "\n",
      "Epoch:    3/3     Batch:1100/6968  Loss: 3.4680970668792725\n",
      "\n",
      "Epoch:    3/3     Batch:1105/6968  Loss: 3.6101277351379393\n",
      "\n",
      "Epoch:    3/3     Batch:1110/6968  Loss: 3.6279091835021973\n",
      "\n",
      "Epoch:    3/3     Batch:1115/6968  Loss: 3.6733822345733644\n",
      "\n",
      "Epoch:    3/3     Batch:1120/6968  Loss: 3.7929718494415283\n",
      "\n",
      "Epoch:    3/3     Batch:1125/6968  Loss: 3.6539440155029297\n",
      "\n",
      "Epoch:    3/3     Batch:1130/6968  Loss: 3.4479439735412596\n",
      "\n",
      "Epoch:    3/3     Batch:1135/6968  Loss: 3.6210196018218994\n",
      "\n",
      "Epoch:    3/3     Batch:1140/6968  Loss: 3.5091880798339843\n",
      "\n",
      "Epoch:    3/3     Batch:1145/6968  Loss: 3.499842977523804\n",
      "\n",
      "Epoch:    3/3     Batch:1150/6968  Loss: 3.5072057247161865\n",
      "\n",
      "Epoch:    3/3     Batch:1155/6968  Loss: 3.5642138004302977\n",
      "\n",
      "Epoch:    3/3     Batch:1160/6968  Loss: 3.475923442840576\n",
      "\n",
      "Epoch:    3/3     Batch:1165/6968  Loss: 3.5097954273223877\n",
      "\n",
      "Epoch:    3/3     Batch:1170/6968  Loss: 3.4675281047821045\n",
      "\n",
      "Epoch:    3/3     Batch:1175/6968  Loss: 3.457300806045532\n",
      "\n",
      "Epoch:    3/3     Batch:1180/6968  Loss: 3.5898493766784667\n",
      "\n",
      "Epoch:    3/3     Batch:1185/6968  Loss: 3.602126693725586\n",
      "\n",
      "Epoch:    3/3     Batch:1190/6968  Loss: 3.5970759868621824\n",
      "\n",
      "Epoch:    3/3     Batch:1195/6968  Loss: 3.5466295719146728\n",
      "\n",
      "Epoch:    3/3     Batch:1200/6968  Loss: 3.590008783340454\n",
      "\n",
      "Epoch:    3/3     Batch:1205/6968  Loss: 3.366240978240967\n",
      "\n",
      "Epoch:    3/3     Batch:1210/6968  Loss: 3.593217468261719\n",
      "\n",
      "Epoch:    3/3     Batch:1215/6968  Loss: 3.6441125869750977\n",
      "\n",
      "Epoch:    3/3     Batch:1220/6968  Loss: 3.49698486328125\n",
      "\n",
      "Epoch:    3/3     Batch:1225/6968  Loss: 3.556214714050293\n",
      "\n",
      "Epoch:    3/3     Batch:1230/6968  Loss: 3.6375879287719726\n",
      "\n",
      "Epoch:    3/3     Batch:1235/6968  Loss: 3.662204360961914\n",
      "\n",
      "Epoch:    3/3     Batch:1240/6968  Loss: 3.4931902408599855\n",
      "\n",
      "Epoch:    3/3     Batch:1245/6968  Loss: 3.745975971221924\n",
      "\n",
      "Epoch:    3/3     Batch:1250/6968  Loss: 3.4924067497253417\n",
      "\n",
      "Epoch:    3/3     Batch:1255/6968  Loss: 3.554186391830444\n",
      "\n",
      "Epoch:    3/3     Batch:1260/6968  Loss: 3.5801750659942626\n",
      "\n",
      "Epoch:    3/3     Batch:1265/6968  Loss: 3.5332043170928955\n",
      "\n",
      "Epoch:    3/3     Batch:1270/6968  Loss: 3.5683552742004396\n",
      "\n",
      "Epoch:    3/3     Batch:1275/6968  Loss: 3.696707582473755\n",
      "\n",
      "Epoch:    3/3     Batch:1280/6968  Loss: 3.5249853134155273\n",
      "\n",
      "Epoch:    3/3     Batch:1285/6968  Loss: 3.6245988845825194\n",
      "\n",
      "Epoch:    3/3     Batch:1290/6968  Loss: 3.6989792346954347\n",
      "\n",
      "Epoch:    3/3     Batch:1295/6968  Loss: 3.709672737121582\n",
      "\n",
      "Epoch:    3/3     Batch:1300/6968  Loss: 3.479390096664429\n",
      "\n",
      "Epoch:    3/3     Batch:1305/6968  Loss: 3.6679955959320067\n",
      "\n",
      "Epoch:    3/3     Batch:1310/6968  Loss: 3.5763267040252686\n",
      "\n",
      "Epoch:    3/3     Batch:1315/6968  Loss: 3.4659453868865966\n",
      "\n",
      "Epoch:    3/3     Batch:1320/6968  Loss: 3.5310982704162597\n",
      "\n",
      "Epoch:    3/3     Batch:1325/6968  Loss: 3.7202032566070558\n",
      "\n",
      "Epoch:    3/3     Batch:1330/6968  Loss: 3.62726469039917\n",
      "\n",
      "Epoch:    3/3     Batch:1335/6968  Loss: 3.5627041816711427\n",
      "\n",
      "Epoch:    3/3     Batch:1340/6968  Loss: 3.5764976501464845\n",
      "\n",
      "Epoch:    3/3     Batch:1345/6968  Loss: 3.587092399597168\n",
      "\n",
      "Epoch:    3/3     Batch:1350/6968  Loss: 3.4639273643493653\n",
      "\n",
      "Epoch:    3/3     Batch:1355/6968  Loss: 3.4935179233551024\n",
      "\n",
      "Epoch:    3/3     Batch:1360/6968  Loss: 3.7345455646514893\n",
      "\n",
      "Epoch:    3/3     Batch:1365/6968  Loss: 3.502607250213623\n",
      "\n",
      "Epoch:    3/3     Batch:1370/6968  Loss: 3.6960989952087404\n",
      "\n",
      "Epoch:    3/3     Batch:1375/6968  Loss: 3.713025951385498\n",
      "\n",
      "Epoch:    3/3     Batch:1380/6968  Loss: 3.498680257797241\n",
      "\n",
      "Epoch:    3/3     Batch:1385/6968  Loss: 3.744627809524536\n",
      "\n",
      "Epoch:    3/3     Batch:1390/6968  Loss: 3.5548593521118166\n",
      "\n",
      "Epoch:    3/3     Batch:1395/6968  Loss: 3.623660373687744\n",
      "\n",
      "Epoch:    3/3     Batch:1400/6968  Loss: 3.624595355987549\n",
      "\n",
      "Epoch:    3/3     Batch:1405/6968  Loss: 3.594098997116089\n",
      "\n",
      "Epoch:    3/3     Batch:1410/6968  Loss: 3.5612080097198486\n",
      "\n",
      "Epoch:    3/3     Batch:1415/6968  Loss: 3.581259250640869\n",
      "\n",
      "Epoch:    3/3     Batch:1420/6968  Loss: 3.4475605964660643\n",
      "\n",
      "Epoch:    3/3     Batch:1425/6968  Loss: 3.623110628128052\n",
      "\n",
      "Epoch:    3/3     Batch:1430/6968  Loss: 3.3980729579925537\n",
      "\n",
      "Epoch:    3/3     Batch:1435/6968  Loss: 3.667676496505737\n",
      "\n",
      "Epoch:    3/3     Batch:1440/6968  Loss: 3.4639657974243163\n",
      "\n",
      "Epoch:    3/3     Batch:1445/6968  Loss: 3.60664644241333\n",
      "\n",
      "Epoch:    3/3     Batch:1450/6968  Loss: 3.4633119106292725\n",
      "\n",
      "Epoch:    3/3     Batch:1455/6968  Loss: 3.702583742141724\n",
      "\n",
      "Epoch:    3/3     Batch:1460/6968  Loss: 3.5702381134033203\n",
      "\n",
      "Epoch:    3/3     Batch:1465/6968  Loss: 3.67188401222229\n",
      "\n",
      "Epoch:    3/3     Batch:1470/6968  Loss: 3.698140525817871\n",
      "\n",
      "Epoch:    3/3     Batch:1475/6968  Loss: 3.6806821823120117\n",
      "\n",
      "Epoch:    3/3     Batch:1480/6968  Loss: 3.591050052642822\n",
      "\n",
      "Epoch:    3/3     Batch:1485/6968  Loss: 3.644481086730957\n",
      "\n",
      "Epoch:    3/3     Batch:1490/6968  Loss: 3.618240213394165\n",
      "\n",
      "Epoch:    3/3     Batch:1495/6968  Loss: 3.477790355682373\n",
      "\n",
      "Epoch:    3/3     Batch:1500/6968  Loss: 3.692776584625244\n",
      "\n",
      "Epoch:    3/3     Batch:1505/6968  Loss: 3.458515453338623\n",
      "\n",
      "Epoch:    3/3     Batch:1510/6968  Loss: 3.5919957637786863\n",
      "\n",
      "Epoch:    3/3     Batch:1515/6968  Loss: 3.495047378540039\n",
      "\n",
      "Epoch:    3/3     Batch:1520/6968  Loss: 3.560694169998169\n",
      "\n",
      "Epoch:    3/3     Batch:1525/6968  Loss: 3.5891905784606934\n",
      "\n",
      "Epoch:    3/3     Batch:1530/6968  Loss: 3.5634480476379395\n",
      "\n",
      "Epoch:    3/3     Batch:1535/6968  Loss: 3.5487594604492188\n",
      "\n",
      "Epoch:    3/3     Batch:1540/6968  Loss: 3.6533013820648192\n",
      "\n",
      "Epoch:    3/3     Batch:1545/6968  Loss: 3.542034149169922\n",
      "\n",
      "Epoch:    3/3     Batch:1550/6968  Loss: 3.5880930423736572\n",
      "\n",
      "Epoch:    3/3     Batch:1555/6968  Loss: 3.511932134628296\n",
      "\n",
      "Epoch:    3/3     Batch:1560/6968  Loss: 3.3301545143127442\n",
      "\n",
      "Epoch:    3/3     Batch:1565/6968  Loss: 3.615730381011963\n",
      "\n",
      "Epoch:    3/3     Batch:1570/6968  Loss: 3.987571954727173\n",
      "\n",
      "Epoch:    3/3     Batch:1575/6968  Loss: 3.6057366371154784\n",
      "\n",
      "Epoch:    3/3     Batch:1580/6968  Loss: 3.7021580219268797\n",
      "\n",
      "Epoch:    3/3     Batch:1585/6968  Loss: 3.469346761703491\n",
      "\n",
      "Epoch:    3/3     Batch:1590/6968  Loss: 3.618389892578125\n",
      "\n",
      "Epoch:    3/3     Batch:1595/6968  Loss: 3.5453123092651366\n",
      "\n",
      "Epoch:    3/3     Batch:1600/6968  Loss: 3.5463164806365968\n",
      "\n",
      "Epoch:    3/3     Batch:1605/6968  Loss: 3.367997741699219\n",
      "\n",
      "Epoch:    3/3     Batch:1610/6968  Loss: 3.41052360534668\n",
      "\n",
      "Epoch:    3/3     Batch:1615/6968  Loss: 3.6424763202667236\n",
      "\n",
      "Epoch:    3/3     Batch:1620/6968  Loss: 3.606777048110962\n",
      "\n",
      "Epoch:    3/3     Batch:1625/6968  Loss: 3.3789010524749754\n",
      "\n",
      "Epoch:    3/3     Batch:1630/6968  Loss: 3.4202005863189697\n",
      "\n",
      "Epoch:    3/3     Batch:1635/6968  Loss: 3.3674219131469725\n",
      "\n",
      "Epoch:    3/3     Batch:1640/6968  Loss: 3.4734209537506104\n",
      "\n",
      "Epoch:    3/3     Batch:1645/6968  Loss: 3.6399001598358156\n",
      "\n",
      "Epoch:    3/3     Batch:1650/6968  Loss: 3.6006607532501222\n",
      "\n",
      "Epoch:    3/3     Batch:1655/6968  Loss: 3.7381821632385255\n",
      "\n",
      "Epoch:    3/3     Batch:1660/6968  Loss: 3.5220873832702635\n",
      "\n",
      "Epoch:    3/3     Batch:1665/6968  Loss: 3.6538341999053956\n",
      "\n",
      "Epoch:    3/3     Batch:1670/6968  Loss: 3.70267391204834\n",
      "\n",
      "Epoch:    3/3     Batch:1675/6968  Loss: 3.5645350933074953\n",
      "\n",
      "Epoch:    3/3     Batch:1680/6968  Loss: 3.616590213775635\n",
      "\n",
      "Epoch:    3/3     Batch:1685/6968  Loss: 3.6299095153808594\n",
      "\n",
      "Epoch:    3/3     Batch:1690/6968  Loss: 3.5725058555603026\n",
      "\n",
      "Epoch:    3/3     Batch:1695/6968  Loss: 3.6135401248931887\n",
      "\n",
      "Epoch:    3/3     Batch:1700/6968  Loss: 3.501714277267456\n",
      "\n",
      "Epoch:    3/3     Batch:1705/6968  Loss: 3.5051895141601563\n",
      "\n",
      "Epoch:    3/3     Batch:1710/6968  Loss: 3.4949685096740724\n",
      "\n",
      "Epoch:    3/3     Batch:1715/6968  Loss: 3.7574060440063475\n",
      "\n",
      "Epoch:    3/3     Batch:1720/6968  Loss: 3.383737802505493\n",
      "\n",
      "Epoch:    3/3     Batch:1725/6968  Loss: 3.751639175415039\n",
      "\n",
      "Epoch:    3/3     Batch:1730/6968  Loss: 3.513350582122803\n",
      "\n",
      "Epoch:    3/3     Batch:1735/6968  Loss: 3.551835298538208\n",
      "\n",
      "Epoch:    3/3     Batch:1740/6968  Loss: 3.4459962368011476\n",
      "\n",
      "Epoch:    3/3     Batch:1745/6968  Loss: 3.7565959453582765\n",
      "\n",
      "Epoch:    3/3     Batch:1750/6968  Loss: 3.5709197521209717\n",
      "\n",
      "Epoch:    3/3     Batch:1755/6968  Loss: 3.553384017944336\n",
      "\n",
      "Epoch:    3/3     Batch:1760/6968  Loss: 3.519113826751709\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    3/3     Batch:1765/6968  Loss: 3.42406644821167\n",
      "\n",
      "Epoch:    3/3     Batch:1770/6968  Loss: 3.5736614227294923\n",
      "\n",
      "Epoch:    3/3     Batch:1775/6968  Loss: 3.6834042072296143\n",
      "\n",
      "Epoch:    3/3     Batch:1780/6968  Loss: 3.5977049350738524\n",
      "\n",
      "Epoch:    3/3     Batch:1785/6968  Loss: 3.7201319217681883\n",
      "\n",
      "Epoch:    3/3     Batch:1790/6968  Loss: 3.644954967498779\n",
      "\n",
      "Epoch:    3/3     Batch:1795/6968  Loss: 3.6896531105041506\n",
      "\n",
      "Epoch:    3/3     Batch:1800/6968  Loss: 3.4496826171875\n",
      "\n",
      "Epoch:    3/3     Batch:1805/6968  Loss: 3.5507387638092043\n",
      "\n",
      "Epoch:    3/3     Batch:1810/6968  Loss: 3.5638923168182375\n",
      "\n",
      "Epoch:    3/3     Batch:1815/6968  Loss: 3.6865937232971193\n",
      "\n",
      "Epoch:    3/3     Batch:1820/6968  Loss: 3.7124523162841796\n",
      "\n",
      "Epoch:    3/3     Batch:1825/6968  Loss: 3.502395820617676\n",
      "\n",
      "Epoch:    3/3     Batch:1830/6968  Loss: 3.5047096729278566\n",
      "\n",
      "Epoch:    3/3     Batch:1835/6968  Loss: 3.6303123950958254\n",
      "\n",
      "Epoch:    3/3     Batch:1840/6968  Loss: 3.424153184890747\n",
      "\n",
      "Epoch:    3/3     Batch:1845/6968  Loss: 3.4648863792419435\n",
      "\n",
      "Epoch:    3/3     Batch:1850/6968  Loss: 3.5084872245788574\n",
      "\n",
      "Epoch:    3/3     Batch:1855/6968  Loss: 3.577838659286499\n",
      "\n",
      "Epoch:    3/3     Batch:1860/6968  Loss: 3.566099166870117\n",
      "\n",
      "Epoch:    3/3     Batch:1865/6968  Loss: 3.743935489654541\n",
      "\n",
      "Epoch:    3/3     Batch:1870/6968  Loss: 3.6725272655487062\n",
      "\n",
      "Epoch:    3/3     Batch:1875/6968  Loss: 3.537408638000488\n",
      "\n",
      "Epoch:    3/3     Batch:1880/6968  Loss: 3.311072826385498\n",
      "\n",
      "Epoch:    3/3     Batch:1885/6968  Loss: 3.6397836685180662\n",
      "\n",
      "Epoch:    3/3     Batch:1890/6968  Loss: 3.472448205947876\n",
      "\n",
      "Epoch:    3/3     Batch:1895/6968  Loss: 3.820465421676636\n",
      "\n",
      "Epoch:    3/3     Batch:1900/6968  Loss: 3.50608549118042\n",
      "\n",
      "Epoch:    3/3     Batch:1905/6968  Loss: 3.7511717319488525\n",
      "\n",
      "Epoch:    3/3     Batch:1910/6968  Loss: 3.6638168334960937\n",
      "\n",
      "Epoch:    3/3     Batch:1915/6968  Loss: 3.6533446311950684\n",
      "\n",
      "Epoch:    3/3     Batch:1920/6968  Loss: 3.7915627479553224\n",
      "\n",
      "Epoch:    3/3     Batch:1925/6968  Loss: 3.554420804977417\n",
      "\n",
      "Epoch:    3/3     Batch:1930/6968  Loss: 3.680320119857788\n",
      "\n",
      "Epoch:    3/3     Batch:1935/6968  Loss: 3.744528818130493\n",
      "\n",
      "Epoch:    3/3     Batch:1940/6968  Loss: 3.818883180618286\n",
      "\n",
      "Epoch:    3/3     Batch:1945/6968  Loss: 3.5764443397521974\n",
      "\n",
      "Epoch:    3/3     Batch:1950/6968  Loss: 3.610568475723267\n",
      "\n",
      "Epoch:    3/3     Batch:1955/6968  Loss: 3.611581039428711\n",
      "\n",
      "Epoch:    3/3     Batch:1960/6968  Loss: 3.569539928436279\n",
      "\n",
      "Epoch:    3/3     Batch:1965/6968  Loss: 3.569955062866211\n",
      "\n",
      "Epoch:    3/3     Batch:1970/6968  Loss: 3.5981462955474854\n",
      "\n",
      "Epoch:    3/3     Batch:1975/6968  Loss: 3.63391170501709\n",
      "\n",
      "Epoch:    3/3     Batch:1980/6968  Loss: 3.5747610569000243\n",
      "\n",
      "Epoch:    3/3     Batch:1985/6968  Loss: 3.632157897949219\n",
      "\n",
      "Epoch:    3/3     Batch:1990/6968  Loss: 3.5207533836364746\n",
      "\n",
      "Epoch:    3/3     Batch:1995/6968  Loss: 3.5344075202941894\n",
      "\n",
      "Epoch:    3/3     Batch:2000/6968  Loss: 3.564786767959595\n",
      "\n",
      "Epoch:    3/3     Batch:2005/6968  Loss: 3.763960361480713\n",
      "\n",
      "Epoch:    3/3     Batch:2010/6968  Loss: 3.6686330318450926\n",
      "\n",
      "Epoch:    3/3     Batch:2015/6968  Loss: 3.689862012863159\n",
      "\n",
      "Epoch:    3/3     Batch:2020/6968  Loss: 3.430174446105957\n",
      "\n",
      "Epoch:    3/3     Batch:2025/6968  Loss: 3.5471031665802\n",
      "\n",
      "Epoch:    3/3     Batch:2030/6968  Loss: 3.5517048835754395\n",
      "\n",
      "Epoch:    3/3     Batch:2035/6968  Loss: 3.4037347793579102\n",
      "\n",
      "Epoch:    3/3     Batch:2040/6968  Loss: 3.620273971557617\n",
      "\n",
      "Epoch:    3/3     Batch:2045/6968  Loss: 3.6782363414764405\n",
      "\n",
      "Epoch:    3/3     Batch:2050/6968  Loss: 3.6514352321624757\n",
      "\n",
      "Epoch:    3/3     Batch:2055/6968  Loss: 3.5934387683868407\n",
      "\n",
      "Epoch:    3/3     Batch:2060/6968  Loss: 3.7368446826934814\n",
      "\n",
      "Epoch:    3/3     Batch:2065/6968  Loss: 3.609031867980957\n",
      "\n",
      "Epoch:    3/3     Batch:2070/6968  Loss: 3.598777341842651\n",
      "\n",
      "Epoch:    3/3     Batch:2075/6968  Loss: 3.588443899154663\n",
      "\n",
      "Epoch:    3/3     Batch:2080/6968  Loss: 3.543428325653076\n",
      "\n",
      "Epoch:    3/3     Batch:2085/6968  Loss: 3.58403000831604\n",
      "\n",
      "Epoch:    3/3     Batch:2090/6968  Loss: 3.5080482959747314\n",
      "\n",
      "Epoch:    3/3     Batch:2095/6968  Loss: 3.627969169616699\n",
      "\n",
      "Epoch:    3/3     Batch:2100/6968  Loss: 3.7202526092529298\n",
      "\n",
      "Epoch:    3/3     Batch:2105/6968  Loss: 3.7142225742340087\n",
      "\n",
      "Epoch:    3/3     Batch:2110/6968  Loss: 3.503081941604614\n",
      "\n",
      "Epoch:    3/3     Batch:2115/6968  Loss: 3.492802143096924\n",
      "\n",
      "Epoch:    3/3     Batch:2120/6968  Loss: 3.505495309829712\n",
      "\n",
      "Epoch:    3/3     Batch:2125/6968  Loss: 3.2793730735778808\n",
      "\n",
      "Epoch:    3/3     Batch:2130/6968  Loss: 3.599375867843628\n",
      "\n",
      "Epoch:    3/3     Batch:2135/6968  Loss: 3.3820605754852293\n",
      "\n",
      "Epoch:    3/3     Batch:2140/6968  Loss: 3.545019197463989\n",
      "\n",
      "Epoch:    3/3     Batch:2145/6968  Loss: 3.5990575313568116\n",
      "\n",
      "Epoch:    3/3     Batch:2150/6968  Loss: 3.6291250228881835\n",
      "\n",
      "Epoch:    3/3     Batch:2155/6968  Loss: 3.5123435497283935\n",
      "\n",
      "Epoch:    3/3     Batch:2160/6968  Loss: 3.6153101921081543\n",
      "\n",
      "Epoch:    3/3     Batch:2165/6968  Loss: 3.6541866779327394\n",
      "\n",
      "Epoch:    3/3     Batch:2170/6968  Loss: 3.5755852699279784\n",
      "\n",
      "Epoch:    3/3     Batch:2175/6968  Loss: 3.6381502628326414\n",
      "\n",
      "Epoch:    3/3     Batch:2180/6968  Loss: 3.6332114219665526\n",
      "\n",
      "Epoch:    3/3     Batch:2185/6968  Loss: 3.6490829944610597\n",
      "\n",
      "Epoch:    3/3     Batch:2190/6968  Loss: 3.503344678878784\n",
      "\n",
      "Epoch:    3/3     Batch:2195/6968  Loss: 3.56884765625\n",
      "\n",
      "Epoch:    3/3     Batch:2200/6968  Loss: 3.6525596141815186\n",
      "\n",
      "Epoch:    3/3     Batch:2205/6968  Loss: 3.5618202686309814\n",
      "\n",
      "Epoch:    3/3     Batch:2210/6968  Loss: 3.5572296142578126\n",
      "\n",
      "Epoch:    3/3     Batch:2215/6968  Loss: 3.545432424545288\n",
      "\n",
      "Epoch:    3/3     Batch:2220/6968  Loss: 3.843314838409424\n",
      "\n",
      "Epoch:    3/3     Batch:2225/6968  Loss: 3.4830169677734375\n",
      "\n",
      "Epoch:    3/3     Batch:2230/6968  Loss: 3.796165704727173\n",
      "\n",
      "Epoch:    3/3     Batch:2235/6968  Loss: 3.7335434913635255\n",
      "\n",
      "Epoch:    3/3     Batch:2240/6968  Loss: 3.598319244384766\n",
      "\n",
      "Epoch:    3/3     Batch:2245/6968  Loss: 3.654708480834961\n",
      "\n",
      "Epoch:    3/3     Batch:2250/6968  Loss: 3.5409215927124023\n",
      "\n",
      "Epoch:    3/3     Batch:2255/6968  Loss: 3.5290213108062742\n",
      "\n",
      "Epoch:    3/3     Batch:2260/6968  Loss: 3.6321386814117433\n",
      "\n",
      "Epoch:    3/3     Batch:2265/6968  Loss: 3.620654249191284\n",
      "\n",
      "Epoch:    3/3     Batch:2270/6968  Loss: 3.42102689743042\n",
      "\n",
      "Epoch:    3/3     Batch:2275/6968  Loss: 3.6097137928009033\n",
      "\n",
      "Epoch:    3/3     Batch:2280/6968  Loss: 3.7170676708221437\n",
      "\n",
      "Epoch:    3/3     Batch:2285/6968  Loss: 3.5481215000152586\n",
      "\n",
      "Epoch:    3/3     Batch:2290/6968  Loss: 3.262298059463501\n",
      "\n",
      "Epoch:    3/3     Batch:2295/6968  Loss: 3.6550341129302977\n",
      "\n",
      "Epoch:    3/3     Batch:2300/6968  Loss: 3.6252015590667725\n",
      "\n",
      "Epoch:    3/3     Batch:2305/6968  Loss: 3.689331388473511\n",
      "\n",
      "Epoch:    3/3     Batch:2310/6968  Loss: 3.425949144363403\n",
      "\n",
      "Epoch:    3/3     Batch:2315/6968  Loss: 3.5458024978637694\n",
      "\n",
      "Epoch:    3/3     Batch:2320/6968  Loss: 3.6582565784454344\n",
      "\n",
      "Epoch:    3/3     Batch:2325/6968  Loss: 3.591929531097412\n",
      "\n",
      "Epoch:    3/3     Batch:2330/6968  Loss: 3.489134168624878\n",
      "\n",
      "Epoch:    3/3     Batch:2335/6968  Loss: 3.680688190460205\n",
      "\n",
      "Epoch:    3/3     Batch:2340/6968  Loss: 3.5961438179016114\n",
      "\n",
      "Epoch:    3/3     Batch:2345/6968  Loss: 3.6075284481048584\n",
      "\n",
      "Epoch:    3/3     Batch:2350/6968  Loss: 3.400458240509033\n",
      "\n",
      "Epoch:    3/3     Batch:2355/6968  Loss: 3.575205612182617\n",
      "\n",
      "Epoch:    3/3     Batch:2360/6968  Loss: 3.5272429943084718\n",
      "\n",
      "Epoch:    3/3     Batch:2365/6968  Loss: 3.4183468341827394\n",
      "\n",
      "Epoch:    3/3     Batch:2370/6968  Loss: 3.5177777767181397\n",
      "\n",
      "Epoch:    3/3     Batch:2375/6968  Loss: 3.702280616760254\n",
      "\n",
      "Epoch:    3/3     Batch:2380/6968  Loss: 3.5212755680084227\n",
      "\n",
      "Epoch:    3/3     Batch:2385/6968  Loss: 3.8051257610321043\n",
      "\n",
      "Epoch:    3/3     Batch:2390/6968  Loss: 3.6093687534332277\n",
      "\n",
      "Epoch:    3/3     Batch:2395/6968  Loss: 3.394140386581421\n",
      "\n",
      "Epoch:    3/3     Batch:2400/6968  Loss: 3.7094531059265137\n",
      "\n",
      "Epoch:    3/3     Batch:2405/6968  Loss: 3.355393409729004\n",
      "\n",
      "Epoch:    3/3     Batch:2410/6968  Loss: 3.899234676361084\n",
      "\n",
      "Epoch:    3/3     Batch:2415/6968  Loss: 3.498529052734375\n",
      "\n",
      "Epoch:    3/3     Batch:2420/6968  Loss: 3.435884189605713\n",
      "\n",
      "Epoch:    3/3     Batch:2425/6968  Loss: 3.6418328285217285\n",
      "\n",
      "Epoch:    3/3     Batch:2430/6968  Loss: 3.6911237239837646\n",
      "\n",
      "Epoch:    3/3     Batch:2435/6968  Loss: 3.4900488376617433\n",
      "\n",
      "Epoch:    3/3     Batch:2440/6968  Loss: 3.6603021144866945\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    3/3     Batch:2445/6968  Loss: 3.561333990097046\n",
      "\n",
      "Epoch:    3/3     Batch:2450/6968  Loss: 3.708781623840332\n",
      "\n",
      "Epoch:    3/3     Batch:2455/6968  Loss: 3.572990131378174\n",
      "\n",
      "Epoch:    3/3     Batch:2460/6968  Loss: 3.583543872833252\n",
      "\n",
      "Epoch:    3/3     Batch:2465/6968  Loss: 3.46852126121521\n",
      "\n",
      "Epoch:    3/3     Batch:2470/6968  Loss: 3.619842290878296\n",
      "\n",
      "Epoch:    3/3     Batch:2475/6968  Loss: 3.5817803859710695\n",
      "\n",
      "Epoch:    3/3     Batch:2480/6968  Loss: 3.464384126663208\n",
      "\n",
      "Epoch:    3/3     Batch:2485/6968  Loss: 3.58955340385437\n",
      "\n",
      "Epoch:    3/3     Batch:2490/6968  Loss: 3.4387584209442137\n",
      "\n",
      "Epoch:    3/3     Batch:2495/6968  Loss: 3.5356839656829835\n",
      "\n",
      "Epoch:    3/3     Batch:2500/6968  Loss: 3.467518186569214\n",
      "\n",
      "Epoch:    3/3     Batch:2505/6968  Loss: 3.7810497760772703\n",
      "\n",
      "Epoch:    3/3     Batch:2510/6968  Loss: 3.7282032012939452\n",
      "\n",
      "Epoch:    3/3     Batch:2515/6968  Loss: 3.728763246536255\n",
      "\n",
      "Epoch:    3/3     Batch:2520/6968  Loss: 3.5388291835784913\n",
      "\n",
      "Epoch:    3/3     Batch:2525/6968  Loss: 3.5657516002655028\n",
      "\n",
      "Epoch:    3/3     Batch:2530/6968  Loss: 3.6606798648834227\n",
      "\n",
      "Epoch:    3/3     Batch:2535/6968  Loss: 3.46091685295105\n",
      "\n",
      "Epoch:    3/3     Batch:2540/6968  Loss: 3.6001227855682374\n",
      "\n",
      "Epoch:    3/3     Batch:2545/6968  Loss: 3.7119614124298095\n",
      "\n",
      "Epoch:    3/3     Batch:2550/6968  Loss: 3.4636908054351805\n",
      "\n",
      "Epoch:    3/3     Batch:2555/6968  Loss: 3.496503400802612\n",
      "\n",
      "Epoch:    3/3     Batch:2560/6968  Loss: 3.7164823532104494\n",
      "\n",
      "Epoch:    3/3     Batch:2565/6968  Loss: 3.637281894683838\n",
      "\n",
      "Epoch:    3/3     Batch:2570/6968  Loss: 3.6551910400390626\n",
      "\n",
      "Epoch:    3/3     Batch:2575/6968  Loss: 3.5901210784912108\n",
      "\n",
      "Epoch:    3/3     Batch:2580/6968  Loss: 3.469291639328003\n",
      "\n",
      "Epoch:    3/3     Batch:2585/6968  Loss: 3.691315937042236\n",
      "\n",
      "Epoch:    3/3     Batch:2590/6968  Loss: 3.5466043949127197\n",
      "\n",
      "Epoch:    3/3     Batch:2595/6968  Loss: 3.678437852859497\n",
      "\n",
      "Epoch:    3/3     Batch:2600/6968  Loss: 3.7144593238830566\n",
      "\n",
      "Epoch:    3/3     Batch:2605/6968  Loss: 3.359840679168701\n",
      "\n",
      "Epoch:    3/3     Batch:2610/6968  Loss: 3.5821025371551514\n",
      "\n",
      "Epoch:    3/3     Batch:2615/6968  Loss: 3.455355405807495\n",
      "\n",
      "Epoch:    3/3     Batch:2620/6968  Loss: 3.559564447402954\n",
      "\n",
      "Epoch:    3/3     Batch:2625/6968  Loss: 3.6396579265594484\n",
      "\n",
      "Epoch:    3/3     Batch:2630/6968  Loss: 3.4702573299407957\n",
      "\n",
      "Epoch:    3/3     Batch:2635/6968  Loss: 3.5776252269744875\n",
      "\n",
      "Epoch:    3/3     Batch:2640/6968  Loss: 3.649070119857788\n",
      "\n",
      "Epoch:    3/3     Batch:2645/6968  Loss: 3.4601895332336428\n",
      "\n",
      "Epoch:    3/3     Batch:2650/6968  Loss: 3.493160772323608\n",
      "\n",
      "Epoch:    3/3     Batch:2655/6968  Loss: 3.5037588119506835\n",
      "\n",
      "Epoch:    3/3     Batch:2660/6968  Loss: 3.6821202754974367\n",
      "\n",
      "Epoch:    3/3     Batch:2665/6968  Loss: 3.666771173477173\n",
      "\n",
      "Epoch:    3/3     Batch:2670/6968  Loss: 3.7033970832824705\n",
      "\n",
      "Epoch:    3/3     Batch:2675/6968  Loss: 3.5623828887939455\n",
      "\n",
      "Epoch:    3/3     Batch:2680/6968  Loss: 3.4929576396942137\n",
      "\n",
      "Epoch:    3/3     Batch:2685/6968  Loss: 3.4294033527374266\n",
      "\n",
      "Epoch:    3/3     Batch:2690/6968  Loss: 3.714617395401001\n",
      "\n",
      "Epoch:    3/3     Batch:2695/6968  Loss: 3.431203079223633\n",
      "\n",
      "Epoch:    3/3     Batch:2700/6968  Loss: 3.572033405303955\n",
      "\n",
      "Epoch:    3/3     Batch:2705/6968  Loss: 3.5778478622436523\n",
      "\n",
      "Epoch:    3/3     Batch:2710/6968  Loss: 3.654666805267334\n",
      "\n",
      "Epoch:    3/3     Batch:2715/6968  Loss: 3.6085643768310547\n",
      "\n",
      "Epoch:    3/3     Batch:2720/6968  Loss: 3.539756488800049\n",
      "\n",
      "Epoch:    3/3     Batch:2725/6968  Loss: 3.631315898895264\n",
      "\n",
      "Epoch:    3/3     Batch:2730/6968  Loss: 3.398208665847778\n",
      "\n",
      "Epoch:    3/3     Batch:2735/6968  Loss: 3.494394302368164\n",
      "\n",
      "Epoch:    3/3     Batch:2740/6968  Loss: 3.5017505168914793\n",
      "\n",
      "Epoch:    3/3     Batch:2745/6968  Loss: 3.432358455657959\n",
      "\n",
      "Epoch:    3/3     Batch:2750/6968  Loss: 3.551889657974243\n",
      "\n",
      "Epoch:    3/3     Batch:2755/6968  Loss: 3.719289016723633\n",
      "\n",
      "Epoch:    3/3     Batch:2760/6968  Loss: 3.502325487136841\n",
      "\n",
      "Epoch:    3/3     Batch:2765/6968  Loss: 3.5827314376831056\n",
      "\n",
      "Epoch:    3/3     Batch:2770/6968  Loss: 3.4562403678894045\n",
      "\n",
      "Epoch:    3/3     Batch:2775/6968  Loss: 3.695369815826416\n",
      "\n",
      "Epoch:    3/3     Batch:2780/6968  Loss: 3.5686307907104493\n",
      "\n",
      "Epoch:    3/3     Batch:2785/6968  Loss: 3.66275372505188\n",
      "\n",
      "Epoch:    3/3     Batch:2790/6968  Loss: 3.760305070877075\n",
      "\n",
      "Epoch:    3/3     Batch:2795/6968  Loss: 3.400387096405029\n",
      "\n",
      "Epoch:    3/3     Batch:2800/6968  Loss: 3.693489837646484\n",
      "\n",
      "Epoch:    3/3     Batch:2805/6968  Loss: 3.6916951179504394\n",
      "\n",
      "Epoch:    3/3     Batch:2810/6968  Loss: 3.815112590789795\n",
      "\n",
      "Epoch:    3/3     Batch:2815/6968  Loss: 3.821041393280029\n",
      "\n",
      "Epoch:    3/3     Batch:2820/6968  Loss: 3.5817728996276856\n",
      "\n",
      "Epoch:    3/3     Batch:2825/6968  Loss: 3.55870099067688\n",
      "\n",
      "Epoch:    3/3     Batch:2830/6968  Loss: 3.515517520904541\n",
      "\n",
      "Epoch:    3/3     Batch:2835/6968  Loss: 3.736192512512207\n",
      "\n",
      "Epoch:    3/3     Batch:2840/6968  Loss: 3.545930528640747\n",
      "\n",
      "Epoch:    3/3     Batch:2845/6968  Loss: 3.66283802986145\n",
      "\n",
      "Epoch:    3/3     Batch:2850/6968  Loss: 3.530586767196655\n",
      "\n",
      "Epoch:    3/3     Batch:2855/6968  Loss: 3.3796103954315186\n",
      "\n",
      "Epoch:    3/3     Batch:2860/6968  Loss: 3.6279052257537843\n",
      "\n",
      "Epoch:    3/3     Batch:2865/6968  Loss: 3.7809320449829102\n",
      "\n",
      "Epoch:    3/3     Batch:2870/6968  Loss: 3.4439603328704833\n",
      "\n",
      "Epoch:    3/3     Batch:2875/6968  Loss: 3.801902914047241\n",
      "\n",
      "Epoch:    3/3     Batch:2880/6968  Loss: 3.6362993717193604\n",
      "\n",
      "Epoch:    3/3     Batch:2885/6968  Loss: 3.607925367355347\n",
      "\n",
      "Epoch:    3/3     Batch:2890/6968  Loss: 3.5767443656921385\n",
      "\n",
      "Epoch:    3/3     Batch:2895/6968  Loss: 3.6641039848327637\n",
      "\n",
      "Epoch:    3/3     Batch:2900/6968  Loss: 3.4123190879821776\n",
      "\n",
      "Epoch:    3/3     Batch:2905/6968  Loss: 3.4499316692352293\n",
      "\n",
      "Epoch:    3/3     Batch:2910/6968  Loss: 3.428537940979004\n",
      "\n",
      "Epoch:    3/3     Batch:2915/6968  Loss: 3.707663154602051\n",
      "\n",
      "Epoch:    3/3     Batch:2920/6968  Loss: 3.659335565567017\n",
      "\n",
      "Epoch:    3/3     Batch:2925/6968  Loss: 3.582519865036011\n",
      "\n",
      "Epoch:    3/3     Batch:2930/6968  Loss: 3.538331460952759\n",
      "\n",
      "Epoch:    3/3     Batch:2935/6968  Loss: 3.628278398513794\n",
      "\n",
      "Epoch:    3/3     Batch:2940/6968  Loss: 3.5486422538757325\n",
      "\n",
      "Epoch:    3/3     Batch:2945/6968  Loss: 3.6023632049560548\n",
      "\n",
      "Epoch:    3/3     Batch:2950/6968  Loss: 3.461224603652954\n",
      "\n",
      "Epoch:    3/3     Batch:2955/6968  Loss: 3.665047550201416\n",
      "\n",
      "Epoch:    3/3     Batch:2960/6968  Loss: 3.4979736328125\n",
      "\n",
      "Epoch:    3/3     Batch:2965/6968  Loss: 3.4970757007598876\n",
      "\n",
      "Epoch:    3/3     Batch:2970/6968  Loss: 3.6434538841247557\n",
      "\n",
      "Epoch:    3/3     Batch:2975/6968  Loss: 3.544237995147705\n",
      "\n",
      "Epoch:    3/3     Batch:2980/6968  Loss: 3.563322925567627\n",
      "\n",
      "Epoch:    3/3     Batch:2985/6968  Loss: 3.5417213916778563\n",
      "\n",
      "Epoch:    3/3     Batch:2990/6968  Loss: 3.493555784225464\n",
      "\n",
      "Epoch:    3/3     Batch:2995/6968  Loss: 3.5767259120941164\n",
      "\n",
      "Epoch:    3/3     Batch:3000/6968  Loss: 3.4276968955993654\n",
      "\n",
      "Epoch:    3/3     Batch:3005/6968  Loss: 3.447457790374756\n",
      "\n",
      "Epoch:    3/3     Batch:3010/6968  Loss: 3.4886696338653564\n",
      "\n",
      "Epoch:    3/3     Batch:3015/6968  Loss: 3.6451061248779295\n",
      "\n",
      "Epoch:    3/3     Batch:3020/6968  Loss: 3.2841819286346436\n",
      "\n",
      "Epoch:    3/3     Batch:3025/6968  Loss: 3.698504114151001\n",
      "\n",
      "Epoch:    3/3     Batch:3030/6968  Loss: 3.5226675987243654\n",
      "\n",
      "Epoch:    3/3     Batch:3035/6968  Loss: 3.721686267852783\n",
      "\n",
      "Epoch:    3/3     Batch:3040/6968  Loss: 3.695960283279419\n",
      "\n",
      "Epoch:    3/3     Batch:3045/6968  Loss: 3.4045552730560305\n",
      "\n",
      "Epoch:    3/3     Batch:3050/6968  Loss: 3.784381294250488\n",
      "\n",
      "Epoch:    3/3     Batch:3055/6968  Loss: 3.467796230316162\n",
      "\n",
      "Epoch:    3/3     Batch:3060/6968  Loss: 3.5193941593170166\n",
      "\n",
      "Epoch:    3/3     Batch:3065/6968  Loss: 3.7622467994689943\n",
      "\n",
      "Epoch:    3/3     Batch:3070/6968  Loss: 3.6507843017578123\n",
      "\n",
      "Epoch:    3/3     Batch:3075/6968  Loss: 3.4511117935180664\n",
      "\n",
      "Epoch:    3/3     Batch:3080/6968  Loss: 3.702347421646118\n",
      "\n",
      "Epoch:    3/3     Batch:3085/6968  Loss: 3.5410307884216308\n",
      "\n",
      "Epoch:    3/3     Batch:3090/6968  Loss: 3.6725815296173097\n",
      "\n",
      "Epoch:    3/3     Batch:3095/6968  Loss: 3.6282132148742674\n",
      "\n",
      "Epoch:    3/3     Batch:3100/6968  Loss: 3.624578094482422\n",
      "\n",
      "Epoch:    3/3     Batch:3105/6968  Loss: 3.5065354347229003\n",
      "\n",
      "Epoch:    3/3     Batch:3110/6968  Loss: 3.4968406200408935\n",
      "\n",
      "Epoch:    3/3     Batch:3115/6968  Loss: 3.7814746856689454\n",
      "\n",
      "Epoch:    3/3     Batch:3120/6968  Loss: 3.6148934364318848\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    3/3     Batch:3125/6968  Loss: 3.695259857177734\n",
      "\n",
      "Epoch:    3/3     Batch:3130/6968  Loss: 3.6842463493347166\n",
      "\n",
      "Epoch:    3/3     Batch:3135/6968  Loss: 3.7317223072052004\n",
      "\n",
      "Epoch:    3/3     Batch:3140/6968  Loss: 3.4611533164978026\n",
      "\n",
      "Epoch:    3/3     Batch:3145/6968  Loss: 3.4972107887268065\n",
      "\n",
      "Epoch:    3/3     Batch:3150/6968  Loss: 3.2903751850128176\n",
      "\n",
      "Epoch:    3/3     Batch:3155/6968  Loss: 3.439926338195801\n",
      "\n",
      "Epoch:    3/3     Batch:3160/6968  Loss: 3.8264657974243166\n",
      "\n",
      "Epoch:    3/3     Batch:3165/6968  Loss: 3.7286198139190674\n",
      "\n",
      "Epoch:    3/3     Batch:3170/6968  Loss: 3.623403549194336\n",
      "\n",
      "Epoch:    3/3     Batch:3175/6968  Loss: 3.536606693267822\n",
      "\n",
      "Epoch:    3/3     Batch:3180/6968  Loss: 3.5809744358062745\n",
      "\n",
      "Epoch:    3/3     Batch:3185/6968  Loss: 3.6067673206329345\n",
      "\n",
      "Epoch:    3/3     Batch:3190/6968  Loss: 3.6150390625\n",
      "\n",
      "Epoch:    3/3     Batch:3195/6968  Loss: 3.703561544418335\n",
      "\n",
      "Epoch:    3/3     Batch:3200/6968  Loss: 3.7529109001159666\n",
      "\n",
      "Epoch:    3/3     Batch:3205/6968  Loss: 3.688887119293213\n",
      "\n",
      "Epoch:    3/3     Batch:3210/6968  Loss: 3.3464309215545653\n",
      "\n",
      "Epoch:    3/3     Batch:3215/6968  Loss: 3.543221664428711\n",
      "\n",
      "Epoch:    3/3     Batch:3220/6968  Loss: 3.5933669567108155\n",
      "\n",
      "Epoch:    3/3     Batch:3225/6968  Loss: 3.5688365936279296\n",
      "\n",
      "Epoch:    3/3     Batch:3230/6968  Loss: 3.694951391220093\n",
      "\n",
      "Epoch:    3/3     Batch:3235/6968  Loss: 3.5067429065704347\n",
      "\n",
      "Epoch:    3/3     Batch:3240/6968  Loss: 3.6345255374908447\n",
      "\n",
      "Epoch:    3/3     Batch:3245/6968  Loss: 3.5180620193481444\n",
      "\n",
      "Epoch:    3/3     Batch:3250/6968  Loss: 3.539200687408447\n",
      "\n",
      "Epoch:    3/3     Batch:3255/6968  Loss: 3.515914249420166\n",
      "\n",
      "Epoch:    3/3     Batch:3260/6968  Loss: 3.7626028537750242\n",
      "\n",
      "Epoch:    3/3     Batch:3265/6968  Loss: 3.245980215072632\n",
      "\n",
      "Epoch:    3/3     Batch:3270/6968  Loss: 3.7260944843292236\n",
      "\n",
      "Epoch:    3/3     Batch:3275/6968  Loss: 3.499212408065796\n",
      "\n",
      "Epoch:    3/3     Batch:3280/6968  Loss: 3.6794832706451417\n",
      "\n",
      "Epoch:    3/3     Batch:3285/6968  Loss: 3.8037257194519043\n",
      "\n",
      "Epoch:    3/3     Batch:3290/6968  Loss: 3.5967408657073974\n",
      "\n",
      "Epoch:    3/3     Batch:3295/6968  Loss: 3.48036150932312\n",
      "\n",
      "Epoch:    3/3     Batch:3300/6968  Loss: 3.551174783706665\n",
      "\n",
      "Epoch:    3/3     Batch:3305/6968  Loss: 3.588398265838623\n",
      "\n",
      "Epoch:    3/3     Batch:3310/6968  Loss: 3.6210256576538087\n",
      "\n",
      "Epoch:    3/3     Batch:3315/6968  Loss: 3.533768081665039\n",
      "\n",
      "Epoch:    3/3     Batch:3320/6968  Loss: 3.6537309169769285\n",
      "\n",
      "Epoch:    3/3     Batch:3325/6968  Loss: 3.733599233627319\n",
      "\n",
      "Epoch:    3/3     Batch:3330/6968  Loss: 3.546495294570923\n",
      "\n",
      "Epoch:    3/3     Batch:3335/6968  Loss: 3.6560627460479735\n",
      "\n",
      "Epoch:    3/3     Batch:3340/6968  Loss: 3.564475393295288\n",
      "\n",
      "Epoch:    3/3     Batch:3345/6968  Loss: 3.655833053588867\n",
      "\n",
      "Epoch:    3/3     Batch:3350/6968  Loss: 3.568312168121338\n",
      "\n",
      "Epoch:    3/3     Batch:3355/6968  Loss: 3.460000514984131\n",
      "\n",
      "Epoch:    3/3     Batch:3360/6968  Loss: 3.62809476852417\n",
      "\n",
      "Epoch:    3/3     Batch:3365/6968  Loss: 3.404311418533325\n",
      "\n",
      "Epoch:    3/3     Batch:3370/6968  Loss: 3.4479764461517335\n",
      "\n",
      "Epoch:    3/3     Batch:3375/6968  Loss: 3.80539984703064\n",
      "\n",
      "Epoch:    3/3     Batch:3380/6968  Loss: 3.73213472366333\n",
      "\n",
      "Epoch:    3/3     Batch:3385/6968  Loss: 3.6750629901885987\n",
      "\n",
      "Epoch:    3/3     Batch:3390/6968  Loss: 3.5858781337738037\n",
      "\n",
      "Epoch:    3/3     Batch:3395/6968  Loss: 3.442302179336548\n",
      "\n",
      "Epoch:    3/3     Batch:3400/6968  Loss: 3.3743252754211426\n",
      "\n",
      "Epoch:    3/3     Batch:3405/6968  Loss: 3.619980239868164\n",
      "\n",
      "Epoch:    3/3     Batch:3410/6968  Loss: 3.619216966629028\n",
      "\n",
      "Epoch:    3/3     Batch:3415/6968  Loss: 3.6086987972259523\n",
      "\n",
      "Epoch:    3/3     Batch:3420/6968  Loss: 3.774150085449219\n",
      "\n",
      "Epoch:    3/3     Batch:3425/6968  Loss: 3.7810354709625242\n",
      "\n",
      "Epoch:    3/3     Batch:3430/6968  Loss: 3.66200647354126\n",
      "\n",
      "Epoch:    3/3     Batch:3435/6968  Loss: 3.495796537399292\n",
      "\n",
      "Epoch:    3/3     Batch:3440/6968  Loss: 3.448141574859619\n",
      "\n",
      "Epoch:    3/3     Batch:3445/6968  Loss: 3.831739902496338\n",
      "\n",
      "Epoch:    3/3     Batch:3450/6968  Loss: 3.551317834854126\n",
      "\n",
      "Epoch:    3/3     Batch:3455/6968  Loss: 3.4514815330505373\n",
      "\n",
      "Epoch:    3/3     Batch:3460/6968  Loss: 3.55049614906311\n",
      "\n",
      "Epoch:    3/3     Batch:3465/6968  Loss: 3.652305841445923\n",
      "\n",
      "Epoch:    3/3     Batch:3470/6968  Loss: 3.666118621826172\n",
      "\n",
      "Epoch:    3/3     Batch:3475/6968  Loss: 3.341098976135254\n",
      "\n",
      "Epoch:    3/3     Batch:3480/6968  Loss: 3.5751723766326906\n",
      "\n",
      "Epoch:    3/3     Batch:3485/6968  Loss: 3.4023290634155274\n",
      "\n",
      "Epoch:    3/3     Batch:3490/6968  Loss: 3.448298454284668\n",
      "\n",
      "Epoch:    3/3     Batch:3495/6968  Loss: 3.546787166595459\n",
      "\n",
      "Epoch:    3/3     Batch:3500/6968  Loss: 3.6180439949035645\n",
      "\n",
      "Epoch:    3/3     Batch:3505/6968  Loss: 3.568067741394043\n",
      "\n",
      "Epoch:    3/3     Batch:3510/6968  Loss: 3.5465298652648927\n",
      "\n",
      "Epoch:    3/3     Batch:3515/6968  Loss: 3.579416513442993\n",
      "\n",
      "Epoch:    3/3     Batch:3520/6968  Loss: 3.592931032180786\n",
      "\n",
      "Epoch:    3/3     Batch:3525/6968  Loss: 3.855716037750244\n",
      "\n",
      "Epoch:    3/3     Batch:3530/6968  Loss: 3.6157741069793703\n",
      "\n",
      "Epoch:    3/3     Batch:3535/6968  Loss: 3.5348368167877195\n",
      "\n",
      "Epoch:    3/3     Batch:3540/6968  Loss: 3.675269842147827\n",
      "\n",
      "Epoch:    3/3     Batch:3545/6968  Loss: 3.681515836715698\n",
      "\n",
      "Epoch:    3/3     Batch:3550/6968  Loss: 3.496034574508667\n",
      "\n",
      "Epoch:    3/3     Batch:3555/6968  Loss: 3.3494083881378174\n",
      "\n",
      "Epoch:    3/3     Batch:3560/6968  Loss: 3.588171863555908\n",
      "\n",
      "Epoch:    3/3     Batch:3565/6968  Loss: 3.5810409069061278\n",
      "\n",
      "Epoch:    3/3     Batch:3570/6968  Loss: 3.642438220977783\n",
      "\n",
      "Epoch:    3/3     Batch:3575/6968  Loss: 3.719079113006592\n",
      "\n",
      "Epoch:    3/3     Batch:3580/6968  Loss: 3.430012512207031\n",
      "\n",
      "Epoch:    3/3     Batch:3585/6968  Loss: 3.3924441814422606\n",
      "\n",
      "Epoch:    3/3     Batch:3590/6968  Loss: 3.6171393394470215\n",
      "\n",
      "Epoch:    3/3     Batch:3595/6968  Loss: 3.567576599121094\n",
      "\n",
      "Epoch:    3/3     Batch:3600/6968  Loss: 3.59229097366333\n",
      "\n",
      "Epoch:    3/3     Batch:3605/6968  Loss: 3.4802610874176025\n",
      "\n",
      "Epoch:    3/3     Batch:3610/6968  Loss: 3.658967208862305\n",
      "\n",
      "Epoch:    3/3     Batch:3615/6968  Loss: 3.637667179107666\n",
      "\n",
      "Epoch:    3/3     Batch:3620/6968  Loss: 3.3646095275878904\n",
      "\n",
      "Epoch:    3/3     Batch:3625/6968  Loss: 3.4954597473144533\n",
      "\n",
      "Epoch:    3/3     Batch:3630/6968  Loss: 3.6748546600341796\n",
      "\n",
      "Epoch:    3/3     Batch:3635/6968  Loss: 3.5206692218780518\n",
      "\n",
      "Epoch:    3/3     Batch:3640/6968  Loss: 3.6208593368530275\n",
      "\n",
      "Epoch:    3/3     Batch:3645/6968  Loss: 3.7525266647338866\n",
      "\n",
      "Epoch:    3/3     Batch:3650/6968  Loss: 3.6679057121276855\n",
      "\n",
      "Epoch:    3/3     Batch:3655/6968  Loss: 3.544520616531372\n",
      "\n",
      "Epoch:    3/3     Batch:3660/6968  Loss: 3.6472604751586912\n",
      "\n",
      "Epoch:    3/3     Batch:3665/6968  Loss: 3.6934628963470457\n",
      "\n",
      "Epoch:    3/3     Batch:3670/6968  Loss: 3.5229076385498046\n",
      "\n",
      "Epoch:    3/3     Batch:3675/6968  Loss: 3.5524731636047364\n",
      "\n",
      "Epoch:    3/3     Batch:3680/6968  Loss: 3.5427684783935547\n",
      "\n",
      "Epoch:    3/3     Batch:3685/6968  Loss: 3.7039185523986817\n",
      "\n",
      "Epoch:    3/3     Batch:3690/6968  Loss: 3.580696153640747\n",
      "\n",
      "Epoch:    3/3     Batch:3695/6968  Loss: 3.48535099029541\n",
      "\n",
      "Epoch:    3/3     Batch:3700/6968  Loss: 3.646078014373779\n",
      "\n",
      "Epoch:    3/3     Batch:3705/6968  Loss: 3.660914897918701\n",
      "\n",
      "Epoch:    3/3     Batch:3710/6968  Loss: 3.480331373214722\n",
      "\n",
      "Epoch:    3/3     Batch:3715/6968  Loss: 3.5173453807830812\n",
      "\n",
      "Epoch:    3/3     Batch:3720/6968  Loss: 3.4890220165252686\n",
      "\n",
      "Epoch:    3/3     Batch:3725/6968  Loss: 3.6026473522186278\n",
      "\n",
      "Epoch:    3/3     Batch:3730/6968  Loss: 3.5607156276702883\n",
      "\n",
      "Epoch:    3/3     Batch:3735/6968  Loss: 3.513111925125122\n",
      "\n",
      "Epoch:    3/3     Batch:3740/6968  Loss: 3.672521162033081\n",
      "\n",
      "Epoch:    3/3     Batch:3745/6968  Loss: 3.7126757144927978\n",
      "\n",
      "Epoch:    3/3     Batch:3750/6968  Loss: 3.3512585163116455\n",
      "\n",
      "Epoch:    3/3     Batch:3755/6968  Loss: 3.63806209564209\n",
      "\n",
      "Epoch:    3/3     Batch:3760/6968  Loss: 3.886063241958618\n",
      "\n",
      "Epoch:    3/3     Batch:3765/6968  Loss: 3.602423095703125\n",
      "\n",
      "Epoch:    3/3     Batch:3770/6968  Loss: 3.591753911972046\n",
      "\n",
      "Epoch:    3/3     Batch:3775/6968  Loss: 3.418229913711548\n",
      "\n",
      "Epoch:    3/3     Batch:3780/6968  Loss: 3.6254233837127687\n",
      "\n",
      "Epoch:    3/3     Batch:3785/6968  Loss: 3.5965742111206054\n",
      "\n",
      "Epoch:    3/3     Batch:3790/6968  Loss: 3.6173230171203614\n",
      "\n",
      "Epoch:    3/3     Batch:3795/6968  Loss: 3.526521110534668\n",
      "\n",
      "Epoch:    3/3     Batch:3800/6968  Loss: 3.483789300918579\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    3/3     Batch:3805/6968  Loss: 3.516105794906616\n",
      "\n",
      "Epoch:    3/3     Batch:3810/6968  Loss: 3.5615859508514403\n",
      "\n",
      "Epoch:    3/3     Batch:3815/6968  Loss: 3.622150993347168\n",
      "\n",
      "Epoch:    3/3     Batch:3820/6968  Loss: 3.4164969444274904\n",
      "\n",
      "Epoch:    3/3     Batch:3825/6968  Loss: 3.7825687408447264\n",
      "\n",
      "Epoch:    3/3     Batch:3830/6968  Loss: 3.4014232635498045\n",
      "\n",
      "Epoch:    3/3     Batch:3835/6968  Loss: 3.5481127738952636\n",
      "\n",
      "Epoch:    3/3     Batch:3840/6968  Loss: 3.8250300884246826\n",
      "\n",
      "Epoch:    3/3     Batch:3845/6968  Loss: 3.5524948120117186\n",
      "\n",
      "Epoch:    3/3     Batch:3850/6968  Loss: 3.718459367752075\n",
      "\n",
      "Epoch:    3/3     Batch:3855/6968  Loss: 3.4620334625244142\n",
      "\n",
      "Epoch:    3/3     Batch:3860/6968  Loss: 3.725214433670044\n",
      "\n",
      "Epoch:    3/3     Batch:3865/6968  Loss: 3.649008560180664\n",
      "\n",
      "Epoch:    3/3     Batch:3870/6968  Loss: 3.6269750595092773\n",
      "\n",
      "Epoch:    3/3     Batch:3875/6968  Loss: 3.4563097953796387\n",
      "\n",
      "Epoch:    3/3     Batch:3880/6968  Loss: 3.754635953903198\n",
      "\n",
      "Epoch:    3/3     Batch:3885/6968  Loss: 3.693782663345337\n",
      "\n",
      "Epoch:    3/3     Batch:3890/6968  Loss: 3.490719032287598\n",
      "\n",
      "Epoch:    3/3     Batch:3895/6968  Loss: 3.538039970397949\n",
      "\n",
      "Epoch:    3/3     Batch:3900/6968  Loss: 3.6264771461486816\n",
      "\n",
      "Epoch:    3/3     Batch:3905/6968  Loss: 3.4627048492431642\n",
      "\n",
      "Epoch:    3/3     Batch:3910/6968  Loss: 3.617940092086792\n",
      "\n",
      "Epoch:    3/3     Batch:3915/6968  Loss: 3.5061378955841063\n",
      "\n",
      "Epoch:    3/3     Batch:3920/6968  Loss: 3.5562501907348634\n",
      "\n",
      "Epoch:    3/3     Batch:3925/6968  Loss: 3.621990203857422\n",
      "\n",
      "Epoch:    3/3     Batch:3930/6968  Loss: 3.478279209136963\n",
      "\n",
      "Epoch:    3/3     Batch:3935/6968  Loss: 3.598979425430298\n",
      "\n",
      "Epoch:    3/3     Batch:3940/6968  Loss: 3.747374725341797\n",
      "\n",
      "Epoch:    3/3     Batch:3945/6968  Loss: 3.5050713539123537\n",
      "\n",
      "Epoch:    3/3     Batch:3950/6968  Loss: 3.504789924621582\n",
      "\n",
      "Epoch:    3/3     Batch:3955/6968  Loss: 3.7045828819274904\n",
      "\n",
      "Epoch:    3/3     Batch:3960/6968  Loss: 3.633377933502197\n",
      "\n",
      "Epoch:    3/3     Batch:3965/6968  Loss: 3.79809627532959\n",
      "\n",
      "Epoch:    3/3     Batch:3970/6968  Loss: 3.6202462196350096\n",
      "\n",
      "Epoch:    3/3     Batch:3975/6968  Loss: 3.8678868770599366\n",
      "\n",
      "Epoch:    3/3     Batch:3980/6968  Loss: 3.761996841430664\n",
      "\n",
      "Epoch:    3/3     Batch:3985/6968  Loss: 3.619359254837036\n",
      "\n",
      "Epoch:    3/3     Batch:3990/6968  Loss: 3.498480224609375\n",
      "\n",
      "Epoch:    3/3     Batch:3995/6968  Loss: 3.5688124656677247\n",
      "\n",
      "Epoch:    3/3     Batch:4000/6968  Loss: 3.7494133949279784\n",
      "\n",
      "Epoch:    3/3     Batch:4005/6968  Loss: 3.8231251716613768\n",
      "\n",
      "Epoch:    3/3     Batch:4010/6968  Loss: 3.4950982570648192\n",
      "\n",
      "Epoch:    3/3     Batch:4015/6968  Loss: 3.562273550033569\n",
      "\n",
      "Epoch:    3/3     Batch:4020/6968  Loss: 3.7133626461029055\n",
      "\n",
      "Epoch:    3/3     Batch:4025/6968  Loss: 3.5846285820007324\n",
      "\n",
      "Epoch:    3/3     Batch:4030/6968  Loss: 3.5614667415618895\n",
      "\n",
      "Epoch:    3/3     Batch:4035/6968  Loss: 3.6884644985198975\n",
      "\n",
      "Epoch:    3/3     Batch:4040/6968  Loss: 3.7596436023712156\n",
      "\n",
      "Epoch:    3/3     Batch:4045/6968  Loss: 3.4899003505706787\n",
      "\n",
      "Epoch:    3/3     Batch:4050/6968  Loss: 3.5791388034820555\n",
      "\n",
      "Epoch:    3/3     Batch:4055/6968  Loss: 3.6545542240142823\n",
      "\n",
      "Epoch:    3/3     Batch:4060/6968  Loss: 3.648560619354248\n",
      "\n",
      "Epoch:    3/3     Batch:4065/6968  Loss: 3.550057601928711\n",
      "\n",
      "Epoch:    3/3     Batch:4070/6968  Loss: 3.715237522125244\n",
      "\n",
      "Epoch:    3/3     Batch:4075/6968  Loss: 3.4728227615356446\n",
      "\n",
      "Epoch:    3/3     Batch:4080/6968  Loss: 3.668948602676392\n",
      "\n",
      "Epoch:    3/3     Batch:4085/6968  Loss: 3.781756353378296\n",
      "\n",
      "Epoch:    3/3     Batch:4090/6968  Loss: 3.574663019180298\n",
      "\n",
      "Epoch:    3/3     Batch:4095/6968  Loss: 3.6293309211730955\n",
      "\n",
      "Epoch:    3/3     Batch:4100/6968  Loss: 3.682841920852661\n",
      "\n",
      "Epoch:    3/3     Batch:4105/6968  Loss: 3.33974232673645\n",
      "\n",
      "Epoch:    3/3     Batch:4110/6968  Loss: 3.7407604694366454\n",
      "\n",
      "Epoch:    3/3     Batch:4115/6968  Loss: 3.622526502609253\n",
      "\n",
      "Epoch:    3/3     Batch:4120/6968  Loss: 3.4283890247344972\n",
      "\n",
      "Epoch:    3/3     Batch:4125/6968  Loss: 3.7885568141937256\n",
      "\n",
      "Epoch:    3/3     Batch:4130/6968  Loss: 3.518802309036255\n",
      "\n",
      "Epoch:    3/3     Batch:4135/6968  Loss: 3.553810787200928\n",
      "\n",
      "Epoch:    3/3     Batch:4140/6968  Loss: 3.6058905124664307\n",
      "\n",
      "Epoch:    3/3     Batch:4145/6968  Loss: 3.5380237102508545\n",
      "\n",
      "Epoch:    3/3     Batch:4150/6968  Loss: 3.635217571258545\n",
      "\n",
      "Epoch:    3/3     Batch:4155/6968  Loss: 3.4757153034210204\n",
      "\n",
      "Epoch:    3/3     Batch:4160/6968  Loss: 3.2901304244995115\n",
      "\n",
      "Epoch:    3/3     Batch:4165/6968  Loss: 3.476276731491089\n",
      "\n",
      "Epoch:    3/3     Batch:4170/6968  Loss: 3.513677549362183\n",
      "\n",
      "Epoch:    3/3     Batch:4175/6968  Loss: 3.705467700958252\n",
      "\n",
      "Epoch:    3/3     Batch:4180/6968  Loss: 3.5891165256500246\n",
      "\n",
      "Epoch:    3/3     Batch:4185/6968  Loss: 3.4632379531860353\n",
      "\n",
      "Epoch:    3/3     Batch:4190/6968  Loss: 3.542008304595947\n",
      "\n",
      "Epoch:    3/3     Batch:4195/6968  Loss: 3.4090322971343996\n",
      "\n",
      "Epoch:    3/3     Batch:4200/6968  Loss: 3.5563701152801515\n",
      "\n",
      "Epoch:    3/3     Batch:4205/6968  Loss: 3.68205246925354\n",
      "\n",
      "Epoch:    3/3     Batch:4210/6968  Loss: 3.720448923110962\n",
      "\n",
      "Epoch:    3/3     Batch:4215/6968  Loss: 3.725242185592651\n",
      "\n",
      "Epoch:    3/3     Batch:4220/6968  Loss: 3.6974129676818848\n",
      "\n",
      "Epoch:    3/3     Batch:4225/6968  Loss: 3.428481197357178\n",
      "\n",
      "Epoch:    3/3     Batch:4230/6968  Loss: 3.6099069595336912\n",
      "\n",
      "Epoch:    3/3     Batch:4235/6968  Loss: 3.705243158340454\n",
      "\n",
      "Epoch:    3/3     Batch:4240/6968  Loss: 3.661467742919922\n",
      "\n",
      "Epoch:    3/3     Batch:4245/6968  Loss: 3.5352073669433595\n",
      "\n",
      "Epoch:    3/3     Batch:4250/6968  Loss: 3.728404092788696\n",
      "\n",
      "Epoch:    3/3     Batch:4255/6968  Loss: 3.6151402950286866\n",
      "\n",
      "Epoch:    3/3     Batch:4260/6968  Loss: 3.4341736793518067\n",
      "\n",
      "Epoch:    3/3     Batch:4265/6968  Loss: 3.5520036220550537\n",
      "\n",
      "Epoch:    3/3     Batch:4270/6968  Loss: 3.5312095165252684\n",
      "\n",
      "Epoch:    3/3     Batch:4275/6968  Loss: 3.5336846828460695\n",
      "\n",
      "Epoch:    3/3     Batch:4280/6968  Loss: 3.6742236614227295\n",
      "\n",
      "Epoch:    3/3     Batch:4285/6968  Loss: 3.633197021484375\n",
      "\n",
      "Epoch:    3/3     Batch:4290/6968  Loss: 3.5543671607971192\n",
      "\n",
      "Epoch:    3/3     Batch:4295/6968  Loss: 3.69761176109314\n",
      "\n",
      "Epoch:    3/3     Batch:4300/6968  Loss: 3.7001654624938967\n",
      "\n",
      "Epoch:    3/3     Batch:4305/6968  Loss: 3.6289586544036867\n",
      "\n",
      "Epoch:    3/3     Batch:4310/6968  Loss: 3.8485114574432373\n",
      "\n",
      "Epoch:    3/3     Batch:4315/6968  Loss: 3.6317562103271483\n",
      "\n",
      "Epoch:    3/3     Batch:4320/6968  Loss: 3.547183895111084\n",
      "\n",
      "Epoch:    3/3     Batch:4325/6968  Loss: 3.496568965911865\n",
      "\n",
      "Epoch:    3/3     Batch:4330/6968  Loss: 3.423158359527588\n",
      "\n",
      "Epoch:    3/3     Batch:4335/6968  Loss: 3.664911413192749\n",
      "\n",
      "Epoch:    3/3     Batch:4340/6968  Loss: 3.584698724746704\n",
      "\n",
      "Epoch:    3/3     Batch:4345/6968  Loss: 3.7585263729095457\n",
      "\n",
      "Epoch:    3/3     Batch:4350/6968  Loss: 3.328691816329956\n",
      "\n",
      "Epoch:    3/3     Batch:4355/6968  Loss: 3.692028284072876\n",
      "\n",
      "Epoch:    3/3     Batch:4360/6968  Loss: 3.635530376434326\n",
      "\n",
      "Epoch:    3/3     Batch:4365/6968  Loss: 3.678899621963501\n",
      "\n",
      "Epoch:    3/3     Batch:4370/6968  Loss: 3.560862350463867\n",
      "\n",
      "Epoch:    3/3     Batch:4375/6968  Loss: 3.6977274417877197\n",
      "\n",
      "Epoch:    3/3     Batch:4380/6968  Loss: 3.4733092308044435\n",
      "\n",
      "Epoch:    3/3     Batch:4385/6968  Loss: 3.4946024417877197\n",
      "\n",
      "Epoch:    3/3     Batch:4390/6968  Loss: 3.6448435306549074\n",
      "\n",
      "Epoch:    3/3     Batch:4395/6968  Loss: 3.6630787372589113\n",
      "\n",
      "Epoch:    3/3     Batch:4400/6968  Loss: 3.665585470199585\n",
      "\n",
      "Epoch:    3/3     Batch:4405/6968  Loss: 3.4751241207122803\n",
      "\n",
      "Epoch:    3/3     Batch:4410/6968  Loss: 3.6420404434204103\n",
      "\n",
      "Epoch:    3/3     Batch:4415/6968  Loss: 3.599849224090576\n",
      "\n",
      "Epoch:    3/3     Batch:4420/6968  Loss: 3.7799540519714356\n",
      "\n",
      "Epoch:    3/3     Batch:4425/6968  Loss: 3.5461543560028077\n",
      "\n",
      "Epoch:    3/3     Batch:4430/6968  Loss: 3.6282143115997316\n",
      "\n",
      "Epoch:    3/3     Batch:4435/6968  Loss: 3.6483551025390626\n",
      "\n",
      "Epoch:    3/3     Batch:4440/6968  Loss: 3.60914888381958\n",
      "\n",
      "Epoch:    3/3     Batch:4445/6968  Loss: 3.6934308052062987\n",
      "\n",
      "Epoch:    3/3     Batch:4450/6968  Loss: 3.6006561756134032\n",
      "\n",
      "Epoch:    3/3     Batch:4455/6968  Loss: 3.5950546264648438\n",
      "\n",
      "Epoch:    3/3     Batch:4460/6968  Loss: 3.8073122024536135\n",
      "\n",
      "Epoch:    3/3     Batch:4465/6968  Loss: 3.7119017124176024\n",
      "\n",
      "Epoch:    3/3     Batch:4470/6968  Loss: 3.6672450065612794\n",
      "\n",
      "Epoch:    3/3     Batch:4475/6968  Loss: 3.664834499359131\n",
      "\n",
      "Epoch:    3/3     Batch:4480/6968  Loss: 3.5816107749938966\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    3/3     Batch:4485/6968  Loss: 3.7091485023498536\n",
      "\n",
      "Epoch:    3/3     Batch:4490/6968  Loss: 3.529189205169678\n",
      "\n",
      "Epoch:    3/3     Batch:4495/6968  Loss: 3.7070430278778077\n",
      "\n",
      "Epoch:    3/3     Batch:4500/6968  Loss: 3.6006863594055174\n",
      "\n",
      "Epoch:    3/3     Batch:4505/6968  Loss: 3.5809555530548094\n",
      "\n",
      "Epoch:    3/3     Batch:4510/6968  Loss: 3.5379905223846437\n",
      "\n",
      "Epoch:    3/3     Batch:4515/6968  Loss: 3.5710799217224123\n",
      "\n",
      "Epoch:    3/3     Batch:4520/6968  Loss: 3.5275697231292726\n",
      "\n",
      "Epoch:    3/3     Batch:4525/6968  Loss: 3.7378358364105226\n",
      "\n",
      "Epoch:    3/3     Batch:4530/6968  Loss: 3.5000651359558104\n",
      "\n",
      "Epoch:    3/3     Batch:4535/6968  Loss: 3.4865933418273927\n",
      "\n",
      "Epoch:    3/3     Batch:4540/6968  Loss: 3.5203099727630613\n",
      "\n",
      "Epoch:    3/3     Batch:4545/6968  Loss: 3.5060737133026123\n",
      "\n",
      "Epoch:    3/3     Batch:4550/6968  Loss: 3.568225383758545\n",
      "\n",
      "Epoch:    3/3     Batch:4555/6968  Loss: 3.57031135559082\n",
      "\n",
      "Epoch:    3/3     Batch:4560/6968  Loss: 3.377719593048096\n",
      "\n",
      "Epoch:    3/3     Batch:4565/6968  Loss: 3.5870011329650877\n",
      "\n",
      "Epoch:    3/3     Batch:4570/6968  Loss: 3.673524522781372\n",
      "\n",
      "Epoch:    3/3     Batch:4575/6968  Loss: 3.7729642391204834\n",
      "\n",
      "Epoch:    3/3     Batch:4580/6968  Loss: 3.4943015575408936\n",
      "\n",
      "Epoch:    3/3     Batch:4585/6968  Loss: 3.686891508102417\n",
      "\n",
      "Epoch:    3/3     Batch:4590/6968  Loss: 3.310944652557373\n",
      "\n",
      "Epoch:    3/3     Batch:4595/6968  Loss: 3.5955299377441405\n",
      "\n",
      "Epoch:    3/3     Batch:4600/6968  Loss: 3.685213232040405\n",
      "\n",
      "Epoch:    3/3     Batch:4605/6968  Loss: 3.5634320259094237\n",
      "\n",
      "Epoch:    3/3     Batch:4610/6968  Loss: 3.5645034313201904\n",
      "\n",
      "Epoch:    3/3     Batch:4615/6968  Loss: 3.8078535556793214\n",
      "\n",
      "Epoch:    3/3     Batch:4620/6968  Loss: 3.6332735061645507\n",
      "\n",
      "Epoch:    3/3     Batch:4625/6968  Loss: 3.57671856880188\n",
      "\n",
      "Epoch:    3/3     Batch:4630/6968  Loss: 3.65452299118042\n",
      "\n",
      "Epoch:    3/3     Batch:4635/6968  Loss: 3.6706946849823\n",
      "\n",
      "Epoch:    3/3     Batch:4640/6968  Loss: 3.537838268280029\n",
      "\n",
      "Epoch:    3/3     Batch:4645/6968  Loss: 3.4696147441864014\n",
      "\n",
      "Epoch:    3/3     Batch:4650/6968  Loss: 3.5052262783050536\n",
      "\n",
      "Epoch:    3/3     Batch:4655/6968  Loss: 3.683149290084839\n",
      "\n",
      "Epoch:    3/3     Batch:4660/6968  Loss: 3.62627534866333\n",
      "\n",
      "Epoch:    3/3     Batch:4665/6968  Loss: 3.5731121063232423\n",
      "\n",
      "Epoch:    3/3     Batch:4670/6968  Loss: 3.5288328170776366\n",
      "\n",
      "Epoch:    3/3     Batch:4675/6968  Loss: 3.7307040214538576\n",
      "\n",
      "Epoch:    3/3     Batch:4680/6968  Loss: 3.6811550140380858\n",
      "\n",
      "Epoch:    3/3     Batch:4685/6968  Loss: 3.6665673732757567\n",
      "\n",
      "Epoch:    3/3     Batch:4690/6968  Loss: 3.665397787094116\n",
      "\n",
      "Epoch:    3/3     Batch:4695/6968  Loss: 3.6315502643585207\n",
      "\n",
      "Epoch:    3/3     Batch:4700/6968  Loss: 3.7055568218231203\n",
      "\n",
      "Epoch:    3/3     Batch:4705/6968  Loss: 3.5759215354919434\n",
      "\n",
      "Epoch:    3/3     Batch:4710/6968  Loss: 3.7140908241271973\n",
      "\n",
      "Epoch:    3/3     Batch:4715/6968  Loss: 3.6815345764160154\n",
      "\n",
      "Epoch:    3/3     Batch:4720/6968  Loss: 3.3841885566711425\n",
      "\n",
      "Epoch:    3/3     Batch:4725/6968  Loss: 3.618095302581787\n",
      "\n",
      "Epoch:    3/3     Batch:4730/6968  Loss: 3.636075162887573\n",
      "\n",
      "Epoch:    3/3     Batch:4735/6968  Loss: 3.606911277770996\n",
      "\n",
      "Epoch:    3/3     Batch:4740/6968  Loss: 3.643028163909912\n",
      "\n",
      "Epoch:    3/3     Batch:4745/6968  Loss: 3.7113117218017577\n",
      "\n",
      "Epoch:    3/3     Batch:4750/6968  Loss: 3.5733245849609374\n",
      "\n",
      "Epoch:    3/3     Batch:4755/6968  Loss: 3.8233824253082274\n",
      "\n",
      "Epoch:    3/3     Batch:4760/6968  Loss: 3.5463449001312255\n",
      "\n",
      "Epoch:    3/3     Batch:4765/6968  Loss: 3.874242639541626\n",
      "\n",
      "Epoch:    3/3     Batch:4770/6968  Loss: 3.6675832271575928\n",
      "\n",
      "Epoch:    3/3     Batch:4775/6968  Loss: 3.529335927963257\n",
      "\n",
      "Epoch:    3/3     Batch:4780/6968  Loss: 3.526708745956421\n",
      "\n",
      "Epoch:    3/3     Batch:4785/6968  Loss: 3.4706250190734864\n",
      "\n",
      "Epoch:    3/3     Batch:4790/6968  Loss: 3.477876663208008\n",
      "\n",
      "Epoch:    3/3     Batch:4795/6968  Loss: 3.611967897415161\n",
      "\n",
      "Epoch:    3/3     Batch:4800/6968  Loss: 3.6119131088256835\n",
      "\n",
      "Epoch:    3/3     Batch:4805/6968  Loss: 3.435998010635376\n",
      "\n",
      "Epoch:    3/3     Batch:4810/6968  Loss: 3.5148961544036865\n",
      "\n",
      "Epoch:    3/3     Batch:4815/6968  Loss: 3.5023804187774656\n",
      "\n",
      "Epoch:    3/3     Batch:4820/6968  Loss: 3.6169644832611083\n",
      "\n",
      "Epoch:    3/3     Batch:4825/6968  Loss: 3.453701972961426\n",
      "\n",
      "Epoch:    3/3     Batch:4830/6968  Loss: 3.610056257247925\n",
      "\n",
      "Epoch:    3/3     Batch:4835/6968  Loss: 3.405136966705322\n",
      "\n",
      "Epoch:    3/3     Batch:4840/6968  Loss: 3.5479094982147217\n",
      "\n",
      "Epoch:    3/3     Batch:4845/6968  Loss: 3.527291774749756\n",
      "\n",
      "Epoch:    3/3     Batch:4850/6968  Loss: 3.551603651046753\n",
      "\n",
      "Epoch:    3/3     Batch:4855/6968  Loss: 3.6074872970581056\n",
      "\n",
      "Epoch:    3/3     Batch:4860/6968  Loss: 3.5247980117797852\n",
      "\n",
      "Epoch:    3/3     Batch:4865/6968  Loss: 3.72986159324646\n",
      "\n",
      "Epoch:    3/3     Batch:4870/6968  Loss: 3.315230894088745\n",
      "\n",
      "Epoch:    3/3     Batch:4875/6968  Loss: 3.553574228286743\n",
      "\n",
      "Epoch:    3/3     Batch:4880/6968  Loss: 3.7547606945037844\n",
      "\n",
      "Epoch:    3/3     Batch:4885/6968  Loss: 3.6483230590820312\n",
      "\n",
      "Epoch:    3/3     Batch:4890/6968  Loss: 3.4691073894500732\n",
      "\n",
      "Epoch:    3/3     Batch:4895/6968  Loss: 3.613467788696289\n",
      "\n",
      "Epoch:    3/3     Batch:4900/6968  Loss: 3.565038871765137\n",
      "\n",
      "Epoch:    3/3     Batch:4905/6968  Loss: 3.4614863872528074\n",
      "\n",
      "Epoch:    3/3     Batch:4910/6968  Loss: 3.604955768585205\n",
      "\n",
      "Epoch:    3/3     Batch:4915/6968  Loss: 3.5411962985992433\n",
      "\n",
      "Epoch:    3/3     Batch:4920/6968  Loss: 3.652792501449585\n",
      "\n",
      "Epoch:    3/3     Batch:4925/6968  Loss: 3.537481594085693\n",
      "\n",
      "Epoch:    3/3     Batch:4930/6968  Loss: 3.6593500137329102\n",
      "\n",
      "Epoch:    3/3     Batch:4935/6968  Loss: 3.466273307800293\n",
      "\n",
      "Epoch:    3/3     Batch:4940/6968  Loss: 3.614671993255615\n",
      "\n",
      "Epoch:    3/3     Batch:4945/6968  Loss: 3.7663851737976075\n",
      "\n",
      "Epoch:    3/3     Batch:4950/6968  Loss: 3.5640044689178465\n",
      "\n",
      "Epoch:    3/3     Batch:4955/6968  Loss: 3.8429336071014406\n",
      "\n",
      "Epoch:    3/3     Batch:4960/6968  Loss: 3.3543606758117677\n",
      "\n",
      "Epoch:    3/3     Batch:4965/6968  Loss: 3.6566335678100588\n",
      "\n",
      "Epoch:    3/3     Batch:4970/6968  Loss: 3.6682459831237795\n",
      "\n",
      "Epoch:    3/3     Batch:4975/6968  Loss: 3.6763601779937742\n",
      "\n",
      "Epoch:    3/3     Batch:4980/6968  Loss: 3.5933917999267577\n",
      "\n",
      "Epoch:    3/3     Batch:4985/6968  Loss: 3.763929748535156\n",
      "\n",
      "Epoch:    3/3     Batch:4990/6968  Loss: 3.741703510284424\n",
      "\n",
      "Epoch:    3/3     Batch:4995/6968  Loss: 3.5508100509643556\n",
      "\n",
      "Epoch:    3/3     Batch:5000/6968  Loss: 3.593087673187256\n",
      "\n",
      "Epoch:    3/3     Batch:5005/6968  Loss: 3.7251715660095215\n",
      "\n",
      "Epoch:    3/3     Batch:5010/6968  Loss: 3.392595624923706\n",
      "\n",
      "Epoch:    3/3     Batch:5015/6968  Loss: 3.7157729148864744\n",
      "\n",
      "Epoch:    3/3     Batch:5020/6968  Loss: 3.4439416885375977\n",
      "\n",
      "Epoch:    3/3     Batch:5025/6968  Loss: 3.926988887786865\n",
      "\n",
      "Epoch:    3/3     Batch:5030/6968  Loss: 3.6096896171569823\n",
      "\n",
      "Epoch:    3/3     Batch:5035/6968  Loss: 3.6001843929290773\n",
      "\n",
      "Epoch:    3/3     Batch:5040/6968  Loss: 3.5730932712554933\n",
      "\n",
      "Epoch:    3/3     Batch:5045/6968  Loss: 3.6403692245483397\n",
      "\n",
      "Epoch:    3/3     Batch:5050/6968  Loss: 3.751398706436157\n",
      "\n",
      "Epoch:    3/3     Batch:5055/6968  Loss: 3.6894530773162844\n",
      "\n",
      "Epoch:    3/3     Batch:5060/6968  Loss: 3.5338319301605225\n",
      "\n",
      "Epoch:    3/3     Batch:5065/6968  Loss: 3.71775426864624\n",
      "\n",
      "Epoch:    3/3     Batch:5070/6968  Loss: 3.576842451095581\n",
      "\n",
      "Epoch:    3/3     Batch:5075/6968  Loss: 3.564582347869873\n",
      "\n",
      "Epoch:    3/3     Batch:5080/6968  Loss: 3.693761920928955\n",
      "\n",
      "Epoch:    3/3     Batch:5085/6968  Loss: 3.772764205932617\n",
      "\n",
      "Epoch:    3/3     Batch:5090/6968  Loss: 3.6677650451660155\n",
      "\n",
      "Epoch:    3/3     Batch:5095/6968  Loss: 3.599368381500244\n",
      "\n",
      "Epoch:    3/3     Batch:5100/6968  Loss: 3.639881944656372\n",
      "\n",
      "Epoch:    3/3     Batch:5105/6968  Loss: 3.543026161193848\n",
      "\n",
      "Epoch:    3/3     Batch:5110/6968  Loss: 3.7259326457977293\n",
      "\n",
      "Epoch:    3/3     Batch:5115/6968  Loss: 3.4918564319610597\n",
      "\n",
      "Epoch:    3/3     Batch:5120/6968  Loss: 3.6197478771209717\n",
      "\n",
      "Epoch:    3/3     Batch:5125/6968  Loss: 3.4838018894195555\n",
      "\n",
      "Epoch:    3/3     Batch:5130/6968  Loss: 3.5031685829162598\n",
      "\n",
      "Epoch:    3/3     Batch:5135/6968  Loss: 3.6743183612823485\n",
      "\n",
      "Epoch:    3/3     Batch:5140/6968  Loss: 3.645981550216675\n",
      "\n",
      "Epoch:    3/3     Batch:5145/6968  Loss: 3.536047840118408\n",
      "\n",
      "Epoch:    3/3     Batch:5150/6968  Loss: 3.55196795463562\n",
      "\n",
      "Epoch:    3/3     Batch:5155/6968  Loss: 3.58213472366333\n",
      "\n",
      "Epoch:    3/3     Batch:5160/6968  Loss: 3.68381404876709\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    3/3     Batch:5165/6968  Loss: 3.6839279174804687\n",
      "\n",
      "Epoch:    3/3     Batch:5170/6968  Loss: 3.3830214500427247\n",
      "\n",
      "Epoch:    3/3     Batch:5175/6968  Loss: 3.606970024108887\n",
      "\n",
      "Epoch:    3/3     Batch:5180/6968  Loss: 3.6893571853637694\n",
      "\n",
      "Epoch:    3/3     Batch:5185/6968  Loss: 3.4656761646270753\n",
      "\n",
      "Epoch:    3/3     Batch:5190/6968  Loss: 3.4868828296661376\n",
      "\n",
      "Epoch:    3/3     Batch:5195/6968  Loss: 3.404055452346802\n",
      "\n",
      "Epoch:    3/3     Batch:5200/6968  Loss: 3.4418720245361327\n",
      "\n",
      "Epoch:    3/3     Batch:5205/6968  Loss: 3.6551002979278566\n",
      "\n",
      "Epoch:    3/3     Batch:5210/6968  Loss: 3.5998230934143067\n",
      "\n",
      "Epoch:    3/3     Batch:5215/6968  Loss: 3.57011022567749\n",
      "\n",
      "Epoch:    3/3     Batch:5220/6968  Loss: 3.616094636917114\n",
      "\n",
      "Epoch:    3/3     Batch:5225/6968  Loss: 3.7826910495758055\n",
      "\n",
      "Epoch:    3/3     Batch:5230/6968  Loss: 3.623262310028076\n",
      "\n",
      "Epoch:    3/3     Batch:5235/6968  Loss: 3.6759397983551025\n",
      "\n",
      "Epoch:    3/3     Batch:5240/6968  Loss: 3.655489778518677\n",
      "\n",
      "Epoch:    3/3     Batch:5245/6968  Loss: 3.5090775966644285\n",
      "\n",
      "Epoch:    3/3     Batch:5250/6968  Loss: 3.841588354110718\n",
      "\n",
      "Epoch:    3/3     Batch:5255/6968  Loss: 3.4936942577362062\n",
      "\n",
      "Epoch:    3/3     Batch:5260/6968  Loss: 3.6084354400634764\n",
      "\n",
      "Epoch:    3/3     Batch:5265/6968  Loss: 3.509359884262085\n",
      "\n",
      "Epoch:    3/3     Batch:5270/6968  Loss: 3.5351954460144044\n",
      "\n",
      "Epoch:    3/3     Batch:5275/6968  Loss: 3.553805446624756\n",
      "\n",
      "Epoch:    3/3     Batch:5280/6968  Loss: 3.729556179046631\n",
      "\n",
      "Epoch:    3/3     Batch:5285/6968  Loss: 3.7700767517089844\n",
      "\n",
      "Epoch:    3/3     Batch:5290/6968  Loss: 3.701549768447876\n",
      "\n",
      "Epoch:    3/3     Batch:5295/6968  Loss: 3.559422826766968\n",
      "\n",
      "Epoch:    3/3     Batch:5300/6968  Loss: 3.5492275238037108\n",
      "\n",
      "Epoch:    3/3     Batch:5305/6968  Loss: 3.6003699779510496\n",
      "\n",
      "Epoch:    3/3     Batch:5310/6968  Loss: 3.564942216873169\n",
      "\n",
      "Epoch:    3/3     Batch:5315/6968  Loss: 3.599802303314209\n",
      "\n",
      "Epoch:    3/3     Batch:5320/6968  Loss: 3.56340913772583\n",
      "\n",
      "Epoch:    3/3     Batch:5325/6968  Loss: 3.6118536949157716\n",
      "\n",
      "Epoch:    3/3     Batch:5330/6968  Loss: 3.795608329772949\n",
      "\n",
      "Epoch:    3/3     Batch:5335/6968  Loss: 3.551668882369995\n",
      "\n",
      "Epoch:    3/3     Batch:5340/6968  Loss: 3.7584314346313477\n",
      "\n",
      "Epoch:    3/3     Batch:5345/6968  Loss: 3.5525902271270753\n",
      "\n",
      "Epoch:    3/3     Batch:5350/6968  Loss: 3.6976129055023192\n",
      "\n",
      "Epoch:    3/3     Batch:5355/6968  Loss: 3.720607376098633\n",
      "\n",
      "Epoch:    3/3     Batch:5360/6968  Loss: 3.500351619720459\n",
      "\n",
      "Epoch:    3/3     Batch:5365/6968  Loss: 3.481164646148682\n",
      "\n",
      "Epoch:    3/3     Batch:5370/6968  Loss: 3.51310772895813\n",
      "\n",
      "Epoch:    3/3     Batch:5375/6968  Loss: 3.6596792697906495\n",
      "\n",
      "Epoch:    3/3     Batch:5380/6968  Loss: 3.499063777923584\n",
      "\n",
      "Epoch:    3/3     Batch:5385/6968  Loss: 3.342266893386841\n",
      "\n",
      "Epoch:    3/3     Batch:5390/6968  Loss: 3.54523606300354\n",
      "\n",
      "Epoch:    3/3     Batch:5395/6968  Loss: 3.447238492965698\n",
      "\n",
      "Epoch:    3/3     Batch:5400/6968  Loss: 3.3882330417633058\n",
      "\n",
      "Epoch:    3/3     Batch:5405/6968  Loss: 3.6393910884857177\n",
      "\n",
      "Epoch:    3/3     Batch:5410/6968  Loss: 3.546040105819702\n",
      "\n",
      "Epoch:    3/3     Batch:5415/6968  Loss: 3.4887773036956786\n",
      "\n",
      "Epoch:    3/3     Batch:5420/6968  Loss: 3.5729186058044435\n",
      "\n",
      "Epoch:    3/3     Batch:5425/6968  Loss: 3.717646265029907\n",
      "\n",
      "Epoch:    3/3     Batch:5430/6968  Loss: 3.6966418266296386\n",
      "\n",
      "Epoch:    3/3     Batch:5435/6968  Loss: 3.674750566482544\n",
      "\n",
      "Epoch:    3/3     Batch:5440/6968  Loss: 3.697106647491455\n",
      "\n",
      "Epoch:    3/3     Batch:5445/6968  Loss: 3.7141032218933105\n",
      "\n",
      "Epoch:    3/3     Batch:5450/6968  Loss: 3.5591814041137697\n",
      "\n",
      "Epoch:    3/3     Batch:5455/6968  Loss: 3.593597173690796\n",
      "\n",
      "Epoch:    3/3     Batch:5460/6968  Loss: 3.6875452041625976\n",
      "\n",
      "Epoch:    3/3     Batch:5465/6968  Loss: 3.5740158557891846\n",
      "\n",
      "Epoch:    3/3     Batch:5470/6968  Loss: 3.6852156639099123\n",
      "\n",
      "Epoch:    3/3     Batch:5475/6968  Loss: 3.686179685592651\n",
      "\n",
      "Epoch:    3/3     Batch:5480/6968  Loss: 3.728145790100098\n",
      "\n",
      "Epoch:    3/3     Batch:5485/6968  Loss: 3.6160727977752685\n",
      "\n",
      "Epoch:    3/3     Batch:5490/6968  Loss: 3.467766761779785\n",
      "\n",
      "Epoch:    3/3     Batch:5495/6968  Loss: 3.745930814743042\n",
      "\n",
      "Epoch:    3/3     Batch:5500/6968  Loss: 3.51411509513855\n",
      "\n",
      "Epoch:    3/3     Batch:5505/6968  Loss: 3.5792590141296388\n",
      "\n",
      "Epoch:    3/3     Batch:5510/6968  Loss: 3.6624489307403563\n",
      "\n",
      "Epoch:    3/3     Batch:5515/6968  Loss: 3.48065071105957\n",
      "\n",
      "Epoch:    3/3     Batch:5520/6968  Loss: 3.1843752384185793\n",
      "\n",
      "Epoch:    3/3     Batch:5525/6968  Loss: 3.807913875579834\n",
      "\n",
      "Epoch:    3/3     Batch:5530/6968  Loss: 3.6224785327911375\n",
      "\n",
      "Epoch:    3/3     Batch:5535/6968  Loss: 3.49833722114563\n",
      "\n",
      "Epoch:    3/3     Batch:5540/6968  Loss: 3.7843934059143067\n",
      "\n",
      "Epoch:    3/3     Batch:5545/6968  Loss: 3.567514419555664\n",
      "\n",
      "Epoch:    3/3     Batch:5550/6968  Loss: 3.604648208618164\n",
      "\n",
      "Epoch:    3/3     Batch:5555/6968  Loss: 3.8799232006073\n",
      "\n",
      "Epoch:    3/3     Batch:5560/6968  Loss: 3.540267562866211\n",
      "\n",
      "Epoch:    3/3     Batch:5565/6968  Loss: 3.691546010971069\n",
      "\n",
      "Epoch:    3/3     Batch:5570/6968  Loss: 3.5680264949798586\n",
      "\n",
      "Epoch:    3/3     Batch:5575/6968  Loss: 3.6552701950073243\n",
      "\n",
      "Epoch:    3/3     Batch:5580/6968  Loss: 3.5579567909240724\n",
      "\n",
      "Epoch:    3/3     Batch:5585/6968  Loss: 3.5279350757598875\n",
      "\n",
      "Epoch:    3/3     Batch:5590/6968  Loss: 3.5102454662322997\n",
      "\n",
      "Epoch:    3/3     Batch:5595/6968  Loss: 3.5638191223144533\n",
      "\n",
      "Epoch:    3/3     Batch:5600/6968  Loss: 3.8738383769989015\n",
      "\n",
      "Epoch:    3/3     Batch:5605/6968  Loss: 3.901649761199951\n",
      "\n",
      "Epoch:    3/3     Batch:5610/6968  Loss: 3.587859582901001\n",
      "\n",
      "Epoch:    3/3     Batch:5615/6968  Loss: 3.593744421005249\n",
      "\n",
      "Epoch:    3/3     Batch:5620/6968  Loss: 3.4886621952056887\n",
      "\n",
      "Epoch:    3/3     Batch:5625/6968  Loss: 3.4283088207244874\n",
      "\n",
      "Epoch:    3/3     Batch:5630/6968  Loss: 3.7430131912231444\n",
      "\n",
      "Epoch:    3/3     Batch:5635/6968  Loss: 3.626735973358154\n",
      "\n",
      "Epoch:    3/3     Batch:5640/6968  Loss: 3.6423104763031007\n",
      "\n",
      "Epoch:    3/3     Batch:5645/6968  Loss: 3.5848732948303224\n",
      "\n",
      "Epoch:    3/3     Batch:5650/6968  Loss: 3.529042100906372\n",
      "\n",
      "Epoch:    3/3     Batch:5655/6968  Loss: 3.539984846115112\n",
      "\n",
      "Epoch:    3/3     Batch:5660/6968  Loss: 3.724641799926758\n",
      "\n",
      "Epoch:    3/3     Batch:5665/6968  Loss: 3.629345941543579\n",
      "\n",
      "Epoch:    3/3     Batch:5670/6968  Loss: 3.4853658199310305\n",
      "\n",
      "Epoch:    3/3     Batch:5675/6968  Loss: 3.4999840259552\n",
      "\n",
      "Epoch:    3/3     Batch:5680/6968  Loss: 3.620179796218872\n",
      "\n",
      "Epoch:    3/3     Batch:5685/6968  Loss: 3.6764196872711183\n",
      "\n",
      "Epoch:    3/3     Batch:5690/6968  Loss: 3.7750222206115724\n",
      "\n",
      "Epoch:    3/3     Batch:5695/6968  Loss: 3.5396857261657715\n",
      "\n",
      "Epoch:    3/3     Batch:5700/6968  Loss: 3.495248031616211\n",
      "\n",
      "Epoch:    3/3     Batch:5705/6968  Loss: 3.418088674545288\n",
      "\n",
      "Epoch:    3/3     Batch:5710/6968  Loss: 3.7014207363128664\n",
      "\n",
      "Epoch:    3/3     Batch:5715/6968  Loss: 3.462440919876099\n",
      "\n",
      "Epoch:    3/3     Batch:5720/6968  Loss: 3.632744312286377\n",
      "\n",
      "Epoch:    3/3     Batch:5725/6968  Loss: 3.5935405254364015\n",
      "\n",
      "Epoch:    3/3     Batch:5730/6968  Loss: 3.7224884033203125\n",
      "\n",
      "Epoch:    3/3     Batch:5735/6968  Loss: 3.664026069641113\n",
      "\n",
      "Epoch:    3/3     Batch:5740/6968  Loss: 3.632951498031616\n",
      "\n",
      "Epoch:    3/3     Batch:5745/6968  Loss: 3.698374128341675\n",
      "\n",
      "Epoch:    3/3     Batch:5750/6968  Loss: 3.5183319568634035\n",
      "\n",
      "Epoch:    3/3     Batch:5755/6968  Loss: 3.6378316402435305\n",
      "\n",
      "Epoch:    3/3     Batch:5760/6968  Loss: 3.3823184967041016\n",
      "\n",
      "Epoch:    3/3     Batch:5765/6968  Loss: 3.617667865753174\n",
      "\n",
      "Epoch:    3/3     Batch:5770/6968  Loss: 3.5116891384124758\n",
      "\n",
      "Epoch:    3/3     Batch:5775/6968  Loss: 3.639150619506836\n",
      "\n",
      "Epoch:    3/3     Batch:5780/6968  Loss: 3.443907356262207\n",
      "\n",
      "Epoch:    3/3     Batch:5785/6968  Loss: 3.4696303367614747\n",
      "\n",
      "Epoch:    3/3     Batch:5790/6968  Loss: 3.710811710357666\n",
      "\n",
      "Epoch:    3/3     Batch:5795/6968  Loss: 3.6983147144317625\n",
      "\n",
      "Epoch:    3/3     Batch:5800/6968  Loss: 3.7596529483795167\n",
      "\n",
      "Epoch:    3/3     Batch:5805/6968  Loss: 3.5217652797698973\n",
      "\n",
      "Epoch:    3/3     Batch:5810/6968  Loss: 3.6408583164215087\n",
      "\n",
      "Epoch:    3/3     Batch:5815/6968  Loss: 3.5213061332702638\n",
      "\n",
      "Epoch:    3/3     Batch:5820/6968  Loss: 3.4972071170806887\n",
      "\n",
      "Epoch:    3/3     Batch:5825/6968  Loss: 3.508717918395996\n",
      "\n",
      "Epoch:    3/3     Batch:5830/6968  Loss: 3.5477914333343508\n",
      "\n",
      "Epoch:    3/3     Batch:5835/6968  Loss: 3.7799729824066164\n",
      "\n",
      "Epoch:    3/3     Batch:5840/6968  Loss: 3.6715183734893797\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    3/3     Batch:5845/6968  Loss: 3.7006557464599608\n",
      "\n",
      "Epoch:    3/3     Batch:5850/6968  Loss: 3.5943041324615477\n",
      "\n",
      "Epoch:    3/3     Batch:5855/6968  Loss: 3.503140115737915\n",
      "\n",
      "Epoch:    3/3     Batch:5860/6968  Loss: 3.591386604309082\n",
      "\n",
      "Epoch:    3/3     Batch:5865/6968  Loss: 3.5006507396698\n",
      "\n",
      "Epoch:    3/3     Batch:5870/6968  Loss: 3.637872409820557\n",
      "\n",
      "Epoch:    3/3     Batch:5875/6968  Loss: 3.707839012145996\n",
      "\n",
      "Epoch:    3/3     Batch:5880/6968  Loss: 3.2679510593414305\n",
      "\n",
      "Epoch:    3/3     Batch:5885/6968  Loss: 3.676378917694092\n",
      "\n",
      "Epoch:    3/3     Batch:5890/6968  Loss: 3.6293718338012697\n",
      "\n",
      "Epoch:    3/3     Batch:5895/6968  Loss: 3.4220908164978026\n",
      "\n",
      "Epoch:    3/3     Batch:5900/6968  Loss: 3.510081100463867\n",
      "\n",
      "Epoch:    3/3     Batch:5905/6968  Loss: 3.6900959491729735\n",
      "\n",
      "Epoch:    3/3     Batch:5910/6968  Loss: 3.499337100982666\n",
      "\n",
      "Epoch:    3/3     Batch:5915/6968  Loss: 3.4556767463684084\n",
      "\n",
      "Epoch:    3/3     Batch:5920/6968  Loss: 3.727239418029785\n",
      "\n",
      "Epoch:    3/3     Batch:5925/6968  Loss: 3.5948638916015625\n",
      "\n",
      "Epoch:    3/3     Batch:5930/6968  Loss: 3.6332726001739504\n",
      "\n",
      "Epoch:    3/3     Batch:5935/6968  Loss: 3.6594385147094726\n",
      "\n",
      "Epoch:    3/3     Batch:5940/6968  Loss: 3.6695155620574953\n",
      "\n",
      "Epoch:    3/3     Batch:5945/6968  Loss: 3.397738552093506\n",
      "\n",
      "Epoch:    3/3     Batch:5950/6968  Loss: 3.689455509185791\n",
      "\n",
      "Epoch:    3/3     Batch:5955/6968  Loss: 3.765370178222656\n",
      "\n",
      "Epoch:    3/3     Batch:5960/6968  Loss: 3.481348180770874\n",
      "\n",
      "Epoch:    3/3     Batch:5965/6968  Loss: 3.6478482246398927\n",
      "\n",
      "Epoch:    3/3     Batch:5970/6968  Loss: 3.485438585281372\n",
      "\n",
      "Epoch:    3/3     Batch:5975/6968  Loss: 3.4274666786193846\n",
      "\n",
      "Epoch:    3/3     Batch:5980/6968  Loss: 3.917269229888916\n",
      "\n",
      "Epoch:    3/3     Batch:5985/6968  Loss: 3.90450758934021\n",
      "\n",
      "Epoch:    3/3     Batch:5990/6968  Loss: 3.573064422607422\n",
      "\n",
      "Epoch:    3/3     Batch:5995/6968  Loss: 3.623909521102905\n",
      "\n",
      "Epoch:    3/3     Batch:6000/6968  Loss: 3.529407262802124\n",
      "\n",
      "Epoch:    3/3     Batch:6005/6968  Loss: 3.3925466537475586\n",
      "\n",
      "Epoch:    3/3     Batch:6010/6968  Loss: 3.6775928020477293\n",
      "\n",
      "Epoch:    3/3     Batch:6015/6968  Loss: 3.651239109039307\n",
      "\n",
      "Epoch:    3/3     Batch:6020/6968  Loss: 3.638371801376343\n",
      "\n",
      "Epoch:    3/3     Batch:6025/6968  Loss: 3.587307071685791\n",
      "\n",
      "Epoch:    3/3     Batch:6030/6968  Loss: 3.549798107147217\n",
      "\n",
      "Epoch:    3/3     Batch:6035/6968  Loss: 3.951360750198364\n",
      "\n",
      "Epoch:    3/3     Batch:6040/6968  Loss: 3.7162015438079834\n",
      "\n",
      "Epoch:    3/3     Batch:6045/6968  Loss: 3.5886792182922362\n",
      "\n",
      "Epoch:    3/3     Batch:6050/6968  Loss: 3.573960542678833\n",
      "\n",
      "Epoch:    3/3     Batch:6055/6968  Loss: 3.7169403076171874\n",
      "\n",
      "Epoch:    3/3     Batch:6060/6968  Loss: 3.6125884532928465\n",
      "\n",
      "Epoch:    3/3     Batch:6065/6968  Loss: 3.493911790847778\n",
      "\n",
      "Epoch:    3/3     Batch:6070/6968  Loss: 3.750978136062622\n",
      "\n",
      "Epoch:    3/3     Batch:6075/6968  Loss: 3.8264022350311278\n",
      "\n",
      "Epoch:    3/3     Batch:6080/6968  Loss: 3.702236604690552\n",
      "\n",
      "Epoch:    3/3     Batch:6085/6968  Loss: 3.7301383018493652\n",
      "\n",
      "Epoch:    3/3     Batch:6090/6968  Loss: 3.6567291736602785\n",
      "\n",
      "Epoch:    3/3     Batch:6095/6968  Loss: 3.504810333251953\n",
      "\n",
      "Epoch:    3/3     Batch:6100/6968  Loss: 3.5876137256622314\n",
      "\n",
      "Epoch:    3/3     Batch:6105/6968  Loss: 3.4457475662231447\n",
      "\n",
      "Epoch:    3/3     Batch:6110/6968  Loss: 3.649174690246582\n",
      "\n",
      "Epoch:    3/3     Batch:6115/6968  Loss: 3.705258083343506\n",
      "\n",
      "Epoch:    3/3     Batch:6120/6968  Loss: 3.5035141468048097\n",
      "\n",
      "Epoch:    3/3     Batch:6125/6968  Loss: 3.8262378215789794\n",
      "\n",
      "Epoch:    3/3     Batch:6130/6968  Loss: 3.7129011154174805\n",
      "\n",
      "Epoch:    3/3     Batch:6135/6968  Loss: 3.6607492923736573\n",
      "\n",
      "Epoch:    3/3     Batch:6140/6968  Loss: 3.5799545764923097\n",
      "\n",
      "Epoch:    3/3     Batch:6145/6968  Loss: 3.6028939723968505\n",
      "\n",
      "Epoch:    3/3     Batch:6150/6968  Loss: 3.619406270980835\n",
      "\n",
      "Epoch:    3/3     Batch:6155/6968  Loss: 3.599244737625122\n",
      "\n",
      "Epoch:    3/3     Batch:6160/6968  Loss: 3.4687849044799806\n",
      "\n",
      "Epoch:    3/3     Batch:6165/6968  Loss: 3.638315296173096\n",
      "\n",
      "Epoch:    3/3     Batch:6170/6968  Loss: 3.795287036895752\n",
      "\n",
      "Epoch:    3/3     Batch:6175/6968  Loss: 3.610910415649414\n",
      "\n",
      "Epoch:    3/3     Batch:6180/6968  Loss: 3.397690439224243\n",
      "\n",
      "Epoch:    3/3     Batch:6185/6968  Loss: 3.359698247909546\n",
      "\n",
      "Epoch:    3/3     Batch:6190/6968  Loss: 3.6990734100341798\n",
      "\n",
      "Epoch:    3/3     Batch:6195/6968  Loss: 3.610044002532959\n",
      "\n",
      "Epoch:    3/3     Batch:6200/6968  Loss: 3.610909366607666\n",
      "\n",
      "Epoch:    3/3     Batch:6205/6968  Loss: 3.5131760120391844\n",
      "\n",
      "Epoch:    3/3     Batch:6210/6968  Loss: 3.616502809524536\n",
      "\n",
      "Epoch:    3/3     Batch:6215/6968  Loss: 3.4507805347442626\n",
      "\n",
      "Epoch:    3/3     Batch:6220/6968  Loss: 3.647936391830444\n",
      "\n",
      "Epoch:    3/3     Batch:6225/6968  Loss: 3.6052478313446046\n",
      "\n",
      "Epoch:    3/3     Batch:6230/6968  Loss: 3.635296869277954\n",
      "\n",
      "Epoch:    3/3     Batch:6235/6968  Loss: 3.682665157318115\n",
      "\n",
      "Epoch:    3/3     Batch:6240/6968  Loss: 3.521597719192505\n",
      "\n",
      "Epoch:    3/3     Batch:6245/6968  Loss: 3.6951111793518066\n",
      "\n",
      "Epoch:    3/3     Batch:6250/6968  Loss: 3.652638387680054\n",
      "\n",
      "Epoch:    3/3     Batch:6255/6968  Loss: 3.349701690673828\n",
      "\n",
      "Epoch:    3/3     Batch:6260/6968  Loss: 3.6834450721740724\n",
      "\n",
      "Epoch:    3/3     Batch:6265/6968  Loss: 3.615078163146973\n",
      "\n",
      "Epoch:    3/3     Batch:6270/6968  Loss: 3.67802152633667\n",
      "\n",
      "Epoch:    3/3     Batch:6275/6968  Loss: 3.504541349411011\n",
      "\n",
      "Epoch:    3/3     Batch:6280/6968  Loss: 3.439112138748169\n",
      "\n",
      "Epoch:    3/3     Batch:6285/6968  Loss: 3.5691465854644777\n",
      "\n",
      "Epoch:    3/3     Batch:6290/6968  Loss: 3.6400258541107178\n",
      "\n",
      "Epoch:    3/3     Batch:6295/6968  Loss: 3.5131808280944825\n",
      "\n",
      "Epoch:    3/3     Batch:6300/6968  Loss: 3.6809231281280517\n",
      "\n",
      "Epoch:    3/3     Batch:6305/6968  Loss: 3.5623941898345945\n",
      "\n",
      "Epoch:    3/3     Batch:6310/6968  Loss: 3.6994423866271973\n",
      "\n",
      "Epoch:    3/3     Batch:6315/6968  Loss: 3.8370055675506594\n",
      "\n",
      "Epoch:    3/3     Batch:6320/6968  Loss: 3.4597026348114013\n",
      "\n",
      "Epoch:    3/3     Batch:6325/6968  Loss: 3.6785157680511475\n",
      "\n",
      "Epoch:    3/3     Batch:6330/6968  Loss: 3.4856881141662597\n",
      "\n",
      "Epoch:    3/3     Batch:6335/6968  Loss: 3.5650493621826174\n",
      "\n",
      "Epoch:    3/3     Batch:6340/6968  Loss: 3.562278938293457\n",
      "\n",
      "Epoch:    3/3     Batch:6345/6968  Loss: 3.7841070652008058\n",
      "\n",
      "Epoch:    3/3     Batch:6350/6968  Loss: 3.8717794895172117\n",
      "\n",
      "Epoch:    3/3     Batch:6355/6968  Loss: 3.3763125419616697\n",
      "\n",
      "Epoch:    3/3     Batch:6360/6968  Loss: 3.6387331962585447\n",
      "\n",
      "Epoch:    3/3     Batch:6365/6968  Loss: 3.6921653747558594\n",
      "\n",
      "Epoch:    3/3     Batch:6370/6968  Loss: 3.56028733253479\n",
      "\n",
      "Epoch:    3/3     Batch:6375/6968  Loss: 3.4081616401672363\n",
      "\n",
      "Epoch:    3/3     Batch:6380/6968  Loss: 3.6564648151397705\n",
      "\n",
      "Epoch:    3/3     Batch:6385/6968  Loss: 3.759284782409668\n",
      "\n",
      "Epoch:    3/3     Batch:6390/6968  Loss: 3.57062349319458\n",
      "\n",
      "Epoch:    3/3     Batch:6395/6968  Loss: 3.667746829986572\n",
      "\n",
      "Epoch:    3/3     Batch:6400/6968  Loss: 3.521876001358032\n",
      "\n",
      "Epoch:    3/3     Batch:6405/6968  Loss: 3.7725539207458496\n",
      "\n",
      "Epoch:    3/3     Batch:6410/6968  Loss: 3.7439364433288573\n",
      "\n",
      "Epoch:    3/3     Batch:6415/6968  Loss: 3.6116205215454102\n",
      "\n",
      "Epoch:    3/3     Batch:6420/6968  Loss: 3.602252960205078\n",
      "\n",
      "Epoch:    3/3     Batch:6425/6968  Loss: 3.806879091262817\n",
      "\n",
      "Epoch:    3/3     Batch:6430/6968  Loss: 3.702566719055176\n",
      "\n",
      "Epoch:    3/3     Batch:6435/6968  Loss: 3.687175464630127\n",
      "\n",
      "Epoch:    3/3     Batch:6440/6968  Loss: 3.4057467937469483\n",
      "\n",
      "Epoch:    3/3     Batch:6445/6968  Loss: 3.592828702926636\n",
      "\n",
      "Epoch:    3/3     Batch:6450/6968  Loss: 3.761558198928833\n",
      "\n",
      "Epoch:    3/3     Batch:6455/6968  Loss: 3.6726738929748537\n",
      "\n",
      "Epoch:    3/3     Batch:6460/6968  Loss: 3.601555013656616\n",
      "\n",
      "Epoch:    3/3     Batch:6465/6968  Loss: 3.6892093658447265\n",
      "\n",
      "Epoch:    3/3     Batch:6470/6968  Loss: 3.8065235137939455\n",
      "\n",
      "Epoch:    3/3     Batch:6475/6968  Loss: 3.6973615646362306\n",
      "\n",
      "Epoch:    3/3     Batch:6480/6968  Loss: 3.5743914604187013\n",
      "\n",
      "Epoch:    3/3     Batch:6485/6968  Loss: 3.7937264919281004\n",
      "\n",
      "Epoch:    3/3     Batch:6490/6968  Loss: 3.625578260421753\n",
      "\n",
      "Epoch:    3/3     Batch:6495/6968  Loss: 3.437683629989624\n",
      "\n",
      "Epoch:    3/3     Batch:6500/6968  Loss: 3.5053543567657472\n",
      "\n",
      "Epoch:    3/3     Batch:6505/6968  Loss: 3.5040014743804933\n",
      "\n",
      "Epoch:    3/3     Batch:6510/6968  Loss: 3.5438581466674806\n",
      "\n",
      "Epoch:    3/3     Batch:6515/6968  Loss: 3.7528801918029786\n",
      "\n",
      "Epoch:    3/3     Batch:6520/6968  Loss: 3.7079631328582763\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    3/3     Batch:6525/6968  Loss: 3.5829555988311768\n",
      "\n",
      "Epoch:    3/3     Batch:6530/6968  Loss: 3.530452919006348\n",
      "\n",
      "Epoch:    3/3     Batch:6535/6968  Loss: 3.5610610485076903\n",
      "\n",
      "Epoch:    3/3     Batch:6540/6968  Loss: 3.698462200164795\n",
      "\n",
      "Epoch:    3/3     Batch:6545/6968  Loss: 3.5773062705993652\n",
      "\n",
      "Epoch:    3/3     Batch:6550/6968  Loss: 3.756347179412842\n",
      "\n",
      "Epoch:    3/3     Batch:6555/6968  Loss: 3.4952016353607176\n",
      "\n",
      "Epoch:    3/3     Batch:6560/6968  Loss: 3.44041166305542\n",
      "\n",
      "Epoch:    3/3     Batch:6565/6968  Loss: 3.753227710723877\n",
      "\n",
      "Epoch:    3/3     Batch:6570/6968  Loss: 3.7005665779113768\n",
      "\n",
      "Epoch:    3/3     Batch:6575/6968  Loss: 3.5332562923431396\n",
      "\n",
      "Epoch:    3/3     Batch:6580/6968  Loss: 3.559890699386597\n",
      "\n",
      "Epoch:    3/3     Batch:6585/6968  Loss: 3.3737367153167725\n",
      "\n",
      "Epoch:    3/3     Batch:6590/6968  Loss: 3.5647215366363527\n",
      "\n",
      "Epoch:    3/3     Batch:6595/6968  Loss: 3.700952100753784\n",
      "\n",
      "Epoch:    3/3     Batch:6600/6968  Loss: 3.232957458496094\n",
      "\n",
      "Epoch:    3/3     Batch:6605/6968  Loss: 3.4357194900512695\n",
      "\n",
      "Epoch:    3/3     Batch:6610/6968  Loss: 3.7675338268280028\n",
      "\n",
      "Epoch:    3/3     Batch:6615/6968  Loss: 3.6361529350280763\n",
      "\n",
      "Epoch:    3/3     Batch:6620/6968  Loss: 3.637845849990845\n",
      "\n",
      "Epoch:    3/3     Batch:6625/6968  Loss: 3.7124048709869384\n",
      "\n",
      "Epoch:    3/3     Batch:6630/6968  Loss: 3.4818460941314697\n",
      "\n",
      "Epoch:    3/3     Batch:6635/6968  Loss: 3.718156671524048\n",
      "\n",
      "Epoch:    3/3     Batch:6640/6968  Loss: 3.8071543693542482\n",
      "\n",
      "Epoch:    3/3     Batch:6645/6968  Loss: 3.6043616771697997\n",
      "\n",
      "Epoch:    3/3     Batch:6650/6968  Loss: 3.652070665359497\n",
      "\n",
      "Epoch:    3/3     Batch:6655/6968  Loss: 3.6908188343048094\n",
      "\n",
      "Epoch:    3/3     Batch:6660/6968  Loss: 3.7829421520233155\n",
      "\n",
      "Epoch:    3/3     Batch:6665/6968  Loss: 3.7333337306976317\n",
      "\n",
      "Epoch:    3/3     Batch:6670/6968  Loss: 3.7816202640533447\n",
      "\n",
      "Epoch:    3/3     Batch:6675/6968  Loss: 3.5689866065979006\n",
      "\n",
      "Epoch:    3/3     Batch:6680/6968  Loss: 3.556623411178589\n",
      "\n",
      "Epoch:    3/3     Batch:6685/6968  Loss: 3.60898904800415\n",
      "\n",
      "Epoch:    3/3     Batch:6690/6968  Loss: 3.661164712905884\n",
      "\n",
      "Epoch:    3/3     Batch:6695/6968  Loss: 3.6185887813568116\n",
      "\n",
      "Epoch:    3/3     Batch:6700/6968  Loss: 3.476650047302246\n",
      "\n",
      "Epoch:    3/3     Batch:6705/6968  Loss: 3.5731419563293456\n",
      "\n",
      "Epoch:    3/3     Batch:6710/6968  Loss: 3.6452924251556396\n",
      "\n",
      "Epoch:    3/3     Batch:6715/6968  Loss: 3.798500823974609\n",
      "\n",
      "Epoch:    3/3     Batch:6720/6968  Loss: 3.6476033687591554\n",
      "\n",
      "Epoch:    3/3     Batch:6725/6968  Loss: 3.7617923736572267\n",
      "\n",
      "Epoch:    3/3     Batch:6730/6968  Loss: 3.569374704360962\n",
      "\n",
      "Epoch:    3/3     Batch:6735/6968  Loss: 3.5671746253967287\n",
      "\n",
      "Epoch:    3/3     Batch:6740/6968  Loss: 3.663136100769043\n",
      "\n",
      "Epoch:    3/3     Batch:6745/6968  Loss: 3.5786638259887695\n",
      "\n",
      "Epoch:    3/3     Batch:6750/6968  Loss: 3.6707956790924072\n",
      "\n",
      "Epoch:    3/3     Batch:6755/6968  Loss: 3.598493957519531\n",
      "\n",
      "Epoch:    3/3     Batch:6760/6968  Loss: 3.5338633060455322\n",
      "\n",
      "Epoch:    3/3     Batch:6765/6968  Loss: 3.357118320465088\n",
      "\n",
      "Epoch:    3/3     Batch:6770/6968  Loss: 3.645379877090454\n",
      "\n",
      "Epoch:    3/3     Batch:6775/6968  Loss: 3.560618543624878\n",
      "\n",
      "Epoch:    3/3     Batch:6780/6968  Loss: 3.7151097297668456\n",
      "\n",
      "Epoch:    3/3     Batch:6785/6968  Loss: 3.528292942047119\n",
      "\n",
      "Epoch:    3/3     Batch:6790/6968  Loss: 3.499956655502319\n",
      "\n",
      "Epoch:    3/3     Batch:6795/6968  Loss: 3.590787649154663\n",
      "\n",
      "Epoch:    3/3     Batch:6800/6968  Loss: 3.563859796524048\n",
      "\n",
      "Epoch:    3/3     Batch:6805/6968  Loss: 3.4950952529907227\n",
      "\n",
      "Epoch:    3/3     Batch:6810/6968  Loss: 3.4522743225097656\n",
      "\n",
      "Epoch:    3/3     Batch:6815/6968  Loss: 3.4794214725494386\n",
      "\n",
      "Epoch:    3/3     Batch:6820/6968  Loss: 3.54187593460083\n",
      "\n",
      "Epoch:    3/3     Batch:6825/6968  Loss: 3.7951528072357177\n",
      "\n",
      "Epoch:    3/3     Batch:6830/6968  Loss: 3.433597040176392\n",
      "\n",
      "Epoch:    3/3     Batch:6835/6968  Loss: 3.5415790557861326\n",
      "\n",
      "Epoch:    3/3     Batch:6840/6968  Loss: 3.566202735900879\n",
      "\n",
      "Epoch:    3/3     Batch:6845/6968  Loss: 3.7647832870483398\n",
      "\n",
      "Epoch:    3/3     Batch:6850/6968  Loss: 3.5372707843780518\n",
      "\n",
      "Epoch:    3/3     Batch:6855/6968  Loss: 3.456643581390381\n",
      "\n",
      "Epoch:    3/3     Batch:6860/6968  Loss: 3.612435150146484\n",
      "\n",
      "Epoch:    3/3     Batch:6865/6968  Loss: 3.4351158618927\n",
      "\n",
      "Epoch:    3/3     Batch:6870/6968  Loss: 3.678071165084839\n",
      "\n",
      "Epoch:    3/3     Batch:6875/6968  Loss: 3.6686287403106688\n",
      "\n",
      "Epoch:    3/3     Batch:6880/6968  Loss: 3.686643123626709\n",
      "\n",
      "Epoch:    3/3     Batch:6885/6968  Loss: 3.5929612159729003\n",
      "\n",
      "Epoch:    3/3     Batch:6890/6968  Loss: 3.763274908065796\n",
      "\n",
      "Epoch:    3/3     Batch:6895/6968  Loss: 3.6056727886199953\n",
      "\n",
      "Epoch:    3/3     Batch:6900/6968  Loss: 3.498540496826172\n",
      "\n",
      "Epoch:    3/3     Batch:6905/6968  Loss: 3.54656777381897\n",
      "\n",
      "Epoch:    3/3     Batch:6910/6968  Loss: 3.6781774520874024\n",
      "\n",
      "Epoch:    3/3     Batch:6915/6968  Loss: 3.5419416427612305\n",
      "\n",
      "Epoch:    3/3     Batch:6920/6968  Loss: 3.5813950061798097\n",
      "\n",
      "Epoch:    3/3     Batch:6925/6968  Loss: 3.5970701694488527\n",
      "\n",
      "Epoch:    3/3     Batch:6930/6968  Loss: 3.578663396835327\n",
      "\n",
      "Epoch:    3/3     Batch:6935/6968  Loss: 3.5063587188720704\n",
      "\n",
      "Epoch:    3/3     Batch:6940/6968  Loss: 3.4941399574279783\n",
      "\n",
      "Epoch:    3/3     Batch:6945/6968  Loss: 3.420799398422241\n",
      "\n",
      "Epoch:    3/3     Batch:6950/6968  Loss: 3.6281972885131837\n",
      "\n",
      "Epoch:    3/3     Batch:6955/6968  Loss: 3.668337917327881\n",
      "\n",
      "Epoch:    3/3     Batch:6960/6968  Loss: 3.5879578590393066\n",
      "\n",
      "Epoch:    3/3     Batch:6965/6968  Loss: 3.4976489543914795\n",
      "\n",
      "Model Trained and Saved\n",
      "CPU times: user 3h 9min 47s, sys: 1h 32min 46s, total: 4h 42min 33s\n",
      "Wall time: 4h 42min 59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type RNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "\n",
    "# create model and move to gpu if available\n",
    "rnn = RNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, dropout=0.5)\n",
    "if train_on_gpu:\n",
    "    rnn.cuda()\n",
    "\n",
    "# defining loss and optimization functions for training\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.BCELoss()\n",
    "\n",
    "# training the model\n",
    "from workspace_utils import active_session\n",
    "with active_session():\n",
    "    trained_rnn = train_rnn(rnn, batch_size, optimizer, criterion, num_epochs, show_every_n_batches)\n",
    "\n",
    "# saving the trained model\n",
    "helper.save_model('./save/trained_rnn', trained_rnn)\n",
    "print('Model Trained and Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题: 你如何决定你的模型超参数？\n",
    "比如，你是否试过不同的 different sequence_lengths 并发现哪个使得模型的收敛速度变化？那你的隐藏层数和层数呢？你是如何决定使用这个网络参数的？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**答案:** (在这里写下)    \n",
    "<font color=red>1.sequence_length最后选择为131，因为句子长度为:110到892,公因数为30, 131, 227，取其中131;</font>[How to Generate Music using a LSTM Neural Network in Keras](https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5)   \n",
    "<font color=red>2.隐藏层数设为300，层数设为512,根据推荐论文选择</font>[A Long Short-Term Memory Model for Answer Sentence Selection in Question Answering](http://www.aclweb.org/anthology/P15-2116)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 检查点\n",
    "\n",
    "通过运行上面的训练单元，你的模型已经以`trained_rnn`名字存储，如果你存储了你的notebook， **你可以在之后的任何时间来访问你的代码和结果**. 下述代码可以帮助你重载你的结果!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.path.splitext(os.path.basename('./save/trained_rnn'))[0] + '.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='metadata.google.internal', port=80): Max retries exceeded with url: /computeMetadata/v1/instance/attributes/keep_alive_token (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000000018055780>: Failed to establish a new connection: [Errno 11004] getaddrinfo failed',))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32md:\\setup_room\\python\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             )\n",
      "\u001b[0;32md:\\setup_room\\python\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32md:\\setup_room\\python\\lib\\socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno 11004] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32md:\\setup_room\\python\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m             )\n",
      "\u001b[0;32md:\\setup_room\\python\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32md:\\setup_room\\python\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32md:\\setup_room\\python\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32md:\\setup_room\\python\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1233\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1234\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32md:\\setup_room\\python\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32md:\\setup_room\\python\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32md:\\setup_room\\python\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32md:\\setup_room\\python\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 169\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Failed to establish a new connection: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m             )\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x0000000018055780>: Failed to establish a new connection: [Errno 11004] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32md:\\setup_room\\python\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n",
      "\u001b[0;32md:\\setup_room\\python\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    719\u001b[0m             retries = retries.increment(\n\u001b[0;32m--> 720\u001b[0;31m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             )\n",
      "\u001b[0;32md:\\setup_room\\python\\lib\\site-packages\\urllib3\\util\\retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='metadata.google.internal', port=80): Max retries exceeded with url: /computeMetadata/v1/instance/attributes/keep_alive_token (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000000018055780>: Failed to establish a new connection: [Errno 11004] getaddrinfo failed',))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-734922a1c32c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_to_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint_to_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mactive_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtrained_rnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./save/trained_rnn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32md:\\setup_room\\python\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\workspace_python\\uda_DL\\item_4\\workspace_utils.py\u001b[0m in \u001b[0;36mactive_session\u001b[0;34m(delay, interval)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# do long-running work here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \"\"\"\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTOKEN_URL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTOKEN_HEADERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'Authorization'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"STAR \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mdelay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMIN_DELAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32md:\\setup_room\\python\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32md:\\setup_room\\python\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    531\u001b[0m         }\n\u001b[1;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32md:\\setup_room\\python\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32md:\\setup_room\\python\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='metadata.google.internal', port=80): Max retries exceeded with url: /computeMetadata/v1/instance/attributes/keep_alive_token (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000000018055780>: Failed to establish a new connection: [Errno 11004] getaddrinfo failed',))"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import torch\n",
    "import helper\n",
    "import problem_unittests as tests\n",
    "\n",
    "from workspace_utils import active_session\n",
    "\n",
    "_, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()\n",
    "with active_session():\n",
    "    trained_rnn = helper.load_model('./save/trained_rnn')\n",
    "    \n",
    "trained_rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成电视剧剧本\n",
    "你现在可以生成你的“假”电视剧剧本啦！\n",
    "\n",
    "### 生成文字\n",
    "你的神经网络会不断重复生成一个单词，直到生成满足你要求长度的剧本。使用 `generate` 函数来完成上述操作。首先，使用 `prime_id` 来生成word id，之后确定生成文本长度 `predict_len`。同时， topk 采样来引入文字选择的随机性!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def generate(rnn, prime_id, int_to_vocab, token_dict, pad_value, predict_len=100):\n",
    "    \"\"\"\n",
    "    Generate text using the neural network\n",
    "    :param decoder: The PyTorch Module that holds the trained neural network\n",
    "    :param prime_id: The word id to start the first prediction\n",
    "    :param int_to_vocab: Dict of word id keys to word values\n",
    "    :param token_dict: Dict of puncuation tokens keys to puncuation values\n",
    "    :param pad_value: The value used to pad a sequence\n",
    "    :param predict_len: The length of text to generate\n",
    "    :return: The generated text\n",
    "    \"\"\"\n",
    "    rnn.eval()\n",
    "    \n",
    "    # create a sequence (batch_size=1) with the prime_id\n",
    "    current_seq = np.full((1, sequence_length), pad_value)\n",
    "    current_seq[-1][-1] = prime_id\n",
    "    predicted = [int_to_vocab[prime_id]]\n",
    "    \n",
    "    for _ in range(predict_len):\n",
    "        if train_on_gpu:\n",
    "            current_seq = torch.LongTensor(current_seq).cuda()\n",
    "        else:\n",
    "            current_seq = torch.LongTensor(current_seq)\n",
    "        \n",
    "        # initialize the hidden state\n",
    "        hidden = rnn.init_hidden(current_seq.size(0))\n",
    "        \n",
    "        # get the output of the rnn\n",
    "        output, _ = rnn(current_seq, hidden)\n",
    "        output = output.cuda()\n",
    "        \n",
    "        # get the next word probabilities\n",
    "        p = F.softmax(output, dim=1).data\n",
    "        if(train_on_gpu):\n",
    "            p = p.cpu() # move to cpu\n",
    "         \n",
    "        # use top_k sampling to get the index of the next word\n",
    "        top_k = 5\n",
    "        p, top_i = p.topk(top_k)\n",
    "        top_i = top_i.numpy().squeeze()\n",
    "        \n",
    "        # select the likely next word index with some element of randomness\n",
    "        p = p.numpy().squeeze()\n",
    "        word_i = np.random.choice(top_i, p=p/p.sum())\n",
    "        \n",
    "        # retrieve that word from the dictionary\n",
    "        word = int_to_vocab[word_i]\n",
    "        predicted.append(word)     \n",
    "        \n",
    "        # the generated word becomes the next \"current sequence\" and the cycle can continue\n",
    "        current_seq = np.roll(current_seq, -1, 1)\n",
    "        current_seq[-1][-1] = word_i\n",
    "    \n",
    "    gen_sentences = ' '.join(predicted)\n",
    "    \n",
    "    # Replace punctuation tokens\n",
    "    for key, token in token_dict.items():\n",
    "        ending = ' ' if key in ['\\n', '(', '\"'] else ''\n",
    "        gen_sentences = gen_sentences.replace(' ' + token.lower(), key)\n",
    "    gen_sentences = gen_sentences.replace('\\n ', '\\n')\n",
    "    gen_sentences = gen_sentences.replace('( ', '(')\n",
    "    \n",
    "    # return all the sentences\n",
    "    return gen_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成一个新剧本\n",
    "是时候生成一个剧本啦。设置`gen_length` 剧本长度，设置 `prime_word`为以下任意词来开始生成吧:\n",
    "- \"jerry\"\n",
    "- \"elaine\"\n",
    "- \"george\"\n",
    "- \"kramer\"\n",
    "\n",
    "你可以把prime word 设置成 _任意 _ 单词, 但是使用名字开始会比较好(任何其他名字也是可以哒!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDNN_STATUS_EXECUTION_FAILED",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-fe740e11b3a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpad_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSPECIAL_WORDS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PADDING'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mactive_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mgenerated_script\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_to_int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprime_word\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m':'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint_to_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_to_int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpad_word\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_script\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-3e955a80d033>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(rnn, prime_id, int_to_vocab, token_dict, pad_value, predict_len)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# get the output of the rnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-ee3d76f28cde>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, nn_input, hidden)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# batch first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0membedding_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mnn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mnn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hx, batch_sizes)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mbatch_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_sizes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvariable_length\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             dropout_ts)\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDNN_STATUS_EXECUTION_FAILED"
     ]
    }
   ],
   "source": [
    "# run the cell multiple times to get different results!\n",
    "gen_length = 400 # modify the length to your preference\n",
    "prime_word = 'jerry' # name for starting the script\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "pad_word = helper.SPECIAL_WORDS['PADDING']\n",
    "generated_script = generate(trained_rnn, vocab_to_int[prime_word + ':'], int_to_vocab, token_dict, vocab_to_int[pad_word], gen_length)\n",
    "print(generated_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 存下你最爱的片段\n",
    "\n",
    "一旦你发现一段有趣或者好玩的片段，就把它存下啦！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save script to a text file\n",
    "with active_session():\n",
    "    f =  open(\"generated_script_1.txt\",\"w\")\n",
    "    f.write(generated_script)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 这个电视剧剧本是无意义的\n",
    "如果你的电视剧剧本不是很有逻辑也是ok的。下面是一个例子。\n",
    "\n",
    "### 生成剧本案例\n",
    "\n",
    ">jerry: what about me?\n",
    ">\n",
    ">jerry: i don't have to wait.\n",
    ">\n",
    ">kramer:(to the sales table)\n",
    ">\n",
    ">elaine:(to jerry) hey, look at this, i'm a good doctor.\n",
    ">\n",
    ">newman:(to elaine) you think i have no idea of this...\n",
    ">\n",
    ">elaine: oh, you better take the phone, and he was a little nervous.\n",
    ">\n",
    ">kramer:(to the phone) hey, hey, jerry, i don't want to be a little bit.(to kramer and jerry) you can't.\n",
    ">\n",
    ">jerry: oh, yeah. i don't even know, i know.\n",
    ">\n",
    ">jerry:(to the phone) oh, i know.\n",
    ">\n",
    ">kramer:(laughing) you know...(to jerry) you don't know.\n",
    "\n",
    "\n",
    "如果这个电视剧剧本毫无意义，那也没有关系。我们的训练文本不到一兆字节。为了获得更好的结果，你需要使用更小的词汇范围或是更多数据。幸运的是，我们的确拥有更多数据！在本项目开始之初我们也曾提过，这是[另一个数据集](https://www.kaggle.com/wcukierski/the-simpsons-by-the-data)的子集。我们并没有让你基于所有数据进行训练，因为这将耗费大量时间。然而，你可以随意使用这些数据训练你的神经网络。当然，是在完成本项目之后。\n",
    "# 提交项目\n",
    "在提交项目时，请确保你在保存 notebook 前运行了所有的单元格代码。请将 notebook 文件保存为 \"dlnd_tv_script_generation.ipynb\"，并将它作为 HTML 文件保存在 \"File\" -> \"Download as\" 中。请将 \"helper.py\" 和 \"problem_unittests.py\" 文件一并打包成 zip 文件提交。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\;$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
